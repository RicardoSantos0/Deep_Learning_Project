{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#image manipulation packages\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "sns.set()\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define YOUR path for the data here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\DatasetPartial-Agreement-Images'\n",
    "path_txt = r'C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset/PA-expert-annotations.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_cnn_model():\n",
    "    '''creates an image classification model that uses 2 Convolutional CNNs layers (with maxpooling) and feeds the data through\n",
    "    a dense connected layer. This is trial and error there is no specific reason for 2 layers'''\n",
    "    cnn_model = keras.Sequential([\n",
    "\n",
    "        #convolutional layer with 24 3x3 filters - again, arbitrary,\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'), \n",
    "\n",
    "        #MaxPooling - takes the max value of each 2x2 pool in the feature map\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "\n",
    "        #second convolution with 36 filters\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation= 'relu'),\n",
    "    \n",
    "        #Second MaxPool2D - to check with other options\n",
    "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        \n",
    "        #the result of kthe CNN is then flattened and placed into the \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        \n",
    "        #keras.layers.Dense(256, activation='relu'),\n",
    "        \n",
    "        #final layer, is output, 1 out of 5 possible results\n",
    "        #0 Normal, 1 Tapered, 2 Pyriform, 3 Small, 5 Amorphous\n",
    "        keras.layers.Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - load txt file\n",
    "sperm = 'Sperm'\n",
    "dataframe = pd.read_csv(path_txt, sep = '\\\\t', header = None)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#editions to target dataset\n",
    "dataframe.rename(columns={0 :\"Sperm_Pic\", 1: 'Expert_1', 2: 'Expert_2', 3: 'Expert_3', 4: 'Majority_Vote'}, inplace = True)\n",
    "dataframe['Sperm_Pic'] = dataframe['Sperm_Pic'].str.replace('/S', '-s')\n",
    "dataframe['Majority_Vote'] = dataframe['Majority_Vote'].replace(5, 4)\n",
    "\n",
    "\n",
    "#add ch_00 to all rows:\n",
    "dataframe['Sperm_Pic'] = 'ch00_' + dataframe['Sperm_Pic'] + '.tif'\n",
    "\n",
    "#Drop all irrelevant features\n",
    "dataframe = dataframe.drop(['Expert_1', 'Expert_2', 'Expert_3'], axis = 1)\n",
    "\n",
    "#Show\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Majority_Vote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels in array\n",
    "labels = np.array(dataframe['Majority_Vote'])\n",
    "labels = np.array(np.split(labels, 1132))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Divides Dataset in Folders by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "for image in glob.glob(path+'\\*.tif'):\n",
    "        \n",
    "    imgs.append(cv2.imread(image))\n",
    "\n",
    "    #names of each sample in the image and dataframe are different, gotta deal with this here to match them\n",
    "\n",
    "    img_name = image.split('/')[-1]\n",
    "    check_length = img_name.split('-')[-2]\n",
    "    if len(check_length) == 7:\n",
    "        img_name = img_name[:18] + '0' + img_name[18:]\n",
    "    check_length = img_name.split('-')[-1]\n",
    "    if len(check_length) == 10:\n",
    "        img_name = img_name[:-5] + '0' + img_name[-5:]\n",
    "    img_name = img_name[:-6] + '_' + img_name[-6:]\n",
    "    \n",
    "    #path of each class\n",
    "    path0 = path+'\\class0'\n",
    "    path1 = path+'\\class1'\n",
    "    path2 = path+'\\class2'\n",
    "    path3 = path+'\\class3'\n",
    "    path4 = path+'\\class4'\n",
    "    \n",
    "    #creates folders to store images from eacg category, if not exists already\n",
    "    if not os.path.isdir(path0):\n",
    "        path = path4\n",
    "        os.mkdir(path)\n",
    "        path = path3\n",
    "        os.mkdir(path)\n",
    "        path = path2\n",
    "        os.mkdir(path)\n",
    "        path = path1\n",
    "        os.mkdir(path)\n",
    "        path = path0\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    maj_vote = dataframe[dataframe['Sperm_Pic'].str.contains(img_name)]['Majority_Vote']\n",
    "    if maj_vote.values == 4:\n",
    "        shutil.copy(image, path4)\n",
    "    if maj_vote.values == 3:\n",
    "        shutil.copy(image, path3)\n",
    "    if maj_vote.values == 2:\n",
    "        shutil.copy(image, path2)\n",
    "    if maj_vote.values == 1:\n",
    "        shutil.copy(image, path1)\n",
    "    if maj_vote.values == 0:\n",
    "        shutil.copy(image, path0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Divides Dataset in Training, Validation and Test Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dir = ['/class0', '/class1', '/class2', '/class3', '/class4']\n",
    "\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "if not os.path.isdir(path + '/train'):\n",
    "\n",
    "    for cls in classes_dir:\n",
    "    \n",
    "        #creates train and test folders, with each class separated inside\n",
    "        os.makedirs(path +'/train' + cls)\n",
    "        os.makedirs(path +'/val' + cls)\n",
    "        os.makedirs(path +'/test' + cls)\n",
    "\n",
    "\n",
    "        # Creating partitions of the data after shuffeling\n",
    "        src = path + cls # Folder to copy images from\n",
    "\n",
    "        allFileNames = os.listdir(src)\n",
    "        np.random.shuffle(allFileNames)\n",
    "        \n",
    "        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                              [int(len(allFileNames)* (1 - val_ratio - test_ratio)), \n",
    "                                                               int(len(allFileNames)* (1 - val_ratio))])\n",
    "        \n",
    "        train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "        val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "        test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "\n",
    "    \n",
    "        # Copy-pasting images\n",
    "        for name in train_FileNames:\n",
    "            shutil.copy(name, path +'/train' + cls)\n",
    "\n",
    "        for name in val_FileNames:\n",
    "            shutil.copy(name, path +'/val' + cls)\n",
    "\n",
    "        for name in test_FileNames:\n",
    "            shutil.copy(name, path +'/test' + cls)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipelines\n",
    "class_0 = Augmentor.Pipeline(path+'/train/class0')\n",
    "class_1 = Augmentor.Pipeline(path+'/train/class1')\n",
    "class_2 = Augmentor.Pipeline(path+'/train/class2')\n",
    "class_3 = Augmentor.Pipeline(path+'/train/class3')\n",
    "\n",
    "# Define different augmentations depending on the pipeline; options are limited since we're working with microscopy data\n",
    "\n",
    "#visit: https://augmentor.readthedocs.io/en/master/userguide/mainfeatures.html#rotating\n",
    "#options are:\n",
    "#Perspective skewing: does not make sense; microscopy data\n",
    "###Elastic distortion: could work, but I'm afraid it'll actually deform the shape of the sper cell, which is what is picked up to classify it; could be detremental...\n",
    "###Rotation: makes sense! But no more than 5 degrees left or right...\n",
    "#Shear: does not make sense?\n",
    "#Cropping: does not make sense.\n",
    "###Mirroring: yes! both vertically and horizontally, randomly.\n",
    "\n",
    "\n",
    "#rotate by a maximum of 5 degrees\n",
    "class_0.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "class_1.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "class_2.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "class_3.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "\n",
    "#mirroring, vertical or horizontal, randomly\n",
    "class_0.flip_random(probability=0.7)\n",
    "class_1.flip_random(probability=0.7)\n",
    "class_2.flip_random(probability=0.7)\n",
    "class_3.flip_random(probability=0.7)\n",
    "\n",
    "# Augment images to the same proportion as existing ones in class 4 (majority class)\n",
    "class_0.sample(393-60)\n",
    "class_1.sample(394-136)\n",
    "class_2.sample(394-45)\n",
    "class_3.sample(394-43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 5, #rotates images from -5 to 5 degrees\n",
    "                                   width_shift_range = 0.06, #translates images by 6% to left or right\n",
    "                                   height_shift_range = 0.06, #translates images by 6% up and down\n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.2]) #darkens or brightens the images anywhere between 0 and 20%\n",
    "                                   #shear_range = 0.2, #doesn't make sense here\n",
    "                                   #zoom_range = 0.2 #does not make sense coz this is microscopy data, all taken with same magnification\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(path+'/train',\n",
    "                                                 target_size = (35, 35),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "\n",
    "val_set = test_datagen.flow_from_directory(path+'/val',\n",
    "                                            target_size = (35, 35),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(path+'/test',\n",
    "                                            target_size = (35, 35),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_images_from_folder(folder):\n",
    "    #images = []\n",
    "    #for filename in os.listdir(folder):\n",
    "        #if filename.endswith(\".tif\"):\n",
    "            #img = cv2.imread(os.path.join(folder, filename))\n",
    "            #if img is not None:\n",
    "                #img=np.array(img)\n",
    "                #img = img.astype('float32')\n",
    "                #img /= 255\n",
    "                #images.append(img)\n",
    "    #return images\n",
    "\n",
    "#root_folder = path + '/train'\n",
    "#folders = [os.path.join(root_folder, x) for x in ('class0', 'class1', 'class2', 'class3', 'class4')]\n",
    "#all_train_images = [img for folder in folders for img in load_images_from_folder(folder)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = image_cnn_model()\n",
    "\n",
    "cnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping criteria\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights = True)\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have the latest version of tensorflow, the fit_generator is deprecated.\n",
    "# you should use the fit method (i.e., hist=classifier.fit).\n",
    "# if you do not have the last version you must use fit_generator\n",
    "hist=cnn_model.fit_generator(training_set,\n",
    "                         steps_per_epoch = len(training_set)//32,\n",
    "                         epochs = 50,\n",
    "                         validation_data = val_set,\n",
    "                         validation_steps = len(val_set)//32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have the last version of tensorflow, the predict_generator is deprecated.\n",
    "# you should use the predict method.\n",
    "# if you do not have the last version, you must use predict_generator\n",
    "Y_pred = cnn_model.predict_generator(test_set, 8) # ceil(num_of_test_samples / batch_size)\n",
    "\n",
    "Y = []\n",
    "\n",
    "for sperm_cell in Y_pred:\n",
    "    Y.append(list(sperm_cell).index(max(sperm_cell)))\n",
    "\n",
    "#Y_pred = (Y_pred>0.5)\n",
    "print('Confusion Matrix')\n",
    "print(multilabel_confusion_matrix(test_set.classes, Y))\n",
    "print('Classification Report')\n",
    "target_names = ['0', '1', '2', '3', '4']\n",
    "print(classification_report(test_set.classes, Y, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small test to print last 5 pics\n",
    "\n",
    "plt.figure(figsize=(35,35))\n",
    "\n",
    "#test_folder=r'C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\SCIAN-MorphoSpermGS\\Partial-Agreement-Images'\n",
    "test_folder = r'/Users/Daniel/Documents/DL_Project/Datasets/SCIAN-MorphoSpermGS/Partial-Agreement-Images'\n",
    "for i in range(5):\n",
    "    file = random.choice(os.listdir(test_folder))\n",
    "    image_path= os.path.join(test_folder, file)\n",
    "    img=mpimg.imread(image_path)\n",
    "    ax=plt.subplot(1,5,i+1)\n",
    "    ax.title.set_text(file)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    \n",
    "    for file in os.listdir(os.path.join(img_folder)):\n",
    "        \n",
    "        image_path= os.path.join(img_folder, file)\n",
    "        image= cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.resize(image, (35, 35))#, interpolation = cv2.INTER_AREA) #why interpolate? our images are already 35x35, no need to resize\n",
    "        image=np.array(image)\n",
    "        image = image.astype('float32')\n",
    "        image /= 255 \n",
    "        img_data_array.append(image)\n",
    "    \n",
    "    return img_data_array #extract the image array and class name\n",
    "img_data = create_dataset(test_folder)\n",
    "img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. augmentation while dealing w class imbalance\n",
    "#4. callback for ealy stopping, modelcheckpoint and LearningRateScheduler - https://colab.research.google.com/github/mr7495/covid19/blob/master/data_Loading_Training_Evaluating.ipynb#scrollTo=2Gx5rM25d4W4\n",
    "#2. all pipeline for 5fold cv and metrics/plots for metrics (including learning curves and losses)\n",
    "#3. Add dropout layer\n",
    "#3. Copy CNN structure of paper(s)\n",
    "#5. saliency maps\n",
    "#6. app?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
