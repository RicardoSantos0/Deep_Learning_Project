{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "The current project relies on using CNNs in order to process sperm data. The goal is to develop a classifier able to identify sperm cells.\n",
    "\n",
    "The model is not yet fuly defined. We will start with a standard CNN to Dense Layer.\n",
    "\n",
    "The goal is for images to be loaded into the CNN. The CNN will will then perform feature extraction and those will be fed to the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Create the pipeline\n",
    "\n",
    "The Deep learning model will be made out of 2 different parts: \n",
    "\n",
    "1. A CNN that takes the images as inputs and performs feature extraction.\n",
    "2. A dense, fully connected layer that will perform classification itself with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12838017832935611584\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8080208073006711878\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4971491488\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16020402108907825257\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2137664995782886590\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#need this to run, don't know why\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "#Check Computer's available devices\n",
    "#Will need to check in the future\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "#cfg 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "#cfg2\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = \n",
    "                         tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "# device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#image manipulation packages\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "sns.set()\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Label images\n",
    "\n",
    "In this case, we have a folder with 1132 image - SCIAN-MorphoSpermGS folder - https://cimt.uchile.cl/gold10/. Each image is 35 x 35 pixels and has been classified by 3 experts. We will use majority vote result as target. Each image will need to be loaded and the dataset will need to be created.\n",
    "\n",
    "#### This will yield a dataset with the picture name and the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the path where you've put your dataset provided in Moodle\n",
    "\n",
    "#step 1: change directory back\n",
    "os.chdir('../Dataset')\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1-pl2-sample01/Sperm_01</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1-pl2-sample01/Sperm_02</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1-pl2-sample01/Sperm_03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1-pl2-sample01/Sperm_04</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1-pl2-sample01/Sperm_05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>p5-pl1-sample20/Sperm_07</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>p5-pl1-sample20/Sperm_09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>p5-pl1-sample20/Sperm_11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>p5-pl1-sample20/Sperm_12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>p5-pl1-sample20/Sperm_13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1132 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0  1  2  3  4\n",
       "0     p1-pl2-sample01/Sperm_01  5  5  5  5\n",
       "1     p1-pl2-sample01/Sperm_02  1  5  5  5\n",
       "2     p1-pl2-sample01/Sperm_03  0  0  0  0\n",
       "3     p1-pl2-sample01/Sperm_04  1  5  5  5\n",
       "4     p1-pl2-sample01/Sperm_05  0  0  0  0\n",
       "...                        ... .. .. .. ..\n",
       "1127  p5-pl1-sample20/Sperm_07  1  5  5  5\n",
       "1128  p5-pl1-sample20/Sperm_09  1  1  5  1\n",
       "1129  p5-pl1-sample20/Sperm_11  1  1  5  1\n",
       "1130  p5-pl1-sample20/Sperm_12  5  5  5  5\n",
       "1131  p5-pl1-sample20/Sperm_13  1  5  5  5\n",
       "\n",
       "[1132 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 - load txt file\n",
    "dataframe = pd.read_csv(path + '\\PA-expert-annotations.txt', sep = '\\\\t', header = None, engine = 'python')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Start by most standard preprocessing of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6bf5cf9e776b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['Majority_Vote'] = dataframe['Majority_Vote'].replace(5, 3)\n",
      "<ipython-input-5-6bf5cf9e776b>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['Sperm_Pic'] = 'ch00_' + dataframe['Sperm_Pic'] + '.tif'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sperm_Pic</th>\n",
       "      <th>Majority_Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ch00_p1-pl2-sample01-sperm_01.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ch00_p1-pl2-sample01-sperm_02.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ch00_p1-pl2-sample01-sperm_03.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch00_p1-pl2-sample01-sperm_04.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ch00_p1-pl2-sample01-sperm_05.tif</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>ch00_p5-pl1-sample20-sperm_07.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>ch00_p5-pl1-sample20-sperm_09.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ch00_p5-pl1-sample20-sperm_11.tif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ch00_p5-pl1-sample20-sperm_12.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ch00_p5-pl1-sample20-sperm_13.tif</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Sperm_Pic  Majority_Vote\n",
       "0     ch00_p1-pl2-sample01-sperm_01.tif              3\n",
       "1     ch00_p1-pl2-sample01-sperm_02.tif              3\n",
       "2     ch00_p1-pl2-sample01-sperm_03.tif              0\n",
       "3     ch00_p1-pl2-sample01-sperm_04.tif              3\n",
       "4     ch00_p1-pl2-sample01-sperm_05.tif              0\n",
       "...                                 ...            ...\n",
       "1127  ch00_p5-pl1-sample20-sperm_07.tif              3\n",
       "1128  ch00_p5-pl1-sample20-sperm_09.tif              1\n",
       "1129  ch00_p5-pl1-sample20-sperm_11.tif              1\n",
       "1130  ch00_p5-pl1-sample20-sperm_12.tif              3\n",
       "1131  ch00_p5-pl1-sample20-sperm_13.tif              3\n",
       "\n",
       "[1060 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#editions to target dataset\n",
    "dataframe.rename(columns={0 :\"Sperm_Pic\", 1: 'Expert_1', 2: 'Expert_2', 3: 'Expert_3', 4: 'Majority_Vote'}, inplace = True)\n",
    "dataframe['Sperm_Pic'] = dataframe['Sperm_Pic'].str.replace('/S', '-s')\n",
    "\n",
    "#delete tiny\n",
    "dataframe = dataframe.loc[dataframe['Majority_Vote'] != 3]\n",
    "dataframe['Majority_Vote'] = dataframe['Majority_Vote'].replace(5, 3)\n",
    "\n",
    "\n",
    "#add ch_00 to all rows:\n",
    "dataframe['Sperm_Pic'] = 'ch00_' + dataframe['Sperm_Pic'] + '.tif'\n",
    "\n",
    "#Drop all irrelevant features\n",
    "dataframe = dataframe.drop(['Expert_1', 'Expert_2', 'Expert_3'], axis = 1)\n",
    "\n",
    "#Show\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Place images on Folder based on image Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Partial-Agreement-Images')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-bb3cf003d795>:40: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if maj_vote.values == 3:\n",
      "<ipython-input-8-bb3cf003d795>:42: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if maj_vote.values == 2:\n",
      "<ipython-input-8-bb3cf003d795>:44: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if maj_vote.values == 1:\n",
      "<ipython-input-8-bb3cf003d795>:46: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if maj_vote.values == 0:\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "\n",
    "for image in glob.glob(path+'/*.tif'):\n",
    "        \n",
    "    imgs.append(cv2.imread(image))\n",
    "    \n",
    "    #names of each sample in the image and dataframe are different, gotta deal with this here to match them\n",
    "\n",
    "    img_name = image.split('\\\\')[-1]\n",
    "    check_length = img_name.split('-')[-2]\n",
    "    if len(check_length) == 7:\n",
    "        img_name = img_name[:18] + '0' + img_name[18:]\n",
    "    check_length = img_name.split('-')[-1]\n",
    "    if len(check_length) == 10:\n",
    "        img_name = img_name[:-5] + '0' + img_name[-5:]\n",
    "    img_name = img_name[:-6] + '_' + img_name[-6:]\n",
    "   \n",
    "    #path of each class\n",
    "    path0 = path+'\\\\class0'\n",
    "    path1 = path+'\\\\class1'\n",
    "    path2 = path+'\\\\class2'\n",
    "    path3 = path+'\\\\class3'\n",
    "   \n",
    "    #creates folders to store images from eacg category, if not exists already\n",
    "    #requires dirs to exist - otherwise enters infinite loop and we have to restart script\n",
    "    if not os.path.isdir(path0):\n",
    "\n",
    "        path = path3\n",
    "        os.mkdir(path)\n",
    "        path = path2\n",
    "        os.mkdir(path)\n",
    "        path = path1\n",
    "        os.mkdir(path)\n",
    "        path = path0\n",
    "        os.mkdir(path)\n",
    "\n",
    "    #creates copy of image based on label\n",
    "    maj_vote = dataframe[dataframe['Sperm_Pic'].str.contains(img_name)]['Majority_Vote']\n",
    "\n",
    "    if maj_vote.values == 3:\n",
    "        shutil.copy(image, path3)\n",
    "    if maj_vote.values == 2:\n",
    "        shutil.copy(image, path2)\n",
    "    if maj_vote.values == 1:\n",
    "        shutil.copy(image, path1)\n",
    "    if maj_vote.values == 0:\n",
    "        shutil.copy(image, path0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    656\n",
       "1    228\n",
       "0    100\n",
       "2     76\n",
       "Name: Majority_Vote, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparing to images on each folder\n",
    "dataframe['Majority_Vote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_001.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_002.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_003.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_004.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_005.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_006.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_007.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_008.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_009.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_010.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_011.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_012.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_013.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_014.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_015.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_016.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_017.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_018.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_019.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_020.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_021.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_022.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_023.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_024.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_025.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_026.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_027.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_028.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_029.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_030.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_031.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_032.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_033.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_034.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_035.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_036.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_037.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_038.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_039.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_040.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_041.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_042.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_043.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_044.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_045.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_046.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_047.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_048.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_049.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_050.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_051.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_052.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_053.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class0\\\\image_054.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_001.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_002.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_003.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_004.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_005.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_006.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_007.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_008.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_009.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_010.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_011.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_012.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_013.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_014.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_015.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_016.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_017.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_018.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_019.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_020.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_021.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_022.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_023.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_024.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_025.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_026.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_027.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_028.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_029.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_030.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_031.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_032.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_033.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_034.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_035.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_036.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_037.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_038.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_039.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_040.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_041.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_042.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_043.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_044.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_045.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_046.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_047.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_048.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_049.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_050.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_051.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_052.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class1\\\\image_053.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_001.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_002.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_003.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_004.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_005.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_006.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_007.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_008.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_009.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_010.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_011.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_012.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_013.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_014.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_015.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_016.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_017.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_018.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_019.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_020.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_021.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_022.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_023.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_024.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_025.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_026.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_027.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_028.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_029.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_030.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_031.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_032.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_033.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_034.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_035.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_036.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_037.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_038.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_039.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_040.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_041.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_042.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_043.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_044.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_045.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_046.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_047.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_048.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_049.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_050.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_051.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_052.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_053.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_054.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_055.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_056.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class2\\\\image_057.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_001.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_002.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_003.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_004.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_005.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_006.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_007.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_008.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_009.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_010.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_011.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_012.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_013.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_014.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_015.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_016.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_017.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_018.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_019.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_020.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_021.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_022.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_023.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_024.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_025.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_026.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_027.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_028.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_029.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_030.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_031.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_032.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_033.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_034.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_035.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_036.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_037.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_038.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_039.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_040.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_041.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_042.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_043.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_044.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_045.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_046.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_047.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_048.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_049.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_050.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_051.BMP',\n",
       " 'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\Dataset\\\\Partial-Agreement-Images\\\\class3\\\\image_052.BMP']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optional Join Hushem Data\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "# copy subdirectory example\n",
    "fromDirectory = r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset\\HuSHem\"\n",
    "toDirectory = r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset\\Partial-Agreement-Images\"\n",
    "\n",
    "copy_tree(fromDirectory, toDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Create Folders for Training, Validation and Test Data\n",
    "The Current solution is somewhat innefficient because it requires the creation of 2 copies of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dir = ['/class0', '/class1', '/class2', '/class3']\n",
    "\n",
    "val_ratio = 0.20\n",
    "test_ratio = 0.20\n",
    "\n",
    "if not os.path.isdir(path + '/train'):\n",
    "\n",
    "    for cls in classes_dir:\n",
    "    \n",
    "        #creates train and test folders, with each class separated inside\n",
    "        os.makedirs(path +'/train' + cls)\n",
    "        os.makedirs(path +'/val' + cls)\n",
    "        os.makedirs(path +'/test' + cls)\n",
    "\n",
    "\n",
    "        # Creating partitions of the data after shuffeling\n",
    "        src = path + cls # Folder to copy images from\n",
    "\n",
    "        allFileNames = os.listdir(src)\n",
    "        np.random.shuffle(allFileNames)\n",
    "        \n",
    "        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                              [int(len(allFileNames)* (1 - val_ratio - test_ratio)), \n",
    "                                                               int(len(allFileNames)* (1 - val_ratio))])\n",
    "        \n",
    "        train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "        val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "        test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "\n",
    "    \n",
    "        # Copy-pasting images\n",
    "        for name in train_FileNames:\n",
    "            shutil.copy(name, path +'/train' + cls)\n",
    "\n",
    "        for name in val_FileNames:\n",
    "            shutil.copy(name, path +'/val' + cls)\n",
    "\n",
    "        for name in test_FileNames:\n",
    "            shutil.copy(name, path +'/test' + cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Normal: 1024\n",
      "Images Tapered: 1024\n",
      "Images Pyriform: 1024\n",
      "Images Amorphous: 1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count files in folder\n",
    "\n",
    "def fileCount(folder):\n",
    "    \"count the number of files in a directory\"\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            count += 1\n",
    "        elif os.path.isdir(path):\n",
    "            count += fileCount(path)\n",
    "\n",
    "    return count\n",
    "\n",
    "count_0 = fileCount(path+'/train/class0')\n",
    "count_1 = fileCount(path+'/train/class1')\n",
    "count_2 = fileCount(path+'/train/class2')\n",
    "count_3 = fileCount(path+'/train/class3')\n",
    "\n",
    "print(f'Images Normal: {count_0}\\n' +\n",
    "     f'Images Tapered: {count_1}\\n' +\n",
    "     f'Images Pyriform: {count_2}\\n' +\n",
    "     f'Images Amorphous: {count_3}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Augment images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 92 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset\\Partial-Agreement-Images/train/class0\\output.Initialised with 168 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset\\Partial-Agreement-Images/train/class1\\output.Initialised with 79 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset\\Partial-Agreement-Images/train/class2\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=131x131 at 0x2DAE54128E0>:   2%|â–ˆ                                           | 23/932 [00:00<00:09, 99.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 424 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Dataset\\Partial-Agreement-Images/train/class3\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=34x34 at 0x2DAE5319190>: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 932/932 [00:01<00:00, 542.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x2DAE7B1E040>: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 856/856 [00:01<00:00, 542.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=131x131 at 0x2DAE5696490>: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 945/945 [00:01<00:00, 569.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x2DAE53190A0>: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:01<00:00, 518.58 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation pipelines\n",
    "class_0 = Augmentor.Pipeline(path+'/train/class0')\n",
    "class_1 = Augmentor.Pipeline(path+'/train/class1')\n",
    "class_2 = Augmentor.Pipeline(path+'/train/class2')\n",
    "class_3 = Augmentor.Pipeline(path+'/train/class3')\n",
    "\n",
    "# Define different augmentations depending on the pipeline; options are limited since we're working with microscopy data\n",
    "\n",
    "#visit: https://augmentor.readthedocs.io/en/master/userguide/mainfeatures.html#rotating\n",
    "#options are:\n",
    "#Perspective skewing: does not make sense; microscopy data\n",
    "###Elastic distortion: could work, but I'm afraid it'll actually deform the shape of the sper cell, which is what is picked up to classify it; could be detremental...\n",
    "###Rotation: makes sense! But no more than 5 degrees left or right...\n",
    "#Shear: does not make sense?\n",
    "#Cropping: does not make sense.\n",
    "###Mirroring: yes! both vertically and horizontally, randomly.\n",
    "\n",
    "\n",
    "#rotate by a maximum of 5 degrees\n",
    "class_0.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "class_1.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "class_2.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "class_3.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "\n",
    "#mirroring, vertical or horizontal, randomly\n",
    "class_0.flip_random(probability=0.7)\n",
    "class_1.flip_random(probability=0.7)\n",
    "class_2.flip_random(probability=0.7)\n",
    "class_3.flip_random(probability=0.7)\n",
    "\n",
    "\n",
    "# Augment images to the same proportion as existing ones in class 4 (majority class - get to 1000 in each class)\n",
    "class_0.sample(512 - count_0)\n",
    "class_1.sample(512 - count_1)\n",
    "class_2.sample(512 - count_2)\n",
    "class_3.sample(512 - count_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4096 images belonging to 4 classes.\n",
      "Found 256 images belonging to 4 classes.\n",
      "Found 257 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#load image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#to play around with these\n",
    "#Online Data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 5, #rotates images from -5 to 5 degrees\n",
    "                                   width_shift_range = 0.06, #translates images by 6% to left or right\n",
    "                                   height_shift_range = 0.06, #translates images by 6% up and down\n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.2], \n",
    "                                   fill_mode='nearest',\n",
    "                                   zoom_range = 0.2,\n",
    "                                   ) \n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#test different color maps -  class modes and cross validation types\n",
    "training_set = train_datagen.flow_from_directory(path+'/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 32,\n",
    "                                                 shuffle = True,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 color_mode = 'rgb')\n",
    "\n",
    "val_set = val_datagen.flow_from_directory(path+'/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 32,\n",
    "                                            shuffle = True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(path+'/test',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Very Simple Test Model\n",
    "\n",
    "To Test CROSS_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_test_model():\n",
    "    '''creates an image classification model that uses 2 Convolutional CNNs layers (with maxpooling) and feeds the data through\n",
    "    a dense connected layer. This is a simple model to compute fast to test cross_validation'''\n",
    "    \n",
    "    cnn_model = keras.Sequential([\n",
    "\n",
    "        #convolutional layer with 32 3x3 filters - again, arbitrary,\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding = 'same', activation='relu'), \n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #2nd convolution with 128 filters\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "       \n",
    "        #MaxPooling - takes the max value of each 2x2 pool in the feature map\n",
    "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #the result of kthe CNN is then flattened and placed into the \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #final layer, is output, 1 out of 4 possible results\n",
    "        #0 Normal, 1 Tapered, 2 Pyriform, 3 Amorphous\n",
    "        keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define call-back early stopping criteria\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model: First try\n",
    "test_model = cnn_test_model()\n",
    "\n",
    "test_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 1.7970 - accuracy: 0.3339 - val_loss: 1.3916 - val_accuracy: 0.1875s - loss: 1.8023 - accuracy: 0.33\n",
      "Epoch 2/4000\n",
      "128/128 [==============================] - 4s 32ms/step - loss: 1.2933 - accuracy: 0.4126 - val_loss: 1.6223 - val_accuracy: 0.1367\n",
      "Epoch 3/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.2653 - accuracy: 0.4325 - val_loss: 1.6484 - val_accuracy: 0.1406\n",
      "Epoch 4/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.2413 - accuracy: 0.4370 - val_loss: 1.4852 - val_accuracy: 0.2227\n",
      "Epoch 5/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 1.2171 - accuracy: 0.4500 - val_loss: 1.3507 - val_accuracy: 0.5625\n",
      "Epoch 6/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.1832 - accuracy: 0.4599 - val_loss: 1.0467 - val_accuracy: 0.5820\n",
      "Epoch 7/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.1731 - accuracy: 0.4704 - val_loss: 1.3685 - val_accuracy: 0.3008\n",
      "Epoch 8/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.1823 - accuracy: 0.4680 - val_loss: 1.3767 - val_accuracy: 0.3281\n",
      "Epoch 9/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.1574 - accuracy: 0.4938 - val_loss: 1.2047 - val_accuracy: 0.5742\n",
      "Epoch 10/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 1.1216 - accuracy: 0.4990 - val_loss: 1.1747 - val_accuracy: 0.4531\n",
      "Epoch 11/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 1.0987 - accuracy: 0.5096 - val_loss: 22.0760 - val_accuracy: 0.3750\n",
      "Epoch 12/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 1.1117 - accuracy: 0.5193 - val_loss: 0.9777 - val_accuracy: 0.6094\n",
      "Epoch 13/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 1.0696 - accuracy: 0.5368 - val_loss: 1.0798 - val_accuracy: 0.5898\n",
      "Epoch 14/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 1.0521 - accuracy: 0.5423 - val_loss: 1.2062 - val_accuracy: 0.3555\n",
      "Epoch 15/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 1.0847 - accuracy: 0.5183 - val_loss: 1.3311 - val_accuracy: 0.3555\n",
      "Epoch 16/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 1.0463 - accuracy: 0.5495 - val_loss: 1.0593 - val_accuracy: 0.4961\n",
      "Epoch 17/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 1.0212 - accuracy: 0.5696 - val_loss: 0.9647 - val_accuracy: 0.6016\n",
      "Epoch 18/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.0657 - accuracy: 0.5290 - val_loss: 0.8906 - val_accuracy: 0.6445\n",
      "Epoch 19/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.9803 - accuracy: 0.5821 - val_loss: 1.0141 - val_accuracy: 0.5859\n",
      "Epoch 20/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.0038 - accuracy: 0.5674 - val_loss: 1.2473 - val_accuracy: 0.4375\n",
      "Epoch 21/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.9911 - accuracy: 0.5777 - val_loss: 1.0377 - val_accuracy: 0.4961\n",
      "Epoch 22/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.9572 - accuracy: 0.5961 - val_loss: 1.0118 - val_accuracy: 0.5820\n",
      "Epoch 23/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.9593 - accuracy: 0.6001 - val_loss: 0.9938 - val_accuracy: 0.5352\n",
      "Epoch 24/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.9099 - accuracy: 0.6179 - val_loss: 0.8672 - val_accuracy: 0.6211\n",
      "Epoch 25/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.9095 - accuracy: 0.6133 - val_loss: 1.0744 - val_accuracy: 0.5195\n",
      "Epoch 26/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.9261 - accuracy: 0.6030 - val_loss: 1.0851 - val_accuracy: 0.5625\n",
      "Epoch 27/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.9620 - accuracy: 0.5852 - val_loss: 1.3427 - val_accuracy: 0.5781\n",
      "Epoch 28/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.9689 - accuracy: 0.6042 - val_loss: 0.8928 - val_accuracy: 0.6289\n",
      "Epoch 29/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.9462 - accuracy: 0.6081 - val_loss: 31.8378 - val_accuracy: 0.2695\n",
      "Epoch 30/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 1.0798 - accuracy: 0.5222 - val_loss: 1.0684 - val_accuracy: 0.5156\n",
      "Epoch 31/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.9400 - accuracy: 0.6072 - val_loss: 0.8367 - val_accuracy: 0.6875\n",
      "Epoch 32/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.9222 - accuracy: 0.6152 - val_loss: 1.2315 - val_accuracy: 0.4531\n",
      "Epoch 33/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8907 - accuracy: 0.6313 - val_loss: 1.0458 - val_accuracy: 0.5234\n",
      "Epoch 34/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8673 - accuracy: 0.6426 - val_loss: 0.8439 - val_accuracy: 0.6641\n",
      "Epoch 35/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8816 - accuracy: 0.6393 - val_loss: 0.9497 - val_accuracy: 0.6250\n",
      "Epoch 36/4000\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.8535 - accuracy: 0.6499 - val_loss: 0.8704 - val_accuracy: 0.6055\n",
      "Epoch 37/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8542 - accuracy: 0.6428 - val_loss: 0.9142 - val_accuracy: 0.5898\n",
      "Epoch 38/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8623 - accuracy: 0.6347 - val_loss: 0.9494 - val_accuracy: 0.5703\n",
      "Epoch 39/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8223 - accuracy: 0.6609 - val_loss: 0.9494 - val_accuracy: 0.5742\n",
      "Epoch 40/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8171 - accuracy: 0.6605 - val_loss: 0.9213 - val_accuracy: 0.5938\n",
      "Epoch 41/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8129 - accuracy: 0.6670 - val_loss: 0.9503 - val_accuracy: 0.5898\n",
      "Epoch 42/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8118 - accuracy: 0.6740 - val_loss: 0.9461 - val_accuracy: 0.5859\n",
      "Epoch 43/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7982 - accuracy: 0.6781 - val_loss: 1.0742 - val_accuracy: 0.5742\n",
      "Epoch 44/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7723 - accuracy: 0.6861 - val_loss: 0.9127 - val_accuracy: 0.5781\n",
      "Epoch 45/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7614 - accuracy: 0.6808 - val_loss: 0.7969 - val_accuracy: 0.6641\n",
      "Epoch 46/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7774 - accuracy: 0.6846 - val_loss: 1.0671 - val_accuracy: 0.5742\n",
      "Epoch 47/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.7778 - accuracy: 0.6764 - val_loss: 0.8419 - val_accuracy: 0.6250\n",
      "Epoch 48/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.7466 - accuracy: 0.6965 - val_loss: 1.0068 - val_accuracy: 0.5742\n",
      "Epoch 49/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7721 - accuracy: 0.6876 - val_loss: 0.9114 - val_accuracy: 0.6484\n",
      "Epoch 50/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7344 - accuracy: 0.7129 - val_loss: 0.9868 - val_accuracy: 0.5703\n",
      "Epoch 51/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7228 - accuracy: 0.7002 - val_loss: 0.9427 - val_accuracy: 0.6055\n",
      "Epoch 52/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7315 - accuracy: 0.7053 - val_loss: 0.9585 - val_accuracy: 0.5352\n",
      "Epoch 53/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7136 - accuracy: 0.7181 - val_loss: 0.8921 - val_accuracy: 0.6289\n",
      "Epoch 54/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7205 - accuracy: 0.7050 - val_loss: 4.5600 - val_accuracy: 0.6211\n",
      "Epoch 55/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7845 - accuracy: 0.6710 - val_loss: 1.1102 - val_accuracy: 0.5508\n",
      "Epoch 56/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7508 - accuracy: 0.7008 - val_loss: 0.8636 - val_accuracy: 0.6172\n",
      "Epoch 57/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7687 - accuracy: 0.6855 - val_loss: 1.2722 - val_accuracy: 0.4727\n",
      "Epoch 58/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7725 - accuracy: 0.6723 - val_loss: 1.0179 - val_accuracy: 0.5703\n",
      "Epoch 59/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7263 - accuracy: 0.7050 - val_loss: 1.0372 - val_accuracy: 0.5586\n",
      "Epoch 60/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7111 - accuracy: 0.7054 - val_loss: 0.9831 - val_accuracy: 0.6016\n",
      "Epoch 61/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.8794 - accuracy: 0.6259 - val_loss: 1.0379 - val_accuracy: 0.5312 0s - los\n",
      "Epoch 62/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7258 - accuracy: 0.7101 - val_loss: 1.1119 - val_accuracy: 0.5234\n",
      "Epoch 63/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.7094 - accuracy: 0.7215 - val_loss: 0.8123 - val_accuracy: 0.6367\n",
      "Epoch 64/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6807 - accuracy: 0.7202 - val_loss: 1.0713 - val_accuracy: 0.5352\n",
      "Epoch 65/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6909 - accuracy: 0.7248 - val_loss: 0.9050 - val_accuracy: 0.5703\n",
      "Epoch 66/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6743 - accuracy: 0.7234 - val_loss: 0.8074 - val_accuracy: 0.7031\n",
      "Epoch 67/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6685 - accuracy: 0.7353 - val_loss: 0.8940 - val_accuracy: 0.5820\n",
      "Epoch 68/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6793 - accuracy: 0.7284 - val_loss: 0.9248 - val_accuracy: 0.5781\n",
      "Epoch 69/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6553 - accuracy: 0.7331 - val_loss: 1.0098 - val_accuracy: 0.5508\n",
      "Epoch 70/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6164 - accuracy: 0.7461 - val_loss: 0.8811 - val_accuracy: 0.6094\n",
      "Epoch 71/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6141 - accuracy: 0.7619 - val_loss: 1.1409 - val_accuracy: 0.5820 0s - l\n",
      "Epoch 72/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6269 - accuracy: 0.7506 - val_loss: 1.1848 - val_accuracy: 0.6562\n",
      "Epoch 73/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6474 - accuracy: 0.7475 - val_loss: 0.8574 - val_accuracy: 0.6367\n",
      "Epoch 74/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.6065 - accuracy: 0.7597 - val_loss: 1.0666 - val_accuracy: 0.5469\n",
      "Epoch 75/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.6417 - accuracy: 0.7421 - val_loss: 1.0797 - val_accuracy: 0.5859\n",
      "Epoch 76/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.6494 - accuracy: 0.7463 - val_loss: 1.0642 - val_accuracy: 0.6016\n",
      "Epoch 77/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.6364 - accuracy: 0.7450 - val_loss: 2.0871 - val_accuracy: 0.6094\n",
      "Epoch 78/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.7480 - accuracy: 0.7057 - val_loss: 0.9687 - val_accuracy: 0.6172\n",
      "Epoch 79/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.6298 - accuracy: 0.7455 - val_loss: 1.0070 - val_accuracy: 0.5469\n",
      "Epoch 80/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.6184 - accuracy: 0.7559 - val_loss: 1.0422 - val_accuracy: 0.5977\n",
      "Epoch 81/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.6198 - accuracy: 0.7537 - val_loss: 0.9378 - val_accuracy: 0.5977  - ETA: 1s - loss: 0.6231 - accuracy - ETA: 0s - los\n",
      "Epoch 82/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.6224 - accuracy: 0.7472 - val_loss: 0.9194 - val_accuracy: 0.6406\n",
      "Epoch 83/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.6023 - accuracy: 0.7560 - val_loss: 0.9867 - val_accuracy: 0.6562\n",
      "Epoch 84/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.5752 - accuracy: 0.7688 - val_loss: 0.9573 - val_accuracy: 0.5898\n",
      "Epoch 85/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.5982 - accuracy: 0.7705 - val_loss: 0.9566 - val_accuracy: 0.6055\n",
      "Epoch 86/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.5779 - accuracy: 0.7734 - val_loss: 1.0040 - val_accuracy: 0.5625\n",
      "Epoch 87/4000\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 0.5631 - accuracy: 0.7768 - val_loss: 1.6983 - val_accuracy: 0.4609\n",
      "Epoch 88/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.7393 - accuracy: 0.7021 - val_loss: 0.8958 - val_accuracy: 0.6406\n",
      "Epoch 89/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.5812 - accuracy: 0.7747 - val_loss: 0.9543 - val_accuracy: 0.6094\n",
      "Epoch 90/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5934 - accuracy: 0.7749 - val_loss: 0.8362 - val_accuracy: 0.6406\n",
      "Epoch 91/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.5538 - accuracy: 0.7753 - val_loss: 0.9344 - val_accuracy: 0.6133\n",
      "Epoch 92/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.5857 - accuracy: 0.7659 - val_loss: 0.9739 - val_accuracy: 0.5859\n",
      "Epoch 93/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5629 - accuracy: 0.7817 - val_loss: 0.9904 - val_accuracy: 0.6094\n",
      "Epoch 94/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.5580 - accuracy: 0.7807 - val_loss: 0.9164 - val_accuracy: 0.6289\n",
      "Epoch 95/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.5304 - accuracy: 0.8002 - val_loss: 0.9902 - val_accuracy: 0.6250\n",
      "Epoch 96/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.5387 - accuracy: 0.7836 - val_loss: 1.0418 - val_accuracy: 0.6562\n",
      "Epoch 97/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.5591 - accuracy: 0.7804 - val_loss: 1.0211 - val_accuracy: 0.5742\n",
      "Epoch 98/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.5480 - accuracy: 0.7865 - val_loss: 1.0986 - val_accuracy: 0.6133:\n",
      "Epoch 99/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.5682 - accuracy: 0.7800 - val_loss: 0.9939 - val_accuracy: 0.5781\n",
      "Epoch 100/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5207 - accuracy: 0.7785 - val_loss: 0.9115 - val_accuracy: 0.5781\n",
      "Epoch 101/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5295 - accuracy: 0.7960 - val_loss: 0.9629 - val_accuracy: 0.6250\n",
      "Epoch 102/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5235 - accuracy: 0.7946 - val_loss: 0.9542 - val_accuracy: 0.6055\n",
      "Epoch 103/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5294 - accuracy: 0.7925 - val_loss: 0.9557 - val_accuracy: 0.6094\n",
      "Epoch 104/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.5101 - accuracy: 0.7998 - val_loss: 0.9018 - val_accuracy: 0.6172\n",
      "Epoch 105/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4862 - accuracy: 0.8009 - val_loss: 0.9764 - val_accuracy: 0.6133\n",
      "Epoch 106/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4782 - accuracy: 0.8154 - val_loss: 1.2374 - val_accuracy: 0.5742\n",
      "Epoch 107/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4676 - accuracy: 0.8173 - val_loss: 0.8943 - val_accuracy: 0.6562\n",
      "Epoch 108/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.5117 - accuracy: 0.8002 - val_loss: 1.7968 - val_accuracy: 0.6094\n",
      "Epoch 109/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.7374 - accuracy: 0.7072 - val_loss: 1.0120 - val_accuracy: 0.5703\n",
      "Epoch 110/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.5739 - accuracy: 0.7730 - val_loss: 0.8597 - val_accuracy: 0.6523\n",
      "Epoch 111/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5243 - accuracy: 0.7911 - val_loss: 1.3802 - val_accuracy: 0.5117\n",
      "Epoch 112/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.5180 - accuracy: 0.7989 - val_loss: 1.1198 - val_accuracy: 0.6055\n",
      "Epoch 113/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.5035 - accuracy: 0.8067 - val_loss: 1.2383 - val_accuracy: 0.6445\n",
      "Epoch 114/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4686 - accuracy: 0.8126 - val_loss: 1.0202 - val_accuracy: 0.6484\n",
      "Epoch 115/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4647 - accuracy: 0.8129 - val_loss: 0.9605 - val_accuracy: 0.6328\n",
      "Epoch 116/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4487 - accuracy: 0.8236 - val_loss: 0.9225 - val_accuracy: 0.6680\n",
      "Epoch 117/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4639 - accuracy: 0.8184 - val_loss: 0.9667 - val_accuracy: 0.6094\n",
      "Epoch 118/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4786 - accuracy: 0.8128 - val_loss: 1.0797 - val_accuracy: 0.5938\n",
      "Epoch 119/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4741 - accuracy: 0.8174 - val_loss: 0.8790 - val_accuracy: 0.6602\n",
      "Epoch 120/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4655 - accuracy: 0.8222 - val_loss: 1.0104 - val_accuracy: 0.6328\n",
      "Epoch 121/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4865 - accuracy: 0.8139 - val_loss: 1.1681 - val_accuracy: 0.6094\n",
      "Epoch 122/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4944 - accuracy: 0.8190 - val_loss: 0.9755 - val_accuracy: 0.6641\n",
      "Epoch 123/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4716 - accuracy: 0.8154 - val_loss: 1.0188 - val_accuracy: 0.5859\n",
      "Epoch 124/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4492 - accuracy: 0.8281 - val_loss: 1.0904 - val_accuracy: 0.6133\n",
      "Epoch 125/4000\n",
      "128/128 [==============================] - 4s 35ms/step - loss: 0.4633 - accuracy: 0.8121 - val_loss: 1.0646 - val_accuracy: 0.6562\n",
      "Epoch 126/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4738 - accuracy: 0.8152 - val_loss: 1.0894 - val_accuracy: 0.6328\n",
      "Epoch 127/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4420 - accuracy: 0.8231 - val_loss: 0.9837 - val_accuracy: 0.6211\n",
      "Epoch 128/4000\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.4487 - accuracy: 0.8283 - val_loss: 0.9888 - val_accuracy: 0.6328\n",
      "Epoch 129/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.4176 - accuracy: 0.8416 - val_loss: 1.0270 - val_accuracy: 0.6211\n",
      "Epoch 130/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4309 - accuracy: 0.8363 - val_loss: 0.9471 - val_accuracy: 0.6406\n",
      "Epoch 131/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4428 - accuracy: 0.8286 - val_loss: 1.0307 - val_accuracy: 0.6328\n",
      "Epoch 132/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4183 - accuracy: 0.8405 - val_loss: 1.1034 - val_accuracy: 0.6133\n",
      "Epoch 133/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4278 - accuracy: 0.8321 - val_loss: 1.0605 - val_accuracy: 0.6328\n",
      "Epoch 134/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4125 - accuracy: 0.8505 - val_loss: 1.2303 - val_accuracy: 0.5586\n",
      "Epoch 135/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4469 - accuracy: 0.8317 - val_loss: 1.1326 - val_accuracy: 0.6367\n",
      "Epoch 136/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.4396 - accuracy: 0.8271 - val_loss: 0.8388 - val_accuracy: 0.6719\n",
      "Epoch 137/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4231 - accuracy: 0.8431 - val_loss: 1.0741 - val_accuracy: 0.6445\n",
      "Epoch 138/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4176 - accuracy: 0.8363 - val_loss: 0.9011 - val_accuracy: 0.6641\n",
      "Epoch 139/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4012 - accuracy: 0.8448 - val_loss: 0.9112 - val_accuracy: 0.6602\n",
      "Epoch 140/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.4132 - accuracy: 0.8468 - val_loss: 0.9986 - val_accuracy: 0.6484\n",
      "Epoch 141/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3924 - accuracy: 0.8461 - val_loss: 0.9304 - val_accuracy: 0.6680\n",
      "Epoch 142/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3795 - accuracy: 0.8613 - val_loss: 1.0214 - val_accuracy: 0.6523\n",
      "Epoch 143/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4176 - accuracy: 0.8457 - val_loss: 1.0065 - val_accuracy: 0.6445\n",
      "Epoch 144/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.4408 - accuracy: 0.8280 - val_loss: 1.0787 - val_accuracy: 0.6406\n",
      "Epoch 145/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.4504 - accuracy: 0.8313 - val_loss: 0.8707 - val_accuracy: 0.6445\n",
      "Epoch 146/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4098 - accuracy: 0.8459 - val_loss: 0.9364 - val_accuracy: 0.6836\n",
      "Epoch 147/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3909 - accuracy: 0.8500 - val_loss: 0.8814 - val_accuracy: 0.6484\n",
      "Epoch 148/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3839 - accuracy: 0.8543 - val_loss: 0.9418 - val_accuracy: 0.6562\n",
      "Epoch 149/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3705 - accuracy: 0.8602 - val_loss: 1.4238 - val_accuracy: 0.6328\n",
      "Epoch 150/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3692 - accuracy: 0.8593 - val_loss: 1.2119 - val_accuracy: 0.5859\n",
      "Epoch 151/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3879 - accuracy: 0.8496 - val_loss: 1.5544 - val_accuracy: 0.5820\n",
      "Epoch 152/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4240 - accuracy: 0.8343 - val_loss: 1.0720 - val_accuracy: 0.6094\n",
      "Epoch 153/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3860 - accuracy: 0.8517 - val_loss: 0.9585 - val_accuracy: 0.6328\n",
      "Epoch 154/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3911 - accuracy: 0.8475 - val_loss: 0.9379 - val_accuracy: 0.6250\n",
      "Epoch 155/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.4021 - accuracy: 0.8464 - val_loss: 1.0001 - val_accuracy: 0.6367\n",
      "Epoch 156/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3474 - accuracy: 0.8772 - val_loss: 1.2732 - val_accuracy: 0.5898\n",
      "Epoch 157/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3852 - accuracy: 0.8601 - val_loss: 1.0557 - val_accuracy: 0.6641\n",
      "Epoch 158/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3736 - accuracy: 0.8587 - val_loss: 1.1271 - val_accuracy: 0.6328\n",
      "Epoch 159/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3645 - accuracy: 0.8582 - val_loss: 0.9257 - val_accuracy: 0.6445\n",
      "Epoch 160/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3717 - accuracy: 0.8529 - val_loss: 1.0563 - val_accuracy: 0.6094\n",
      "Epoch 161/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3679 - accuracy: 0.8551 - val_loss: 1.1030 - val_accuracy: 0.6445\n",
      "Epoch 162/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3499 - accuracy: 0.8646 - val_loss: 0.9426 - val_accuracy: 0.6328\n",
      "Epoch 163/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3360 - accuracy: 0.8737 - val_loss: 1.1923 - val_accuracy: 0.5938\n",
      "Epoch 164/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.3624 - accuracy: 0.8601 - val_loss: 1.0910 - val_accuracy: 0.6016\n",
      "Epoch 165/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3434 - accuracy: 0.8598 - val_loss: 0.9944 - val_accuracy: 0.6367\n",
      "Epoch 166/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3845 - accuracy: 0.8531 - val_loss: 1.0044 - val_accuracy: 0.6641\n",
      "Epoch 167/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.4616 - accuracy: 0.8186 - val_loss: 0.9979 - val_accuracy: 0.6602\n",
      "Epoch 168/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3832 - accuracy: 0.8565 - val_loss: 1.1356 - val_accuracy: 0.6484\n",
      "Epoch 169/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3488 - accuracy: 0.8696 - val_loss: 1.1681 - val_accuracy: 0.6328\n",
      "Epoch 170/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3518 - accuracy: 0.8685 - val_loss: 0.9563 - val_accuracy: 0.6680\n",
      "Epoch 171/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3256 - accuracy: 0.8688 - val_loss: 1.0910 - val_accuracy: 0.6289\n",
      "Epoch 172/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3522 - accuracy: 0.8765 - val_loss: 1.1935 - val_accuracy: 0.6211\n",
      "Epoch 173/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3600 - accuracy: 0.8651 - val_loss: 1.2791 - val_accuracy: 0.5781\n",
      "Epoch 174/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3429 - accuracy: 0.8721 - val_loss: 1.0182 - val_accuracy: 0.6523\n",
      "Epoch 175/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3680 - accuracy: 0.8603 - val_loss: 1.0148 - val_accuracy: 0.6602\n",
      "Epoch 176/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3336 - accuracy: 0.8736 - val_loss: 1.0020 - val_accuracy: 0.6562\n",
      "Epoch 177/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3450 - accuracy: 0.8748 - val_loss: 0.9734 - val_accuracy: 0.6484\n",
      "Epoch 178/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3730 - accuracy: 0.8638 - val_loss: 1.0448 - val_accuracy: 0.6602\n",
      "Epoch 179/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3339 - accuracy: 0.8695 - val_loss: 1.0458 - val_accuracy: 0.6602\n",
      "Epoch 180/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.3179 - accuracy: 0.8807 - val_loss: 0.9761 - val_accuracy: 0.6289\n",
      "Epoch 181/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3192 - accuracy: 0.8832 - val_loss: 2.1100 - val_accuracy: 0.5547\n",
      "Epoch 182/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.4287 - accuracy: 0.8341 - val_loss: 0.9548 - val_accuracy: 0.6133\n",
      "Epoch 183/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3096 - accuracy: 0.8841 - val_loss: 1.0108 - val_accuracy: 0.6328\n",
      "Epoch 184/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3151 - accuracy: 0.8948 - val_loss: 1.1180 - val_accuracy: 0.6289\n",
      "Epoch 185/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3200 - accuracy: 0.8715 - val_loss: 0.9644 - val_accuracy: 0.6523\n",
      "Epoch 186/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3293 - accuracy: 0.8813 - val_loss: 1.0605 - val_accuracy: 0.6250\n",
      "Epoch 187/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3028 - accuracy: 0.8918 - val_loss: 1.0086 - val_accuracy: 0.6758\n",
      "Epoch 188/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.2630 - accuracy: 0.8999 - val_loss: 1.0144 - val_accuracy: 0.6406\n",
      "Epoch 189/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3053 - accuracy: 0.8826 - val_loss: 1.0812 - val_accuracy: 0.6367\n",
      "Epoch 190/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3001 - accuracy: 0.8914 - val_loss: 1.2164 - val_accuracy: 0.5898\n",
      "Epoch 191/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3177 - accuracy: 0.8838 - val_loss: 0.9992 - val_accuracy: 0.6367\n",
      "Epoch 192/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3169 - accuracy: 0.8849 - val_loss: 0.9897 - val_accuracy: 0.6445\n",
      "Epoch 193/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3424 - accuracy: 0.8770 - val_loss: 0.9751 - val_accuracy: 0.6406\n",
      "Epoch 194/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2923 - accuracy: 0.8913 - val_loss: 1.0182 - val_accuracy: 0.6719\n",
      "Epoch 195/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3160 - accuracy: 0.8845 - val_loss: 0.9609 - val_accuracy: 0.6562\n",
      "Epoch 196/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3059 - accuracy: 0.8809 - val_loss: 0.9697 - val_accuracy: 0.6562\n",
      "Epoch 197/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3219 - accuracy: 0.8772 - val_loss: 1.2351 - val_accuracy: 0.6250\n",
      "Epoch 198/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2738 - accuracy: 0.8957 - val_loss: 1.1352 - val_accuracy: 0.6328\n",
      "Epoch 199/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2884 - accuracy: 0.8977 - val_loss: 1.0365 - val_accuracy: 0.6445\n",
      "Epoch 200/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2933 - accuracy: 0.8895 - val_loss: 1.0665 - val_accuracy: 0.6797\n",
      "Epoch 201/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3307 - accuracy: 0.8825 - val_loss: 1.0651 - val_accuracy: 0.6602\n",
      "Epoch 202/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3090 - accuracy: 0.8878 - val_loss: 1.1020 - val_accuracy: 0.6133\n",
      "Epoch 203/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.3054 - accuracy: 0.8872 - val_loss: 1.0491 - val_accuracy: 0.6250\n",
      "Epoch 204/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.2941 - accuracy: 0.8854 - val_loss: 1.4328 - val_accuracy: 0.6406\n",
      "Epoch 205/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3283 - accuracy: 0.8778 - val_loss: 1.0646 - val_accuracy: 0.6484\n",
      "Epoch 206/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2507 - accuracy: 0.9073 - val_loss: 0.9416 - val_accuracy: 0.6680\n",
      "Epoch 207/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3079 - accuracy: 0.8869 - val_loss: 1.1837 - val_accuracy: 0.6484\n",
      "Epoch 208/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3406 - accuracy: 0.8694 - val_loss: 1.2952 - val_accuracy: 0.6133\n",
      "Epoch 209/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2932 - accuracy: 0.8941 - val_loss: 1.0198 - val_accuracy: 0.6562\n",
      "Epoch 210/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2731 - accuracy: 0.8931 - val_loss: 1.0632 - val_accuracy: 0.6562\n",
      "Epoch 211/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2544 - accuracy: 0.8968 - val_loss: 0.9811 - val_accuracy: 0.6602\n",
      "Epoch 212/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2672 - accuracy: 0.8987 - val_loss: 1.3481 - val_accuracy: 0.5898\n",
      "Epoch 213/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2615 - accuracy: 0.9078 - val_loss: 1.0342 - val_accuracy: 0.6680\n",
      "Epoch 214/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.4084 - accuracy: 0.8560 - val_loss: 0.9958 - val_accuracy: 0.6914\n",
      "Epoch 215/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3901 - accuracy: 0.8618 - val_loss: 1.0286 - val_accuracy: 0.6602\n",
      "Epoch 216/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3260 - accuracy: 0.8792 - val_loss: 1.1866 - val_accuracy: 0.5938\n",
      "Epoch 217/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2862 - accuracy: 0.8957 - val_loss: 1.0018 - val_accuracy: 0.6680\n",
      "Epoch 218/4000\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.2928 - accuracy: 0.8869 - val_loss: 0.9555 - val_accuracy: 0.6719\n",
      "Epoch 219/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2735 - accuracy: 0.8968 - val_loss: 0.9242 - val_accuracy: 0.6758\n",
      "Epoch 220/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2651 - accuracy: 0.8969 - val_loss: 1.0316 - val_accuracy: 0.6094\n",
      "Epoch 221/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2567 - accuracy: 0.9014 - val_loss: 0.9866 - val_accuracy: 0.6680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2848 - accuracy: 0.8971 - val_loss: 1.1115 - val_accuracy: 0.6328\n",
      "Epoch 223/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2630 - accuracy: 0.9002 - val_loss: 1.0632 - val_accuracy: 0.6680\n",
      "Epoch 224/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2650 - accuracy: 0.9038 - val_loss: 1.0059 - val_accuracy: 0.6445\n",
      "Epoch 225/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.2698 - accuracy: 0.9074 - val_loss: 1.0265 - val_accuracy: 0.6797\n",
      "Epoch 226/4000\n",
      "128/128 [==============================] - 5s 37ms/step - loss: 0.2626 - accuracy: 0.9027 - val_loss: 1.0912 - val_accuracy: 0.6484\n",
      "Epoch 227/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2686 - accuracy: 0.8975 - val_loss: 1.2758 - val_accuracy: 0.6055\n",
      "Epoch 228/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.3039 - accuracy: 0.8865 - val_loss: 1.2490 - val_accuracy: 0.6094\n",
      "Epoch 229/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2835 - accuracy: 0.8910 - val_loss: 0.9909 - val_accuracy: 0.6602\n",
      "Epoch 230/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2597 - accuracy: 0.9053 - val_loss: 1.0854 - val_accuracy: 0.6914\n",
      "Epoch 231/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2804 - accuracy: 0.8984 - val_loss: 1.0351 - val_accuracy: 0.6445\n",
      "Epoch 232/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2445 - accuracy: 0.9084 - val_loss: 1.0438 - val_accuracy: 0.6719\n",
      "Epoch 233/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2398 - accuracy: 0.9114 - val_loss: 1.1275 - val_accuracy: 0.6406\n",
      "Epoch 234/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2619 - accuracy: 0.9015 - val_loss: 1.5236 - val_accuracy: 0.5938\n",
      "Epoch 235/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.3135 - accuracy: 0.8784 - val_loss: 1.7757 - val_accuracy: 0.5234\n",
      "Epoch 236/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2826 - accuracy: 0.8924 - val_loss: 1.1285 - val_accuracy: 0.6953\n",
      "Epoch 237/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2918 - accuracy: 0.8965 - val_loss: 1.0714 - val_accuracy: 0.6445\n",
      "Epoch 238/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.3194 - accuracy: 0.8800 - val_loss: 1.2169 - val_accuracy: 0.6484\n",
      "Epoch 239/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2432 - accuracy: 0.9089 - val_loss: 1.1912 - val_accuracy: 0.6719\n",
      "Epoch 240/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2488 - accuracy: 0.9032 - val_loss: 1.2999 - val_accuracy: 0.6172\n",
      "Epoch 241/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2861 - accuracy: 0.8943 - val_loss: 1.0793 - val_accuracy: 0.5977\n",
      "Epoch 242/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2443 - accuracy: 0.9090 - val_loss: 1.2031 - val_accuracy: 0.6133\n",
      "Epoch 243/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2357 - accuracy: 0.9141 - val_loss: 1.3219 - val_accuracy: 0.6328\n",
      "Epoch 244/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2514 - accuracy: 0.9075 - val_loss: 1.0227 - val_accuracy: 0.6445\n",
      "Epoch 245/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2472 - accuracy: 0.9052 - val_loss: 1.0085 - val_accuracy: 0.6367\n",
      "Epoch 246/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2590 - accuracy: 0.9038 - val_loss: 1.2508 - val_accuracy: 0.6055\n",
      "Epoch 247/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2324 - accuracy: 0.9142 - val_loss: 1.1245 - val_accuracy: 0.6602\n",
      "Epoch 248/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2444 - accuracy: 0.9142 - val_loss: 1.0557 - val_accuracy: 0.6289\n",
      "Epoch 249/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2556 - accuracy: 0.9089 - val_loss: 1.0735 - val_accuracy: 0.6680\n",
      "Epoch 250/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2799 - accuracy: 0.8961 - val_loss: 1.0657 - val_accuracy: 0.6680\n",
      "Epoch 251/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2567 - accuracy: 0.9040 - val_loss: 1.1056 - val_accuracy: 0.6836\n",
      "Epoch 252/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2439 - accuracy: 0.9101 - val_loss: 1.0193 - val_accuracy: 0.6797\n",
      "Epoch 253/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2185 - accuracy: 0.9228 - val_loss: 1.1307 - val_accuracy: 0.6367\n",
      "Epoch 254/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2504 - accuracy: 0.9050 - val_loss: 1.1927 - val_accuracy: 0.6562\n",
      "Epoch 255/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2459 - accuracy: 0.9109 - val_loss: 1.1923 - val_accuracy: 0.6523\n",
      "Epoch 256/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2651 - accuracy: 0.9008 - val_loss: 1.2802 - val_accuracy: 0.6484\n",
      "Epoch 257/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2259 - accuracy: 0.9174 - val_loss: 1.1062 - val_accuracy: 0.6484\n",
      "Epoch 258/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2277 - accuracy: 0.9212 - val_loss: 1.0601 - val_accuracy: 0.6758\n",
      "Epoch 259/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2317 - accuracy: 0.9214 - val_loss: 1.1132 - val_accuracy: 0.6602\n",
      "Epoch 260/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2449 - accuracy: 0.9077 - val_loss: 1.3493 - val_accuracy: 0.5859\n",
      "Epoch 261/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2446 - accuracy: 0.9027 - val_loss: 1.0073 - val_accuracy: 0.6797\n",
      "Epoch 262/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2347 - accuracy: 0.9102 - val_loss: 1.1415 - val_accuracy: 0.6602\n",
      "Epoch 263/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2406 - accuracy: 0.9179 - val_loss: 1.1824 - val_accuracy: 0.6562\n",
      "Epoch 264/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2325 - accuracy: 0.9141 - val_loss: 1.5023 - val_accuracy: 0.6250\n",
      "Epoch 265/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2410 - accuracy: 0.9167 - val_loss: 1.0554 - val_accuracy: 0.6719\n",
      "Epoch 266/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2383 - accuracy: 0.9099 - val_loss: 1.2009 - val_accuracy: 0.6680\n",
      "Epoch 267/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2272 - accuracy: 0.9157 - val_loss: 1.1193 - val_accuracy: 0.6797\n",
      "Epoch 268/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2437 - accuracy: 0.9027 - val_loss: 0.9293 - val_accuracy: 0.6992\n",
      "Epoch 269/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2069 - accuracy: 0.9201 - val_loss: 1.2654 - val_accuracy: 0.6523\n",
      "Epoch 270/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2163 - accuracy: 0.9217 - val_loss: 1.2775 - val_accuracy: 0.6328\n",
      "Epoch 271/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2318 - accuracy: 0.9150 - val_loss: 1.1933 - val_accuracy: 0.6523\n",
      "Epoch 272/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2471 - accuracy: 0.9077 - val_loss: 1.0744 - val_accuracy: 0.6680\n",
      "Epoch 273/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.1937 - accuracy: 0.9290 - val_loss: 1.0697 - val_accuracy: 0.6602\n",
      "Epoch 274/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2279 - accuracy: 0.9142 - val_loss: 1.0121 - val_accuracy: 0.6875\n",
      "Epoch 275/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2049 - accuracy: 0.9259 - val_loss: 1.1554 - val_accuracy: 0.6641\n",
      "Epoch 276/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2176 - accuracy: 0.9202 - val_loss: 1.0381 - val_accuracy: 0.6953\n",
      "Epoch 277/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2151 - accuracy: 0.9139 - val_loss: 1.1425 - val_accuracy: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.1986 - accuracy: 0.9264 - val_loss: 1.3424 - val_accuracy: 0.6523\n",
      "Epoch 279/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2297 - accuracy: 0.9177 - val_loss: 1.3347 - val_accuracy: 0.6172\n",
      "Epoch 280/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2343 - accuracy: 0.9150 - val_loss: 1.0809 - val_accuracy: 0.6797\n",
      "Epoch 281/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2106 - accuracy: 0.9265 - val_loss: 1.2251 - val_accuracy: 0.6367\n",
      "Epoch 282/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2118 - accuracy: 0.9267 - val_loss: 1.1058 - val_accuracy: 0.6680\n",
      "Epoch 283/4000\n",
      "128/128 [==============================] - 5s 39ms/step - loss: 0.2229 - accuracy: 0.9183 - val_loss: 1.0543 - val_accuracy: 0.6289\n",
      "Epoch 284/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.1978 - accuracy: 0.9277 - val_loss: 1.1255 - val_accuracy: 0.6445\n",
      "Epoch 285/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2102 - accuracy: 0.9231 - val_loss: 1.3023 - val_accuracy: 0.6602\n",
      "Epoch 286/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2298 - accuracy: 0.9192 - val_loss: 1.3064 - val_accuracy: 0.6289\n",
      "Epoch 287/4000\n",
      "128/128 [==============================] - 5s 38ms/step - loss: 0.2306 - accuracy: 0.9205 - val_loss: 1.1717 - val_accuracy: 0.6641\n",
      "Epoch 288/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2230 - accuracy: 0.9249 - val_loss: 1.2393 - val_accuracy: 0.6719\n",
      "Epoch 289/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.2255 - accuracy: 0.9191 - val_loss: 1.1783 - val_accuracy: 0.6602\n",
      "Epoch 290/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2290 - accuracy: 0.9182 - val_loss: 1.1867 - val_accuracy: 0.6953\n",
      "Epoch 291/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2174 - accuracy: 0.9265 - val_loss: 1.2892 - val_accuracy: 0.6445\n",
      "Epoch 292/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2071 - accuracy: 0.9188 - val_loss: 1.1908 - val_accuracy: 0.6328\n",
      "Epoch 293/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2163 - accuracy: 0.9231 - val_loss: 1.2545 - val_accuracy: 0.6406\n",
      "Epoch 294/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2412 - accuracy: 0.9105 - val_loss: 1.2391 - val_accuracy: 0.6211\n",
      "Epoch 295/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.1981 - accuracy: 0.9269 - val_loss: 1.1979 - val_accuracy: 0.6484\n",
      "Epoch 296/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2121 - accuracy: 0.9211 - val_loss: 1.3982 - val_accuracy: 0.6562\n",
      "Epoch 297/4000\n",
      "128/128 [==============================] - 5s 41ms/step - loss: 0.2383 - accuracy: 0.9117 - val_loss: 1.2223 - val_accuracy: 0.6914\n",
      "Epoch 298/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2155 - accuracy: 0.9219 - val_loss: 1.2268 - val_accuracy: 0.6484\n",
      "Epoch 299/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1960 - accuracy: 0.9288 - val_loss: 1.3196 - val_accuracy: 0.6680\n",
      "Epoch 300/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2370 - accuracy: 0.9074 - val_loss: 1.3062 - val_accuracy: 0.6641\n",
      "Epoch 301/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2121 - accuracy: 0.9244 - val_loss: 1.1075 - val_accuracy: 0.6406\n",
      "Epoch 302/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1887 - accuracy: 0.9299 - val_loss: 1.2391 - val_accuracy: 0.6719\n",
      "Epoch 303/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2043 - accuracy: 0.9230 - val_loss: 1.2239 - val_accuracy: 0.6719\n",
      "Epoch 304/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1862 - accuracy: 0.9310 - val_loss: 1.1300 - val_accuracy: 0.6758\n",
      "Epoch 305/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2130 - accuracy: 0.9193 - val_loss: 1.2554 - val_accuracy: 0.6406\n",
      "Epoch 306/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1929 - accuracy: 0.9308 - val_loss: 1.1794 - val_accuracy: 0.6484\n",
      "Epoch 307/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2089 - accuracy: 0.9227 - val_loss: 1.2154 - val_accuracy: 0.6602\n",
      "Epoch 308/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1725 - accuracy: 0.9401 - val_loss: 1.3033 - val_accuracy: 0.6602\n",
      "Epoch 309/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1948 - accuracy: 0.9293 - val_loss: 1.1869 - val_accuracy: 0.6719\n",
      "Epoch 310/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1861 - accuracy: 0.9394 - val_loss: 1.4880 - val_accuracy: 0.6016\n",
      "Epoch 311/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.3028 - accuracy: 0.8919 - val_loss: 1.4160 - val_accuracy: 0.6250\n",
      "Epoch 312/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2964 - accuracy: 0.8936 - val_loss: 1.1736 - val_accuracy: 0.6562\n",
      "Epoch 313/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2488 - accuracy: 0.9095 - val_loss: 1.3666 - val_accuracy: 0.6016\n",
      "Epoch 314/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2280 - accuracy: 0.9196 - val_loss: 1.1546 - val_accuracy: 0.6445\n",
      "Epoch 315/4000\n",
      "128/128 [==============================] - 5s 40ms/step - loss: 0.1736 - accuracy: 0.9355 - val_loss: 1.2842 - val_accuracy: 0.6406\n",
      "Epoch 316/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.2073 - accuracy: 0.9271 - val_loss: 1.2175 - val_accuracy: 0.6680\n",
      "Epoch 317/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1879 - accuracy: 0.9360 - val_loss: 1.1209 - val_accuracy: 0.6445\n",
      "Epoch 318/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1702 - accuracy: 0.9352 - val_loss: 1.2842 - val_accuracy: 0.6445\n",
      "Epoch 319/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1729 - accuracy: 0.9397 - val_loss: 1.1024 - val_accuracy: 0.6719\n",
      "Epoch 320/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1875 - accuracy: 0.9342 - val_loss: 1.1931 - val_accuracy: 0.6562\n",
      "Epoch 321/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1928 - accuracy: 0.9268 - val_loss: 1.3313 - val_accuracy: 0.6484\n",
      "Epoch 322/4000\n",
      "128/128 [==============================] - 5s 43ms/step - loss: 0.1739 - accuracy: 0.9378 - val_loss: 1.1881 - val_accuracy: 0.6445\n",
      "Epoch 323/4000\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.1705 - accuracy: 0.9413 - val_loss: 1.3323 - val_accuracy: 0.6602\n",
      "Epoch 324/4000\n",
      "128/128 [==============================] - 5s 43ms/step - loss: 0.1792 - accuracy: 0.9392 - val_loss: 1.3110 - val_accuracy: 0.6562\n",
      "Epoch 325/4000\n",
      "128/128 [==============================] - 5s 43ms/step - loss: 0.1913 - accuracy: 0.9339 - val_loss: 1.3118 - val_accuracy: 0.6523\n",
      "Epoch 326/4000\n",
      "128/128 [==============================] - 5s 43ms/step - loss: 0.1918 - accuracy: 0.9282 - val_loss: 1.3220 - val_accuracy: 0.6523\n",
      "Epoch 327/4000\n",
      "128/128 [==============================] - 5s 43ms/step - loss: 0.1794 - accuracy: 0.9427 - val_loss: 1.0648 - val_accuracy: 0.6875\n",
      "Epoch 328/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.2025 - accuracy: 0.9243 - val_loss: 1.3677 - val_accuracy: 0.6602\n",
      "Epoch 329/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.2226 - accuracy: 0.9136 - val_loss: 1.3347 - val_accuracy: 0.6133\n",
      "Epoch 330/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.2105 - accuracy: 0.9220 - val_loss: 1.2703 - val_accuracy: 0.6797\n",
      "Epoch 331/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1974 - accuracy: 0.9318 - val_loss: 1.2393 - val_accuracy: 0.6562\n",
      "Epoch 332/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1812 - accuracy: 0.9334 - val_loss: 1.2952 - val_accuracy: 0.6641\n",
      "Epoch 333/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1679 - accuracy: 0.9344 - val_loss: 1.4970 - val_accuracy: 0.6602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1816 - accuracy: 0.9320 - val_loss: 1.6603 - val_accuracy: 0.6055\n",
      "Epoch 335/4000\n",
      "128/128 [==============================] - 5s 43ms/step - loss: 0.2836 - accuracy: 0.9011 - val_loss: 1.2559 - val_accuracy: 0.6641\n",
      "Epoch 336/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.2240 - accuracy: 0.9193 - val_loss: 1.1997 - val_accuracy: 0.6367\n",
      "Epoch 337/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.2131 - accuracy: 0.9215 - val_loss: 1.3615 - val_accuracy: 0.6758\n",
      "Epoch 338/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1873 - accuracy: 0.9321 - val_loss: 1.2555 - val_accuracy: 0.6641\n",
      "Epoch 339/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.2224 - accuracy: 0.9196 - val_loss: 1.2678 - val_accuracy: 0.6367\n",
      "Epoch 340/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.1889 - accuracy: 0.9321 - val_loss: 1.2568 - val_accuracy: 0.6719\n",
      "Epoch 341/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.1892 - accuracy: 0.9326 - val_loss: 1.1247 - val_accuracy: 0.6367\n",
      "Epoch 342/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1999 - accuracy: 0.9295 - val_loss: 1.0217 - val_accuracy: 0.6758\n",
      "Epoch 343/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1714 - accuracy: 0.9351 - val_loss: 1.0907 - val_accuracy: 0.6719\n",
      "Epoch 344/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 0.1868 - accuracy: 0.9365 - val_loss: 1.2246 - val_accuracy: 0.6641\n",
      "Epoch 345/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.1541 - accuracy: 0.9438 - val_loss: 1.3085 - val_accuracy: 0.6719\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00345: early stopping\n",
      "128/128 [==============================] - 5s 42ms/step - loss: 0.8017 - accuracy: 0.6519\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.7969 - accuracy: 0.6641\n",
      "Train: 0.652, Val: 0.664\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit model\n",
    "history = test_model.fit(training_set,\n",
    "        epochs=4000,\n",
    "        validation_data=val_set,\n",
    "        verbose = 1, \n",
    "        validation_steps = len(val_set),\n",
    "        callbacks = [es])\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = test_model.evaluate(training_set, verbose=1)\n",
    "_, val_acc = test_model.evaluate(val_set, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#saves model\n",
    "test_model.save(r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Models\\test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 1s 5ms/step - loss: 0.7697 - accuracy: 0.6848\n",
      "Test loss: 0.7696863412857056\n",
      "Test accuracy: 0.6848248839378357\n"
     ]
    }
   ],
   "source": [
    "#Performance do primeiro teste\n",
    "\n",
    "test_loss, test_acc = test_model.evaluate(test_set)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 128)   36992     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 8,429,956\n",
      "Trainable params: 8,428,868\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Summary\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = test_model.predict(test_set,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "# get names of pictures\n",
    "filenames = test_set.filenames\n",
    "\n",
    "#get trueclass\n",
    "true_classes = test_set.classes\n",
    "\n",
    "#store info in dataframe\n",
    "df_predictions = pd.DataFrame({'Filename': filenames, 'Label': true_classes, 'Test': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample3-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample4-sperm15.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm17.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm2.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>class3\\image_036.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>class3\\image_038.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>class3\\image_040.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>class3\\image_048.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>class3\\image_051.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     0\n",
       "1     class0\\ch00_p1-pl2-sample3-sperm4.tif      0     1\n",
       "2    class0\\ch00_p1-pl2-sample4-sperm15.tif      0     3\n",
       "3    class0\\ch00_p1-pl3-sample1-sperm17.tif      0     3\n",
       "4     class0\\ch00_p1-pl3-sample1-sperm2.tif      0     3\n",
       "..                                      ...    ...   ...\n",
       "252                    class3\\image_036.BMP      3     3\n",
       "253                    class3\\image_038.BMP      3     2\n",
       "254                    class3\\image_040.BMP      3     2\n",
       "255                    class3\\image_048.BMP      3     3\n",
       "256                    class3\\image_051.BMP      3     3\n",
       "\n",
       "[257 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  7 18]\n",
      " [ 3  8 13 33]\n",
      " [ 2  6  2 17]\n",
      " [25 27 12 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.06      0.06      0.06        31\n",
      "      class1       0.18      0.14      0.16        57\n",
      "      class2       0.06      0.07      0.07        27\n",
      "      class3       0.53      0.55      0.54       142\n",
      "\n",
      "    accuracy                           0.35       257\n",
      "   macro avg       0.21      0.21      0.21       257\n",
      "weighted avg       0.35      0.35      0.35       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix and classification report\n",
    "class_labels = list(test_set.class_indices.keys())   \n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Design a More Complex and Robust Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_cnn_standard_model():\n",
    "    '''creates an image classification model that uses Convolutional CNNs layers (with maxpooling) and feeds the data through\n",
    "    a dense connected layer. This is trial and error there is no specific reason for 2 layers'''\n",
    "    cnn_model = keras.Sequential([\n",
    "\n",
    "        #convolutional layer with 32 3x3 filters - again, arbitrary,\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding = 'same', activation='relu'), \n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #MaxPooling - takes the max value of each 2x2 pool in the feature map\n",
    "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #3rd convolution with 64 filters\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(3,3),  padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #4rd convolution with 128 filters\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #Second MaxPool2D - to check with other options\n",
    "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #5th convolutional layer with 24 3x3 filters - again, arbitrary,\n",
    "        keras.layers.Conv2D(filters=32, kernel_size=(4,4), padding = 'same', activation='relu'), \n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #MaxPooling - takes the max value of each 2x2 pool in the feature map\n",
    "        #keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        #second convolution with 36 filters\n",
    "        keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #Second MaxPool2D - to check with other options\n",
    "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #convolutional layer with 24 3x3 filters - again, arbitrary,\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=(4,4), padding = 'same', activation='relu'), \n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "\n",
    "        #second convolution with 36 filters\n",
    "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation= 'relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #Second MaxPool2D - to check with other options\n",
    "        keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        #the result of kthe CNN is then flattened and placed into the \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        #Add Dropout\n",
    "        keras.layers.Dropout(0.4),\n",
    "        \n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        #final layer, is output, 1 out of 5 possible results\n",
    "        #0 Normal, 1 Tapered, 2 Pyriform, 3 Amorphous\n",
    "        keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model: First try\n",
    "cnn_model = image_cnn_standard_model()\n",
    "\n",
    "cnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "128/128 [==============================] - 8s 46ms/step - loss: 1.6785 - accuracy: 0.2913 - val_loss: 1.4715 - val_accuracy: 0.1055\n",
      "Epoch 2/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.4596 - accuracy: 0.2944 - val_loss: 1.2299 - val_accuracy: 0.5547\n",
      "Epoch 3/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.4034 - accuracy: 0.3403 - val_loss: 1.3733 - val_accuracy: 0.2070\n",
      "Epoch 4/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.3644 - accuracy: 0.3613 - val_loss: 1.6543 - val_accuracy: 0.1250\n",
      "Epoch 5/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 1.3119 - accuracy: 0.3721 - val_loss: 1.3994 - val_accuracy: 0.2969\n",
      "Epoch 6/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 1.3065 - accuracy: 0.3952 - val_loss: 1.2265 - val_accuracy: 0.4492\n",
      "Epoch 7/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 1.2293 - accuracy: 0.4397 - val_loss: 1.0954 - val_accuracy: 0.5781\n",
      "Epoch 8/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.2234 - accuracy: 0.4398 - val_loss: 1.4513 - val_accuracy: 0.1992\n",
      "Epoch 9/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 1.2062 - accuracy: 0.4453 - val_loss: 1.3875 - val_accuracy: 0.3438\n",
      "Epoch 10/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.1947 - accuracy: 0.4401 - val_loss: 1.3719 - val_accuracy: 0.3359\n",
      "Epoch 11/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.1526 - accuracy: 0.4747 - val_loss: 1.2177 - val_accuracy: 0.3711\n",
      "Epoch 12/4000\n",
      "128/128 [==============================] - 6s 43ms/step - loss: 1.1388 - accuracy: 0.4780 - val_loss: 1.4435 - val_accuracy: 0.3945\n",
      "Epoch 13/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.1116 - accuracy: 0.5166 - val_loss: 1.1780 - val_accuracy: 0.3516\n",
      "Epoch 14/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.0537 - accuracy: 0.5406 - val_loss: 1.1215 - val_accuracy: 0.4688\n",
      "Epoch 15/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.0358 - accuracy: 0.5433 - val_loss: 1.1411 - val_accuracy: 0.4492\n",
      "Epoch 16/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.0076 - accuracy: 0.5658 - val_loss: 1.1705 - val_accuracy: 0.4297\n",
      "Epoch 17/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 1.0151 - accuracy: 0.5650 - val_loss: 1.1227 - val_accuracy: 0.4727\n",
      "Epoch 18/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.9677 - accuracy: 0.5857 - val_loss: 1.0367 - val_accuracy: 0.5078\n",
      "Epoch 19/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.9440 - accuracy: 0.6039 - val_loss: 1.0589 - val_accuracy: 0.4492\n",
      "Epoch 20/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.9187 - accuracy: 0.6176 - val_loss: 1.2731 - val_accuracy: 0.4062\n",
      "Epoch 21/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.9267 - accuracy: 0.6019 - val_loss: 1.0444 - val_accuracy: 0.4883\n",
      "Epoch 22/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.8828 - accuracy: 0.6294 - val_loss: 1.2173 - val_accuracy: 0.3789\n",
      "Epoch 23/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.8764 - accuracy: 0.6318 - val_loss: 1.2412 - val_accuracy: 0.3672\n",
      "Epoch 24/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.8547 - accuracy: 0.6334 - val_loss: 0.9744 - val_accuracy: 0.5586\n",
      "Epoch 25/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.8118 - accuracy: 0.6542 - val_loss: 0.9795 - val_accuracy: 0.5039\n",
      "Epoch 26/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.8179 - accuracy: 0.6613 - val_loss: 0.9819 - val_accuracy: 0.5508\n",
      "Epoch 27/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.8135 - accuracy: 0.6485 - val_loss: 0.8851 - val_accuracy: 0.5391\n",
      "Epoch 28/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.8097 - accuracy: 0.6551 - val_loss: 1.1129 - val_accuracy: 0.5000\n",
      "Epoch 29/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.8002 - accuracy: 0.6698 - val_loss: 0.9208 - val_accuracy: 0.5508\n",
      "Epoch 30/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.7574 - accuracy: 0.6953 - val_loss: 0.9868 - val_accuracy: 0.5469\n",
      "Epoch 31/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.7768 - accuracy: 0.6850 - val_loss: 1.4701 - val_accuracy: 0.3711\n",
      "Epoch 32/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.7345 - accuracy: 0.7007 - val_loss: 1.1091 - val_accuracy: 0.4609\n",
      "Epoch 33/4000\n",
      "128/128 [==============================] - 6s 44ms/step - loss: 0.6984 - accuracy: 0.7210 - val_loss: 1.1055 - val_accuracy: 0.4570\n",
      "Epoch 34/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.7264 - accuracy: 0.7003 - val_loss: 1.0322 - val_accuracy: 0.5156\n",
      "Epoch 35/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.7133 - accuracy: 0.7089 - val_loss: 0.9775 - val_accuracy: 0.5625\n",
      "Epoch 36/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6771 - accuracy: 0.7279 - val_loss: 0.9602 - val_accuracy: 0.5664\n",
      "Epoch 37/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6926 - accuracy: 0.7073 - val_loss: 1.3674 - val_accuracy: 0.4102\n",
      "Epoch 38/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6646 - accuracy: 0.7227 - val_loss: 0.9219 - val_accuracy: 0.6055\n",
      "Epoch 39/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6921 - accuracy: 0.7203 - val_loss: 1.0054 - val_accuracy: 0.5430\n",
      "Epoch 40/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6476 - accuracy: 0.7340 - val_loss: 0.8668 - val_accuracy: 0.6250\n",
      "Epoch 41/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6286 - accuracy: 0.7519 - val_loss: 0.8610 - val_accuracy: 0.6133\n",
      "Epoch 42/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6359 - accuracy: 0.7384 - val_loss: 0.8270 - val_accuracy: 0.6367\n",
      "Epoch 43/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6059 - accuracy: 0.7594 - val_loss: 0.9151 - val_accuracy: 0.5508\n",
      "Epoch 44/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.6157 - accuracy: 0.7553 - val_loss: 0.9251 - val_accuracy: 0.6016\n",
      "Epoch 45/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6479 - accuracy: 0.7459 - val_loss: 0.9603 - val_accuracy: 0.5820\n",
      "Epoch 46/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.6061 - accuracy: 0.7553 - val_loss: 0.9454 - val_accuracy: 0.5586\n",
      "Epoch 47/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.5933 - accuracy: 0.7766 - val_loss: 1.4143 - val_accuracy: 0.4766\n",
      "Epoch 48/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.5766 - accuracy: 0.7795 - val_loss: 0.9404 - val_accuracy: 0.5547\n",
      "Epoch 49/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.5691 - accuracy: 0.7774 - val_loss: 1.0161 - val_accuracy: 0.5430\n",
      "Epoch 50/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.5713 - accuracy: 0.7770 - val_loss: 0.8715 - val_accuracy: 0.6523\n",
      "Epoch 51/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.5514 - accuracy: 0.7896 - val_loss: 0.8329 - val_accuracy: 0.6289\n",
      "Epoch 52/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.5280 - accuracy: 0.7971 - val_loss: 1.0696 - val_accuracy: 0.5898\n",
      "Epoch 53/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.5467 - accuracy: 0.7998 - val_loss: 1.0340 - val_accuracy: 0.5742\n",
      "Epoch 54/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.5829 - accuracy: 0.7708 - val_loss: 1.1092 - val_accuracy: 0.5703\n",
      "Epoch 55/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.4996 - accuracy: 0.8017 - val_loss: 1.0012 - val_accuracy: 0.5859\n",
      "Epoch 56/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.5060 - accuracy: 0.8072 - val_loss: 1.1502 - val_accuracy: 0.5547\n",
      "Epoch 57/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.4961 - accuracy: 0.8080 - val_loss: 1.0453 - val_accuracy: 0.5469\n",
      "Epoch 58/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.5051 - accuracy: 0.8009 - val_loss: 1.0475 - val_accuracy: 0.5664\n",
      "Epoch 59/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.4860 - accuracy: 0.8155 - val_loss: 1.0827 - val_accuracy: 0.5586\n",
      "Epoch 60/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.4551 - accuracy: 0.8168 - val_loss: 1.2678 - val_accuracy: 0.5391\n",
      "Epoch 61/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.4694 - accuracy: 0.8260 - val_loss: 1.0452 - val_accuracy: 0.5742\n",
      "Epoch 62/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.4899 - accuracy: 0.8097 - val_loss: 1.0120 - val_accuracy: 0.5820\n",
      "Epoch 63/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.4662 - accuracy: 0.8235 - val_loss: 1.1193 - val_accuracy: 0.6055\n",
      "Epoch 64/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.4229 - accuracy: 0.8401 - val_loss: 0.8849 - val_accuracy: 0.6602\n",
      "Epoch 65/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.4301 - accuracy: 0.8303 - val_loss: 0.9989 - val_accuracy: 0.5938\n",
      "Epoch 66/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.4861 - accuracy: 0.8130 - val_loss: 0.9190 - val_accuracy: 0.6641\n",
      "Epoch 67/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.4289 - accuracy: 0.8400 - val_loss: 1.0496 - val_accuracy: 0.5781\n",
      "Epoch 68/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.4340 - accuracy: 0.8342 - val_loss: 0.9117 - val_accuracy: 0.6328\n",
      "Epoch 69/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.4170 - accuracy: 0.8380 - val_loss: 1.1000 - val_accuracy: 0.6055\n",
      "Epoch 70/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3871 - accuracy: 0.8528 - val_loss: 0.9588 - val_accuracy: 0.6641\n",
      "Epoch 71/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3861 - accuracy: 0.8474 - val_loss: 1.0081 - val_accuracy: 0.5938\n",
      "Epoch 72/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.4128 - accuracy: 0.8497 - val_loss: 1.0593 - val_accuracy: 0.6914\n",
      "Epoch 73/4000\n",
      "128/128 [==============================] - 6s 45ms/step - loss: 0.3873 - accuracy: 0.8577 - val_loss: 1.0795 - val_accuracy: 0.6172\n",
      "Epoch 74/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.4139 - accuracy: 0.8467 - val_loss: 1.0764 - val_accuracy: 0.6094\n",
      "Epoch 75/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3851 - accuracy: 0.8584 - val_loss: 1.0944 - val_accuracy: 0.5625\n",
      "Epoch 76/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3547 - accuracy: 0.8683 - val_loss: 0.9112 - val_accuracy: 0.6484\n",
      "Epoch 77/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3812 - accuracy: 0.8590 - val_loss: 1.0815 - val_accuracy: 0.5977\n",
      "Epoch 78/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3580 - accuracy: 0.8655 - val_loss: 1.1295 - val_accuracy: 0.6406\n",
      "Epoch 79/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3209 - accuracy: 0.8838 - val_loss: 1.0989 - val_accuracy: 0.6484\n",
      "Epoch 80/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.3265 - accuracy: 0.8833 - val_loss: 1.3226 - val_accuracy: 0.6484\n",
      "Epoch 81/4000\n",
      "128/128 [==============================] - 6s 46ms/step - loss: 0.3489 - accuracy: 0.8789 - val_loss: 1.0293 - val_accuracy: 0.6172\n",
      "Epoch 82/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3357 - accuracy: 0.8784 - val_loss: 0.9985 - val_accuracy: 0.6836\n",
      "Epoch 83/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3169 - accuracy: 0.8795 - val_loss: 1.2074 - val_accuracy: 0.6562\n",
      "Epoch 84/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3628 - accuracy: 0.8613 - val_loss: 1.0829 - val_accuracy: 0.6406\n",
      "Epoch 85/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.3032 - accuracy: 0.8945 - val_loss: 1.0662 - val_accuracy: 0.6484\n",
      "Epoch 86/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2880 - accuracy: 0.8928 - val_loss: 0.9887 - val_accuracy: 0.6719\n",
      "Epoch 87/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.3003 - accuracy: 0.8910 - val_loss: 1.0847 - val_accuracy: 0.6328\n",
      "Epoch 88/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.3265 - accuracy: 0.8800 - val_loss: 1.2247 - val_accuracy: 0.6484\n",
      "Epoch 89/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.2912 - accuracy: 0.8919 - val_loss: 1.0012 - val_accuracy: 0.6367\n",
      "Epoch 90/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.3029 - accuracy: 0.8907 - val_loss: 1.0386 - val_accuracy: 0.6133\n",
      "Epoch 91/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.3104 - accuracy: 0.8898 - val_loss: 1.1771 - val_accuracy: 0.6289\n",
      "Epoch 92/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2738 - accuracy: 0.8995 - val_loss: 1.0702 - val_accuracy: 0.6289\n",
      "Epoch 93/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2885 - accuracy: 0.8996 - val_loss: 0.9886 - val_accuracy: 0.6992\n",
      "Epoch 94/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2492 - accuracy: 0.9093 - val_loss: 1.1090 - val_accuracy: 0.6797\n",
      "Epoch 95/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2979 - accuracy: 0.8939 - val_loss: 1.0396 - val_accuracy: 0.6875\n",
      "Epoch 96/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2872 - accuracy: 0.8969 - val_loss: 1.2168 - val_accuracy: 0.5977\n",
      "Epoch 97/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2512 - accuracy: 0.9095 - val_loss: 1.0424 - val_accuracy: 0.6797\n",
      "Epoch 98/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.2637 - accuracy: 0.9053 - val_loss: 1.2525 - val_accuracy: 0.6289\n",
      "Epoch 99/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2607 - accuracy: 0.8989 - val_loss: 1.0992 - val_accuracy: 0.6836\n",
      "Epoch 100/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2968 - accuracy: 0.8891 - val_loss: 1.1502 - val_accuracy: 0.6562\n",
      "Epoch 101/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2498 - accuracy: 0.9065 - val_loss: 1.1004 - val_accuracy: 0.6523\n",
      "Epoch 102/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2163 - accuracy: 0.9161 - val_loss: 1.1735 - val_accuracy: 0.6680\n",
      "Epoch 103/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.2308 - accuracy: 0.9201 - val_loss: 1.0997 - val_accuracy: 0.6797\n",
      "Epoch 104/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.2253 - accuracy: 0.9200 - val_loss: 1.1073 - val_accuracy: 0.7070\n",
      "Epoch 105/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.2217 - accuracy: 0.9179 - val_loss: 1.2050 - val_accuracy: 0.6172\n",
      "Epoch 106/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2258 - accuracy: 0.9171 - val_loss: 1.1891 - val_accuracy: 0.6914\n",
      "Epoch 107/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2666 - accuracy: 0.9071 - val_loss: 1.1967 - val_accuracy: 0.6719\n",
      "Epoch 108/4000\n",
      "128/128 [==============================] - 6s 47ms/step - loss: 0.2548 - accuracy: 0.9128 - val_loss: 1.2558 - val_accuracy: 0.6211\n",
      "Epoch 109/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2290 - accuracy: 0.9246 - val_loss: 1.2024 - val_accuracy: 0.6289\n",
      "Epoch 110/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2431 - accuracy: 0.9087 - val_loss: 1.1477 - val_accuracy: 0.6641\n",
      "Epoch 111/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2263 - accuracy: 0.9254 - val_loss: 1.1909 - val_accuracy: 0.6641\n",
      "Epoch 112/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2302 - accuracy: 0.9195 - val_loss: 1.2761 - val_accuracy: 0.6562\n",
      "Epoch 113/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2372 - accuracy: 0.9148 - val_loss: 1.1386 - val_accuracy: 0.6445\n",
      "Epoch 114/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2272 - accuracy: 0.9198 - val_loss: 1.3267 - val_accuracy: 0.6875\n",
      "Epoch 115/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2090 - accuracy: 0.9261 - val_loss: 1.2201 - val_accuracy: 0.6602\n",
      "Epoch 116/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1877 - accuracy: 0.9327 - val_loss: 1.1836 - val_accuracy: 0.6445\n",
      "Epoch 117/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2209 - accuracy: 0.9223 - val_loss: 1.3581 - val_accuracy: 0.6367\n",
      "Epoch 118/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.2496 - accuracy: 0.9122 - val_loss: 1.1152 - val_accuracy: 0.6719\n",
      "Epoch 119/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.2067 - accuracy: 0.9205 - val_loss: 1.1163 - val_accuracy: 0.6719\n",
      "Epoch 120/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2189 - accuracy: 0.9274 - val_loss: 1.1947 - val_accuracy: 0.6562\n",
      "Epoch 121/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2142 - accuracy: 0.9338 - val_loss: 1.1261 - val_accuracy: 0.6875\n",
      "Epoch 122/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.2079 - accuracy: 0.9259 - val_loss: 1.1036 - val_accuracy: 0.6719\n",
      "Epoch 123/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2114 - accuracy: 0.9253 - val_loss: 1.3040 - val_accuracy: 0.6328\n",
      "Epoch 124/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1618 - accuracy: 0.9449 - val_loss: 1.2693 - val_accuracy: 0.6445\n",
      "Epoch 125/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1995 - accuracy: 0.9299 - val_loss: 1.1327 - val_accuracy: 0.6992\n",
      "Epoch 126/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1913 - accuracy: 0.9309 - val_loss: 1.1775 - val_accuracy: 0.6836\n",
      "Epoch 127/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1699 - accuracy: 0.9404 - val_loss: 1.2677 - val_accuracy: 0.6797\n",
      "Epoch 128/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1847 - accuracy: 0.9336 - val_loss: 1.1357 - val_accuracy: 0.6719\n",
      "Epoch 129/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1926 - accuracy: 0.9291 - val_loss: 1.0527 - val_accuracy: 0.6914\n",
      "Epoch 130/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1903 - accuracy: 0.9386 - val_loss: 1.3954 - val_accuracy: 0.6484\n",
      "Epoch 131/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.2016 - accuracy: 0.9298 - val_loss: 1.2834 - val_accuracy: 0.6641\n",
      "Epoch 132/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1632 - accuracy: 0.9404 - val_loss: 1.3484 - val_accuracy: 0.6797\n",
      "Epoch 133/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.1866 - accuracy: 0.9377 - val_loss: 1.4397 - val_accuracy: 0.6758\n",
      "Epoch 134/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1618 - accuracy: 0.9425 - val_loss: 1.5389 - val_accuracy: 0.6250\n",
      "Epoch 135/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.1610 - accuracy: 0.9410 - val_loss: 1.3830 - val_accuracy: 0.6367\n",
      "Epoch 136/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1836 - accuracy: 0.9342 - val_loss: 1.2372 - val_accuracy: 0.6719\n",
      "Epoch 137/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1678 - accuracy: 0.9441 - val_loss: 1.3312 - val_accuracy: 0.6602\n",
      "Epoch 138/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1908 - accuracy: 0.9356 - val_loss: 1.3157 - val_accuracy: 0.6523\n",
      "Epoch 139/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1626 - accuracy: 0.9388 - val_loss: 1.2061 - val_accuracy: 0.6289\n",
      "Epoch 140/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1696 - accuracy: 0.9440 - val_loss: 1.4606 - val_accuracy: 0.6250\n",
      "Epoch 141/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1585 - accuracy: 0.9369 - val_loss: 1.3217 - val_accuracy: 0.6719\n",
      "Epoch 142/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1810 - accuracy: 0.9356 - val_loss: 1.3235 - val_accuracy: 0.6953\n",
      "Epoch 143/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1451 - accuracy: 0.9468 - val_loss: 1.4106 - val_accuracy: 0.6602\n",
      "Epoch 144/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1574 - accuracy: 0.9450 - val_loss: 1.3590 - val_accuracy: 0.6836\n",
      "Epoch 145/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1632 - accuracy: 0.9399 - val_loss: 1.3332 - val_accuracy: 0.6953\n",
      "Epoch 146/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.1549 - accuracy: 0.9435 - val_loss: 1.3661 - val_accuracy: 0.6523\n",
      "Epoch 147/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1474 - accuracy: 0.9510 - val_loss: 1.4626 - val_accuracy: 0.6562\n",
      "Epoch 148/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.1544 - accuracy: 0.9413 - val_loss: 1.3257 - val_accuracy: 0.6758\n",
      "Epoch 149/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1417 - accuracy: 0.9511 - val_loss: 1.4477 - val_accuracy: 0.6602\n",
      "Epoch 150/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1682 - accuracy: 0.9491 - val_loss: 1.4124 - val_accuracy: 0.6328\n",
      "Epoch 151/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1466 - accuracy: 0.9546 - val_loss: 1.4067 - val_accuracy: 0.6484\n",
      "Epoch 152/4000\n",
      "128/128 [==============================] - 6s 51ms/step - loss: 0.1264 - accuracy: 0.9548 - val_loss: 1.3687 - val_accuracy: 0.67580\n",
      "Epoch 153/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1528 - accuracy: 0.9510 - val_loss: 1.2832 - val_accuracy: 0.6602\n",
      "Epoch 154/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1475 - accuracy: 0.9478 - val_loss: 1.4950 - val_accuracy: 0.6680\n",
      "Epoch 155/4000\n",
      "128/128 [==============================] - 6s 48ms/step - loss: 0.1401 - accuracy: 0.9505 - val_loss: 1.5785 - val_accuracy: 0.6406\n",
      "Epoch 156/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1362 - accuracy: 0.9512 - val_loss: 1.4985 - val_accuracy: 0.6758\n",
      "Epoch 157/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1366 - accuracy: 0.9519 - val_loss: 1.3234 - val_accuracy: 0.6523\n",
      "Epoch 158/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1613 - accuracy: 0.9380 - val_loss: 1.4655 - val_accuracy: 0.6680\n",
      "Epoch 159/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1327 - accuracy: 0.9525 - val_loss: 1.3864 - val_accuracy: 0.6562\n",
      "Epoch 160/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1265 - accuracy: 0.9555 - val_loss: 1.4952 - val_accuracy: 0.6797\n",
      "Epoch 161/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1227 - accuracy: 0.9544 - val_loss: 1.4692 - val_accuracy: 0.6445\n",
      "Epoch 162/4000\n",
      "128/128 [==============================] - 6s 51ms/step - loss: 0.1461 - accuracy: 0.9465 - val_loss: 1.5117 - val_accuracy: 0.6562\n",
      "Epoch 163/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1246 - accuracy: 0.9605 - val_loss: 1.6643 - val_accuracy: 0.6602\n",
      "Epoch 164/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1096 - accuracy: 0.9641 - val_loss: 1.8110 - val_accuracy: 0.6484\n",
      "Epoch 165/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1217 - accuracy: 0.9646 - val_loss: 1.5912 - val_accuracy: 0.6445\n",
      "Epoch 166/4000\n",
      "128/128 [==============================] - 6s 51ms/step - loss: 0.1686 - accuracy: 0.9438 - val_loss: 1.4384 - val_accuracy: 0.6758\n",
      "Epoch 167/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1146 - accuracy: 0.9627 - val_loss: 1.3434 - val_accuracy: 0.6992\n",
      "Epoch 168/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1209 - accuracy: 0.9591 - val_loss: 1.3814 - val_accuracy: 0.6875\n",
      "Epoch 169/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1435 - accuracy: 0.9534 - val_loss: 1.4314 - val_accuracy: 0.6758\n",
      "Epoch 170/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1305 - accuracy: 0.9573 - val_loss: 1.4973 - val_accuracy: 0.6367\n",
      "Epoch 171/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1355 - accuracy: 0.9522 - val_loss: 1.3489 - val_accuracy: 0.6445\n",
      "Epoch 172/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1250 - accuracy: 0.9647 - val_loss: 1.6212 - val_accuracy: 0.6641\n",
      "Epoch 173/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.1220 - accuracy: 0.9609 - val_loss: 1.2681 - val_accuracy: 0.6680\n",
      "Epoch 174/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1364 - accuracy: 0.9494 - val_loss: 1.2771 - val_accuracy: 0.6680\n",
      "Epoch 175/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1289 - accuracy: 0.9549 - val_loss: 1.4490 - val_accuracy: 0.6836\n",
      "Epoch 176/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1289 - accuracy: 0.9507 - val_loss: 1.3170 - val_accuracy: 0.6797\n",
      "Epoch 177/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1191 - accuracy: 0.9584 - val_loss: 1.4401 - val_accuracy: 0.6875\n",
      "Epoch 178/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1050 - accuracy: 0.9628 - val_loss: 1.5506 - val_accuracy: 0.6719\n",
      "Epoch 179/4000\n",
      "128/128 [==============================] - 6s 49ms/step - loss: 0.1225 - accuracy: 0.9554 - val_loss: 1.5257 - val_accuracy: 0.6914\n",
      "Epoch 180/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1090 - accuracy: 0.9652 - val_loss: 1.4191 - val_accuracy: 0.6836\n",
      "Epoch 181/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1241 - accuracy: 0.9565 - val_loss: 1.5189 - val_accuracy: 0.6836\n",
      "Epoch 182/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1343 - accuracy: 0.9566 - val_loss: 1.4716 - val_accuracy: 0.6641\n",
      "Epoch 183/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1146 - accuracy: 0.9622 - val_loss: 1.5750 - val_accuracy: 0.6562\n",
      "Epoch 184/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1165 - accuracy: 0.9578 - val_loss: 1.6209 - val_accuracy: 0.6602\n",
      "Epoch 185/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.1165 - accuracy: 0.9618 - val_loss: 1.4436 - val_accuracy: 0.6562\n",
      "Epoch 186/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1156 - accuracy: 0.9550 - val_loss: 1.4178 - val_accuracy: 0.6680\n",
      "Epoch 187/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1062 - accuracy: 0.9645 - val_loss: 1.4358 - val_accuracy: 0.6406\n",
      "Epoch 188/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1153 - accuracy: 0.9587 - val_loss: 1.4332 - val_accuracy: 0.6680\n",
      "Epoch 189/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1172 - accuracy: 0.9581 - val_loss: 1.5406 - val_accuracy: 0.6602\n",
      "Epoch 190/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1074 - accuracy: 0.9639 - val_loss: 1.4860 - val_accuracy: 0.6445\n",
      "Epoch 191/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1117 - accuracy: 0.9636 - val_loss: 1.5260 - val_accuracy: 0.6719\n",
      "Epoch 192/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0925 - accuracy: 0.9681 - val_loss: 1.5017 - val_accuracy: 0.6094\n",
      "Epoch 193/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1072 - accuracy: 0.9643 - val_loss: 1.3444 - val_accuracy: 0.6602\n",
      "Epoch 194/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1005 - accuracy: 0.9656 - val_loss: 1.5564 - val_accuracy: 0.6484\n",
      "Epoch 195/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0893 - accuracy: 0.9696 - val_loss: 1.5121 - val_accuracy: 0.6602\n",
      "Epoch 196/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1185 - accuracy: 0.9619 - val_loss: 1.2834 - val_accuracy: 0.7070\n",
      "Epoch 197/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1035 - accuracy: 0.9673 - val_loss: 1.3959 - val_accuracy: 0.6953\n",
      "Epoch 198/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1120 - accuracy: 0.9666 - val_loss: 1.5346 - val_accuracy: 0.6719\n",
      "Epoch 199/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1102 - accuracy: 0.9618 - val_loss: 1.5515 - val_accuracy: 0.6523\n",
      "Epoch 200/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.1247 - accuracy: 0.9580 - val_loss: 1.3008 - val_accuracy: 0.7031\n",
      "Epoch 201/4000\n",
      "128/128 [==============================] - 6s 51ms/step - loss: 0.1106 - accuracy: 0.9579 - val_loss: 1.2823 - val_accuracy: 0.6797\n",
      "Epoch 202/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1052 - accuracy: 0.9597 - val_loss: 1.2385 - val_accuracy: 0.7109\n",
      "Epoch 203/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.0939 - accuracy: 0.9659 - val_loss: 1.4497 - val_accuracy: 0.7148\n",
      "Epoch 204/4000\n",
      "128/128 [==============================] - 6s 50ms/step - loss: 0.0909 - accuracy: 0.9687 - val_loss: 1.6588 - val_accuracy: 0.6875\n",
      "Epoch 205/4000\n",
      "128/128 [==============================] - 7s 51ms/step - loss: 0.1113 - accuracy: 0.9642 - val_loss: 1.3709 - val_accuracy: 0.6758\n",
      "Epoch 206/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.1047 - accuracy: 0.9610 - val_loss: 1.6204 - val_accuracy: 0.6133\n",
      "Epoch 207/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1211 - accuracy: 0.9576 - val_loss: 1.5310 - val_accuracy: 0.6367\n",
      "Epoch 208/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1017 - accuracy: 0.9647 - val_loss: 1.4913 - val_accuracy: 0.6953\n",
      "Epoch 209/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.1530 - accuracy: 0.9525 - val_loss: 1.5542 - val_accuracy: 0.6289\n",
      "Epoch 210/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1042 - accuracy: 0.9644 - val_loss: 1.6375 - val_accuracy: 0.6562\n",
      "Epoch 211/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0898 - accuracy: 0.9690 - val_loss: 1.5302 - val_accuracy: 0.69140908 \n",
      "Epoch 212/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0757 - accuracy: 0.9757 - val_loss: 1.5966 - val_accuracy: 0.6992\n",
      "Epoch 213/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1025 - accuracy: 0.9646 - val_loss: 1.5297 - val_accuracy: 0.6641\n",
      "Epoch 214/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 1.5260 - val_accuracy: 0.6523\n",
      "Epoch 215/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0816 - accuracy: 0.9680 - val_loss: 1.5657 - val_accuracy: 0.6367\n",
      "Epoch 216/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.1015 - accuracy: 0.9644 - val_loss: 1.5562 - val_accuracy: 0.6719\n",
      "Epoch 217/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0962 - accuracy: 0.9690 - val_loss: 1.6713 - val_accuracy: 0.6602\n",
      "Epoch 218/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0956 - accuracy: 0.9636 - val_loss: 1.6805 - val_accuracy: 0.6289\n",
      "Epoch 219/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 1.6800 - val_accuracy: 0.6250\n",
      "Epoch 220/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0872 - accuracy: 0.9690 - val_loss: 1.5458 - val_accuracy: 0.6367\n",
      "Epoch 221/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0906 - accuracy: 0.9696 - val_loss: 1.4420 - val_accuracy: 0.6680\n",
      "Epoch 222/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0700 - accuracy: 0.9762 - val_loss: 1.4719 - val_accuracy: 0.6953\n",
      "Epoch 223/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0912 - accuracy: 0.9703 - val_loss: 1.6988 - val_accuracy: 0.6797\n",
      "Epoch 224/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.1101 - accuracy: 0.9593 - val_loss: 1.2863 - val_accuracy: 0.6641\n",
      "Epoch 225/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 1.6651 - val_accuracy: 0.6680\n",
      "Epoch 226/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0803 - accuracy: 0.9758 - val_loss: 1.5492 - val_accuracy: 0.6602\n",
      "Epoch 227/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 1.5030 - val_accuracy: 0.6875\n",
      "Epoch 228/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0734 - accuracy: 0.9754 - val_loss: 1.5220 - val_accuracy: 0.6602\n",
      "Epoch 229/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0667 - accuracy: 0.9725 - val_loss: 1.5243 - val_accuracy: 0.7031\n",
      "Epoch 230/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0691 - accuracy: 0.9782 - val_loss: 1.5680 - val_accuracy: 0.6680\n",
      "Epoch 231/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0990 - accuracy: 0.9745 - val_loss: 1.5091 - val_accuracy: 0.7031\n",
      "Epoch 232/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0952 - accuracy: 0.9664 - val_loss: 1.5159 - val_accuracy: 0.6875\n",
      "Epoch 233/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0755 - accuracy: 0.9745 - val_loss: 1.5105 - val_accuracy: 0.6367\n",
      "Epoch 234/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0935 - accuracy: 0.9674 - val_loss: 1.5929 - val_accuracy: 0.6562\n",
      "Epoch 235/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 1.3819 - val_accuracy: 0.6836\n",
      "Epoch 236/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0968 - accuracy: 0.9647 - val_loss: 1.5731 - val_accuracy: 0.6719\n",
      "Epoch 237/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0845 - accuracy: 0.9699 - val_loss: 1.3602 - val_accuracy: 0.6602\n",
      "Epoch 238/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0614 - accuracy: 0.9783 - val_loss: 1.6565 - val_accuracy: 0.6719\n",
      "Epoch 239/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0702 - accuracy: 0.9770 - val_loss: 1.5065 - val_accuracy: 0.6875\n",
      "Epoch 240/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0851 - accuracy: 0.9691 - val_loss: 1.7175 - val_accuracy: 0.6641\n",
      "Epoch 241/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0895 - accuracy: 0.9677 - val_loss: 1.8205 - val_accuracy: 0.6523\n",
      "Epoch 242/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0819 - accuracy: 0.9746 - val_loss: 1.5701 - val_accuracy: 0.7070\n",
      "Epoch 243/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 1.5166 - val_accuracy: 0.7070\n",
      "Epoch 244/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 1.7263 - val_accuracy: 0.6641\n",
      "Epoch 245/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 1.4744 - val_accuracy: 0.6836\n",
      "Epoch 246/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.0950 - accuracy: 0.9717 - val_loss: 1.3563 - val_accuracy: 0.7109\n",
      "Epoch 247/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0838 - accuracy: 0.9695 - val_loss: 1.4068 - val_accuracy: 0.7148\n",
      "Epoch 248/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0672 - accuracy: 0.9730 - val_loss: 1.4256 - val_accuracy: 0.6836\n",
      "Epoch 249/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0596 - accuracy: 0.9788 - val_loss: 1.3443 - val_accuracy: 0.7031\n",
      "Epoch 250/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0839 - accuracy: 0.9733 - val_loss: 1.5979 - val_accuracy: 0.6875\n",
      "Epoch 251/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.1096 - accuracy: 0.9661 - val_loss: 1.5371 - val_accuracy: 0.7109\n",
      "Epoch 252/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0680 - accuracy: 0.9766 - val_loss: 1.5903 - val_accuracy: 0.7266\n",
      "Epoch 253/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0631 - accuracy: 0.9785 - val_loss: 1.7131 - val_accuracy: 0.6406\n",
      "Epoch 254/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0680 - accuracy: 0.9759 - val_loss: 1.6482 - val_accuracy: 0.5977\n",
      "Epoch 255/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0703 - accuracy: 0.9747 - val_loss: 1.5693 - val_accuracy: 0.6641\n",
      "Epoch 256/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0851 - accuracy: 0.9690 - val_loss: 1.5760 - val_accuracy: 0.6836\n",
      "Epoch 257/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0974 - accuracy: 0.9680 - val_loss: 1.4179 - val_accuracy: 0.6875\n",
      "Epoch 258/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0817 - accuracy: 0.9731 - val_loss: 1.5909 - val_accuracy: 0.6992\n",
      "Epoch 259/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0677 - accuracy: 0.9761 - val_loss: 1.6884 - val_accuracy: 0.6484\n",
      "Epoch 260/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0765 - accuracy: 0.9771 - val_loss: 1.5966 - val_accuracy: 0.6641\n",
      "Epoch 261/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0645 - accuracy: 0.9752 - val_loss: 1.6725 - val_accuracy: 0.6602\n",
      "Epoch 262/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0936 - accuracy: 0.9715 - val_loss: 1.3767 - val_accuracy: 0.6758\n",
      "Epoch 263/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.1002 - accuracy: 0.9700 - val_loss: 1.7115 - val_accuracy: 0.6602\n",
      "Epoch 264/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 1.5975 - val_accuracy: 0.6445\n",
      "Epoch 265/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 1.6789 - val_accuracy: 0.6562\n",
      "Epoch 266/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 1.7488 - val_accuracy: 0.6523\n",
      "Epoch 267/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0778 - accuracy: 0.9741 - val_loss: 1.6506 - val_accuracy: 0.6523\n",
      "Epoch 268/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0709 - accuracy: 0.9759 - val_loss: 1.9868 - val_accuracy: 0.6641\n",
      "Epoch 269/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0625 - accuracy: 0.9807 - val_loss: 1.7623 - val_accuracy: 0.6758\n",
      "Epoch 270/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0544 - accuracy: 0.9803 - val_loss: 1.8970 - val_accuracy: 0.6836\n",
      "Epoch 271/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0724 - accuracy: 0.9769 - val_loss: 1.7687 - val_accuracy: 0.6719\n",
      "Epoch 272/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.0834 - accuracy: 0.9706 - val_loss: 1.4460 - val_accuracy: 0.6719\n",
      "Epoch 273/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0825 - accuracy: 0.9742 - val_loss: 1.4648 - val_accuracy: 0.6562\n",
      "Epoch 274/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0728 - accuracy: 0.9783 - val_loss: 1.5621 - val_accuracy: 0.7031\n",
      "Epoch 275/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0808 - accuracy: 0.9742 - val_loss: 1.7531 - val_accuracy: 0.6562\n",
      "Epoch 276/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0848 - accuracy: 0.9716 - val_loss: 1.6420 - val_accuracy: 0.6445\n",
      "Epoch 277/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0850 - accuracy: 0.9696 - val_loss: 1.6550 - val_accuracy: 0.6836\n",
      "Epoch 278/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.0450 - accuracy: 0.9876 - val_loss: 1.7037 - val_accuracy: 0.6523\n",
      "Epoch 279/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0809 - accuracy: 0.9703 - val_loss: 1.6325 - val_accuracy: 0.6562\n",
      "Epoch 280/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0538 - accuracy: 0.9782 - val_loss: 1.9546 - val_accuracy: 0.6797\n",
      "Epoch 281/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 1.6781 - val_accuracy: 0.6289\n",
      "Epoch 282/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0816 - accuracy: 0.9710 - val_loss: 1.6017 - val_accuracy: 0.6719\n",
      "Epoch 283/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0690 - accuracy: 0.9771 - val_loss: 1.5871 - val_accuracy: 0.6562\n",
      "Epoch 284/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0624 - accuracy: 0.9776 - val_loss: 1.8212 - val_accuracy: 0.6250\n",
      "Epoch 285/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0693 - accuracy: 0.9746 - val_loss: 1.7312 - val_accuracy: 0.6602\n",
      "Epoch 286/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0639 - accuracy: 0.9761 - val_loss: 1.7551 - val_accuracy: 0.6484\n",
      "Epoch 287/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0757 - accuracy: 0.9781 - val_loss: 1.5207 - val_accuracy: 0.6562\n",
      "Epoch 288/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0728 - accuracy: 0.9781 - val_loss: 1.5544 - val_accuracy: 0.6641\n",
      "Epoch 289/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 1.7442 - val_accuracy: 0.6367\n",
      "Epoch 290/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.1004 - accuracy: 0.9676 - val_loss: 1.7063 - val_accuracy: 0.6836\n",
      "Epoch 291/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0754 - accuracy: 0.9763 - val_loss: 1.7534 - val_accuracy: 0.6875\n",
      "Epoch 292/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0691 - accuracy: 0.9788 - val_loss: 1.7586 - val_accuracy: 0.6719\n",
      "Epoch 293/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0624 - accuracy: 0.9775 - val_loss: 1.6136 - val_accuracy: 0.6875\n",
      "Epoch 294/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 1.8396 - val_accuracy: 0.6797\n",
      "Epoch 295/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0676 - accuracy: 0.9756 - val_loss: 1.8693 - val_accuracy: 0.6992\n",
      "Epoch 296/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0480 - accuracy: 0.9818 - val_loss: 1.7759 - val_accuracy: 0.6602\n",
      "Epoch 297/4000\n",
      "128/128 [==============================] - 7s 52ms/step - loss: 0.0737 - accuracy: 0.9786 - val_loss: 1.6466 - val_accuracy: 0.6680\n",
      "Epoch 298/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0704 - accuracy: 0.9789 - val_loss: 1.5446 - val_accuracy: 0.6797\n",
      "Epoch 299/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 1.6058 - val_accuracy: 0.6875\n",
      "Epoch 300/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 1.5811 - val_accuracy: 0.6836\n",
      "Epoch 301/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0705 - accuracy: 0.9756 - val_loss: 1.8228 - val_accuracy: 0.6367\n",
      "Epoch 302/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0681 - accuracy: 0.9772 - val_loss: 1.7902 - val_accuracy: 0.6680\n",
      "Epoch 303/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0445 - accuracy: 0.9837 - val_loss: 1.8079 - val_accuracy: 0.6484\n",
      "Epoch 304/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 1.8081 - val_accuracy: 0.6602\n",
      "Epoch 305/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0561 - accuracy: 0.9826 - val_loss: 1.6758 - val_accuracy: 0.6289\n",
      "Epoch 306/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 1.6822 - val_accuracy: 0.6250\n",
      "Epoch 307/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 1.8105 - val_accuracy: 0.6562\n",
      "Epoch 308/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0606 - accuracy: 0.9773 - val_loss: 1.6809 - val_accuracy: 0.6719\n",
      "Epoch 309/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0651 - accuracy: 0.9800 - val_loss: 1.6714 - val_accuracy: 0.6758\n",
      "Epoch 310/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0616 - accuracy: 0.9811 - val_loss: 1.5894 - val_accuracy: 0.6602\n",
      "Epoch 311/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0612 - accuracy: 0.9768 - val_loss: 1.5195 - val_accuracy: 0.6797\n",
      "Epoch 312/4000\n",
      "128/128 [==============================] - 7s 53ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 1.5947 - val_accuracy: 0.6875\n",
      "Epoch 313/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 1.4745 - val_accuracy: 0.7031\n",
      "Epoch 314/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 1.4624 - val_accuracy: 0.6875\n",
      "Epoch 315/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0517 - accuracy: 0.9860 - val_loss: 1.4984 - val_accuracy: 0.7148\n",
      "Epoch 316/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 1.5175 - val_accuracy: 0.7031\n",
      "Epoch 317/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 1.6245 - val_accuracy: 0.6758\n",
      "Epoch 318/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 1.5616 - val_accuracy: 0.7109\n",
      "Epoch 319/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0614 - accuracy: 0.9781 - val_loss: 1.4489 - val_accuracy: 0.6992\n",
      "Epoch 320/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.0753 - accuracy: 0.9738 - val_loss: 1.6524 - val_accuracy: 0.6836\n",
      "Epoch 321/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.0658 - accuracy: 0.9775 - val_loss: 1.5829 - val_accuracy: 0.6641\n",
      "Epoch 322/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.0481 - accuracy: 0.9831 - val_loss: 1.6528 - val_accuracy: 0.6758\n",
      "Epoch 323/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0520 - accuracy: 0.9827 - val_loss: 1.6007 - val_accuracy: 0.6719\n",
      "Epoch 324/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 1.7104 - val_accuracy: 0.6875\n",
      "Epoch 325/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 1.6919 - val_accuracy: 0.6602\n",
      "Epoch 326/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0466 - accuracy: 0.9798 - val_loss: 1.8866 - val_accuracy: 0.6484\n",
      "Epoch 327/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0671 - accuracy: 0.9713 - val_loss: 1.8434 - val_accuracy: 0.6758\n",
      "Epoch 328/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0659 - accuracy: 0.9761 - val_loss: 1.7371 - val_accuracy: 0.6719\n",
      "Epoch 329/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 1.8376 - val_accuracy: 0.6562\n",
      "Epoch 330/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0516 - accuracy: 0.9812 - val_loss: 1.6844 - val_accuracy: 0.6797\n",
      "Epoch 331/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0762 - accuracy: 0.9709 - val_loss: 1.8930 - val_accuracy: 0.6875\n",
      "Epoch 332/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0639 - accuracy: 0.9765 - val_loss: 1.7843 - val_accuracy: 0.6914\n",
      "Epoch 333/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0567 - accuracy: 0.9801 - val_loss: 1.5864 - val_accuracy: 0.6914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0412 - accuracy: 0.9842 - val_loss: 1.7684 - val_accuracy: 0.6680\n",
      "Epoch 335/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0702 - accuracy: 0.9771 - val_loss: 1.7378 - val_accuracy: 0.6680\n",
      "Epoch 336/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 1.8495 - val_accuracy: 0.6484\n",
      "Epoch 337/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 1.7788 - val_accuracy: 0.6992\n",
      "Epoch 338/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 1.7178 - val_accuracy: 0.6875\n",
      "Epoch 339/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.0393 - accuracy: 0.9858 - val_loss: 1.8074 - val_accuracy: 0.6914\n",
      "Epoch 340/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.0613 - accuracy: 0.9829 - val_loss: 1.4282 - val_accuracy: 0.7031\n",
      "Epoch 341/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.0638 - accuracy: 0.9795 - val_loss: 1.6022 - val_accuracy: 0.6680\n",
      "Epoch 342/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.0533 - accuracy: 0.9849 - val_loss: 1.6647 - val_accuracy: 0.6797\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00342: early stopping\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.5780 - accuracy: 0.7605\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8270 - accuracy: 0.6367\n",
      "Train: 0.760, Val: 0.637\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit model\n",
    "history = cnn_model.fit(training_set,\n",
    "        epochs=4000,\n",
    "        validation_data=val_set,\n",
    "        verbose = 1, \n",
    "        validation_steps = len(val_set),\n",
    "        callbacks = [es])\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = cnn_model.evaluate(training_set, verbose=1)\n",
    "_, val_acc = cnn_model.evaluate(val_set, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cnn_model.save(r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Models\\model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, None, None, 32)    65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, None, None, 128)   262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 914,852\n",
      "Trainable params: 911,588\n",
      "Non-trainable params: 3,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Summary\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 2s 6ms/step - loss: 0.8227 - accuracy: 0.6342\n",
      "Test loss: 0.8227008581161499\n",
      "Test accuracy: 0.6342412233352661\n"
     ]
    }
   ],
   "source": [
    "#test performance\n",
    "\n",
    "test_loss, test_acc = cnn_model.evaluate(test_set)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "Code still needs improvement\n",
    "\n",
    "These predictions are gated by batch size\n",
    "\n",
    "Let's try and improve it with bruteforce Hyperparam optimization whiole being on the lookout for other ways to improve performance. Model is predicting all as Amorphous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = cnn_model.predict(test_set,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = test_set.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = test_set.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "robust_predictions = pd.DataFrame({'Filename': filenames,'Model_1': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(robust_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del robust_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "      <th>Model_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample3-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample4-sperm15.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm17.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm2.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>class3\\image_036.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>class3\\image_038.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>class3\\image_040.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>class3\\image_048.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>class3\\image_051.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test  Model_1\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     0        3\n",
       "1     class0\\ch00_p1-pl2-sample3-sperm4.tif      0     1        0\n",
       "2    class0\\ch00_p1-pl2-sample4-sperm15.tif      0     3        3\n",
       "3    class0\\ch00_p1-pl3-sample1-sperm17.tif      0     3        3\n",
       "4     class0\\ch00_p1-pl3-sample1-sperm2.tif      0     3        0\n",
       "..                                      ...    ...   ...      ...\n",
       "252                    class3\\image_036.BMP      3     3        3\n",
       "253                    class3\\image_038.BMP      3     2        3\n",
       "254                    class3\\image_040.BMP      3     2        3\n",
       "255                    class3\\image_048.BMP      3     3        3\n",
       "256                    class3\\image_051.BMP      3     3        1\n",
       "\n",
       "[257 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  3  6 15]\n",
      " [ 6 10 13 28]\n",
      " [ 2  6  4 15]\n",
      " [31 27 20 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.15      0.23      0.18        31\n",
      "      class1       0.22      0.18      0.19        57\n",
      "      class2       0.09      0.15      0.11        27\n",
      "      class3       0.52      0.45      0.48       142\n",
      "\n",
      "    accuracy                           0.33       257\n",
      "   macro avg       0.25      0.25      0.24       257\n",
      "weighted avg       0.37      0.33      0.34       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix and classification report\n",
    "class_labels = list(test_set.class_indices.keys())   \n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Other tests\n",
    "\n",
    "Try and compare the models performance with other standardly used models:\n",
    "\n",
    "AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 4004      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 25,724,476\n",
      "Trainable params: 25,703,332\n",
      "Non-trainable params: 21,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ALEX NET\n",
    "\n",
    "#Importing library \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(4))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "128/128 [==============================] - 10s 59ms/step - loss: 1.4531 - accuracy: 0.3229 - val_loss: 1.8978 - val_accuracy: 0.2188\n",
      "Epoch 2/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2994 - accuracy: 0.3715 - val_loss: 1.2839 - val_accuracy: 0.4219\n",
      "Epoch 3/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2930 - accuracy: 0.3735 - val_loss: 1.5356 - val_accuracy: 0.2070\n",
      "Epoch 4/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2750 - accuracy: 0.4061 - val_loss: 1.3514 - val_accuracy: 0.2500\n",
      "Epoch 5/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2626 - accuracy: 0.4125 - val_loss: 1.3055 - val_accuracy: 0.2305\n",
      "Epoch 6/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2352 - accuracy: 0.4276 - val_loss: 1.7236 - val_accuracy: 0.2305\n",
      "Epoch 7/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2207 - accuracy: 0.4388 - val_loss: 1.2912 - val_accuracy: 0.3945\n",
      "Epoch 8/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2272 - accuracy: 0.4410 - val_loss: 1.9718 - val_accuracy: 0.1445\n",
      "Epoch 9/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2380 - accuracy: 0.4271 - val_loss: 1.2084 - val_accuracy: 0.5547\n",
      "Epoch 10/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2131 - accuracy: 0.4461 - val_loss: 1.2743 - val_accuracy: 0.2500\n",
      "Epoch 11/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2135 - accuracy: 0.4511 - val_loss: 1.3075 - val_accuracy: 0.3008\n",
      "Epoch 12/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2281 - accuracy: 0.4259 - val_loss: 1.2082 - val_accuracy: 0.4453\n",
      "Epoch 13/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1950 - accuracy: 0.4684 - val_loss: 1.2619 - val_accuracy: 0.3828\n",
      "Epoch 14/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1759 - accuracy: 0.4796 - val_loss: 1.2935 - val_accuracy: 0.5117\n",
      "Epoch 15/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1587 - accuracy: 0.4904 - val_loss: 1.0619 - val_accuracy: 0.5352\n",
      "Epoch 16/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1787 - accuracy: 0.4667 - val_loss: 1.2863 - val_accuracy: 0.2812\n",
      "Epoch 17/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1494 - accuracy: 0.4824 - val_loss: 1.1474 - val_accuracy: 0.4531\n",
      "Epoch 18/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1491 - accuracy: 0.4749 - val_loss: 1.1484 - val_accuracy: 0.5039\n",
      "Epoch 19/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1355 - accuracy: 0.4932 - val_loss: 1.1307 - val_accuracy: 0.4688\n",
      "Epoch 20/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1433 - accuracy: 0.4806 - val_loss: 1.2607 - val_accuracy: 0.3594\n",
      "Epoch 21/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1120 - accuracy: 0.4968 - val_loss: 1.4760 - val_accuracy: 0.3008\n",
      "Epoch 22/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1160 - accuracy: 0.5059 - val_loss: 1.1998 - val_accuracy: 0.4414\n",
      "Epoch 23/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.0872 - accuracy: 0.5271 - val_loss: 1.1693 - val_accuracy: 0.4102\n",
      "Epoch 24/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1081 - accuracy: 0.5070 - val_loss: 1.4667 - val_accuracy: 0.3242\n",
      "Epoch 25/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.0689 - accuracy: 0.5269 - val_loss: 1.3731 - val_accuracy: 0.3047\n",
      "Epoch 26/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.0577 - accuracy: 0.5386 - val_loss: 1.0131 - val_accuracy: 0.5586\n",
      "Epoch 27/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.0683 - accuracy: 0.5325 - val_loss: 1.2254 - val_accuracy: 0.5312\n",
      "Epoch 28/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.0593 - accuracy: 0.5298 - val_loss: 1.2574 - val_accuracy: 0.3789\n",
      "Epoch 29/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0606 - accuracy: 0.5312 - val_loss: 1.5224 - val_accuracy: 0.2383\n",
      "Epoch 30/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0372 - accuracy: 0.5554 - val_loss: 1.4053 - val_accuracy: 0.3125\n",
      "Epoch 31/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.0325 - accuracy: 0.5369 - val_loss: 1.1113 - val_accuracy: 0.5586\n",
      "Epoch 32/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0286 - accuracy: 0.5526 - val_loss: 1.0225 - val_accuracy: 0.5391\n",
      "Epoch 33/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0014 - accuracy: 0.5748 - val_loss: 1.0887 - val_accuracy: 0.4609\n",
      "Epoch 34/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0038 - accuracy: 0.5766 - val_loss: 1.0816 - val_accuracy: 0.4883\n",
      "Epoch 35/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0039 - accuracy: 0.5712 - val_loss: 1.0147 - val_accuracy: 0.5039\n",
      "Epoch 36/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9898 - accuracy: 0.5768 - val_loss: 1.0650 - val_accuracy: 0.4531\n",
      "Epoch 37/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9798 - accuracy: 0.5697 - val_loss: 1.3526 - val_accuracy: 0.3242\n",
      "Epoch 38/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9802 - accuracy: 0.5863 - val_loss: 0.9486 - val_accuracy: 0.5547\n",
      "Epoch 39/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9683 - accuracy: 0.6021 - val_loss: 1.3776 - val_accuracy: 0.3047\n",
      "Epoch 40/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9898 - accuracy: 0.5853 - val_loss: 1.1930 - val_accuracy: 0.4102\n",
      "Epoch 41/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9710 - accuracy: 0.5842 - val_loss: 1.0298 - val_accuracy: 0.5391\n",
      "Epoch 42/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9586 - accuracy: 0.5900 - val_loss: 1.1596 - val_accuracy: 0.4961\n",
      "Epoch 43/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9701 - accuracy: 0.5799 - val_loss: 0.9827 - val_accuracy: 0.5664\n",
      "Epoch 44/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9647 - accuracy: 0.5880 - val_loss: 1.0608 - val_accuracy: 0.4766\n",
      "Epoch 45/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9632 - accuracy: 0.5831 - val_loss: 0.9356 - val_accuracy: 0.5508\n",
      "Epoch 46/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9277 - accuracy: 0.6090 - val_loss: 1.1029 - val_accuracy: 0.5195\n",
      "Epoch 47/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9516 - accuracy: 0.5933 - val_loss: 1.2515 - val_accuracy: 0.3711\n",
      "Epoch 48/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9369 - accuracy: 0.6090 - val_loss: 1.0207 - val_accuracy: 0.5234\n",
      "Epoch 49/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.9111 - accuracy: 0.6133 - val_loss: 0.9129 - val_accuracy: 0.6094\n",
      "Epoch 50/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9271 - accuracy: 0.6013 - val_loss: 1.0519 - val_accuracy: 0.4648uracy: 0.\n",
      "Epoch 51/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.9282 - accuracy: 0.6074 - val_loss: 1.0982 - val_accuracy: 0.4727\n",
      "Epoch 52/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 0.9026 - accuracy: 0.6268 - val_loss: 0.9020 - val_accuracy: 0.5977\n",
      "Epoch 53/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.9303 - accuracy: 0.5988 - val_loss: 1.0099 - val_accuracy: 0.5156\n",
      "Epoch 54/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.9038 - accuracy: 0.6158 - val_loss: 0.9704 - val_accuracy: 0.5391\n",
      "Epoch 55/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9124 - accuracy: 0.6076 - val_loss: 1.1395 - val_accuracy: 0.4336\n",
      "Epoch 56/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.8885 - accuracy: 0.6261 - val_loss: 0.9638 - val_accuracy: 0.5586\n",
      "Epoch 57/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9035 - accuracy: 0.6169 - val_loss: 1.4469 - val_accuracy: 0.3477\n",
      "Epoch 58/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9287 - accuracy: 0.6039 - val_loss: 0.9611 - val_accuracy: 0.5273\n",
      "Epoch 59/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.9128 - accuracy: 0.6068 - val_loss: 1.0899 - val_accuracy: 0.4727\n",
      "Epoch 60/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.8807 - accuracy: 0.6274 - val_loss: 0.9714 - val_accuracy: 0.5508\n",
      "Epoch 61/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.8722 - accuracy: 0.6350 - val_loss: 0.9415 - val_accuracy: 0.5352\n",
      "Epoch 62/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.8691 - accuracy: 0.6466 - val_loss: 0.9977 - val_accuracy: 0.5352\n",
      "Epoch 63/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.8908 - accuracy: 0.6163 - val_loss: 1.0243 - val_accuracy: 0.5156\n",
      "Epoch 64/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.8444 - accuracy: 0.6670 - val_loss: 0.9744 - val_accuracy: 0.5430\n",
      "Epoch 65/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.8781 - accuracy: 0.6378 - val_loss: 1.2780 - val_accuracy: 0.4141\n",
      "Epoch 66/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 0.8577 - accuracy: 0.6577 - val_loss: 0.8897 - val_accuracy: 0.5820\n",
      "Epoch 67/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.8692 - accuracy: 0.6430 - val_loss: 1.1347 - val_accuracy: 0.4375\n",
      "Epoch 68/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 0.8572 - accuracy: 0.6302 - val_loss: 1.0449 - val_accuracy: 0.5117\n",
      "Epoch 69/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.8446 - accuracy: 0.6498 - val_loss: 0.9347 - val_accuracy: 0.5234\n",
      "Epoch 70/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.8526 - accuracy: 0.6494 - val_loss: 0.9667 - val_accuracy: 0.5391\n",
      "Epoch 71/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.8369 - accuracy: 0.6556 - val_loss: 0.9225 - val_accuracy: 0.6055\n",
      "Epoch 72/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.8412 - accuracy: 0.6603 - val_loss: 0.9817 - val_accuracy: 0.5820\n",
      "Epoch 73/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.8440 - accuracy: 0.6442 - val_loss: 0.8284 - val_accuracy: 0.6172\n",
      "Epoch 74/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.8234 - accuracy: 0.6603 - val_loss: 1.0357 - val_accuracy: 0.4883\n",
      "Epoch 75/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.8279 - accuracy: 0.6596 - val_loss: 0.9949 - val_accuracy: 0.5156\n",
      "Epoch 76/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.8243 - accuracy: 0.6569 - val_loss: 0.8850 - val_accuracy: 0.5938\n",
      "Epoch 77/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.8042 - accuracy: 0.6758 - val_loss: 1.0520 - val_accuracy: 0.4883\n",
      "Epoch 78/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.8141 - accuracy: 0.6570 - val_loss: 1.1477 - val_accuracy: 0.4414\n",
      "Epoch 79/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.8138 - accuracy: 0.6672 - val_loss: 0.9843 - val_accuracy: 0.5664\n",
      "Epoch 80/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.8044 - accuracy: 0.6668 - val_loss: 0.9512 - val_accuracy: 0.6094\n",
      "Epoch 81/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7959 - accuracy: 0.6732 - val_loss: 0.9216 - val_accuracy: 0.5703\n",
      "Epoch 82/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.8105 - accuracy: 0.6637 - val_loss: 1.1652 - val_accuracy: 0.4844\n",
      "Epoch 83/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7934 - accuracy: 0.6662 - val_loss: 1.0305 - val_accuracy: 0.5742\n",
      "Epoch 84/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.8107 - accuracy: 0.6598 - val_loss: 0.9163 - val_accuracy: 0.6016\n",
      "Epoch 85/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.8094 - accuracy: 0.6606 - val_loss: 0.9426 - val_accuracy: 0.5586\n",
      "Epoch 86/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.8207 - accuracy: 0.6555 - val_loss: 1.2202 - val_accuracy: 0.4336\n",
      "Epoch 87/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7870 - accuracy: 0.6554 - val_loss: 1.0244 - val_accuracy: 0.5312\n",
      "Epoch 88/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7542 - accuracy: 0.6909 - val_loss: 0.9682 - val_accuracy: 0.5430\n",
      "Epoch 89/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7540 - accuracy: 0.7010 - val_loss: 0.9535 - val_accuracy: 0.5391\n",
      "Epoch 90/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7981 - accuracy: 0.6656 - val_loss: 1.1418 - val_accuracy: 0.4688\n",
      "Epoch 91/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7685 - accuracy: 0.6849 - val_loss: 0.9663 - val_accuracy: 0.5234\n",
      "Epoch 92/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7710 - accuracy: 0.6929 - val_loss: 0.9891 - val_accuracy: 0.5430\n",
      "Epoch 93/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7764 - accuracy: 0.6838 - val_loss: 1.2551 - val_accuracy: 0.4180\n",
      "Epoch 94/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7583 - accuracy: 0.6868 - val_loss: 1.0280 - val_accuracy: 0.5039\n",
      "Epoch 95/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7624 - accuracy: 0.6897 - val_loss: 0.8927 - val_accuracy: 0.6094\n",
      "Epoch 96/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7624 - accuracy: 0.6943 - val_loss: 1.0088 - val_accuracy: 0.5547\n",
      "Epoch 97/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7929 - accuracy: 0.6794 - val_loss: 0.9950 - val_accuracy: 0.6055\n",
      "Epoch 98/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7656 - accuracy: 0.6837 - val_loss: 0.9474 - val_accuracy: 0.5625\n",
      "Epoch 99/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7727 - accuracy: 0.6971 - val_loss: 0.9841 - val_accuracy: 0.5273\n",
      "Epoch 100/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7457 - accuracy: 0.6930 - val_loss: 0.8283 - val_accuracy: 0.6016\n",
      "Epoch 101/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7311 - accuracy: 0.7081 - val_loss: 0.9045 - val_accuracy: 0.6172\n",
      "Epoch 102/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7463 - accuracy: 0.6938 - val_loss: 0.9253 - val_accuracy: 0.5781\n",
      "Epoch 103/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7101 - accuracy: 0.7180 - val_loss: 0.8931 - val_accuracy: 0.5859\n",
      "Epoch 104/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7425 - accuracy: 0.6894 - val_loss: 1.0058 - val_accuracy: 0.5781\n",
      "Epoch 105/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7466 - accuracy: 0.6930 - val_loss: 0.9577 - val_accuracy: 0.5859\n",
      "Epoch 106/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7335 - accuracy: 0.6995 - val_loss: 1.0140 - val_accuracy: 0.5820\n",
      "Epoch 107/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7458 - accuracy: 0.6946 - val_loss: 0.9437 - val_accuracy: 0.5703\n",
      "Epoch 108/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7275 - accuracy: 0.7014 - val_loss: 0.9133 - val_accuracy: 0.6289\n",
      "Epoch 109/4000\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 0.7329 - accuracy: 0.7053 - val_loss: 0.9461 - val_accuracy: 0.5820\n",
      "Epoch 110/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7216 - accuracy: 0.7053 - val_loss: 1.0705 - val_accuracy: 0.5312\n",
      "Epoch 111/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.7119 - accuracy: 0.7084 - val_loss: 0.9085 - val_accuracy: 0.6367\n",
      "Epoch 112/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7158 - accuracy: 0.7052 - val_loss: 1.0412 - val_accuracy: 0.5938\n",
      "Epoch 113/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 7s 56ms/step - loss: 0.7318 - accuracy: 0.6943 - val_loss: 0.8682 - val_accuracy: 0.5977\n",
      "Epoch 114/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.7341 - accuracy: 0.7055 - val_loss: 1.0535 - val_accuracy: 0.5625\n",
      "Epoch 115/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.7122 - accuracy: 0.7137 - val_loss: 1.0218 - val_accuracy: 0.6250\n",
      "Epoch 116/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.7481 - accuracy: 0.7042 - val_loss: 0.9339 - val_accuracy: 0.5898\n",
      "Epoch 117/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6859 - accuracy: 0.7266 - val_loss: 0.9305 - val_accuracy: 0.5859\n",
      "Epoch 118/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6847 - accuracy: 0.7286 - val_loss: 0.9619 - val_accuracy: 0.5977\n",
      "Epoch 119/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.7025 - accuracy: 0.7208 - val_loss: 0.9435 - val_accuracy: 0.5977\n",
      "Epoch 120/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.6987 - accuracy: 0.7157 - val_loss: 0.8784 - val_accuracy: 0.6094\n",
      "Epoch 121/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6799 - accuracy: 0.7263 - val_loss: 0.9499 - val_accuracy: 0.5859\n",
      "Epoch 122/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6950 - accuracy: 0.7255 - val_loss: 0.8734 - val_accuracy: 0.6680\n",
      "Epoch 123/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6897 - accuracy: 0.7124 - val_loss: 1.0689 - val_accuracy: 0.5742\n",
      "Epoch 124/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6966 - accuracy: 0.7169 - val_loss: 1.0170 - val_accuracy: 0.5586\n",
      "Epoch 125/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.6754 - accuracy: 0.7296 - val_loss: 0.9069 - val_accuracy: 0.5898\n",
      "Epoch 126/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6830 - accuracy: 0.7285 - val_loss: 1.0203 - val_accuracy: 0.5898\n",
      "Epoch 127/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.6929 - accuracy: 0.7193 - val_loss: 0.8688 - val_accuracy: 0.6016\n",
      "Epoch 128/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.6484 - accuracy: 0.7363 - val_loss: 0.8971 - val_accuracy: 0.6016\n",
      "Epoch 129/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.6879 - accuracy: 0.7247 - val_loss: 0.9260 - val_accuracy: 0.5703\n",
      "Epoch 130/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.6587 - accuracy: 0.7344 - val_loss: 0.9119 - val_accuracy: 0.5938\n",
      "Epoch 131/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.6897 - accuracy: 0.7187 - val_loss: 0.9956 - val_accuracy: 0.5430\n",
      "Epoch 132/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6610 - accuracy: 0.7342 - val_loss: 1.2306 - val_accuracy: 0.4141\n",
      "Epoch 133/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6777 - accuracy: 0.7248 - val_loss: 0.9346 - val_accuracy: 0.6055\n",
      "Epoch 134/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6854 - accuracy: 0.7198 - val_loss: 0.8722 - val_accuracy: 0.6133\n",
      "Epoch 135/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6261 - accuracy: 0.7580 - val_loss: 0.8794 - val_accuracy: 0.6133\n",
      "Epoch 136/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6690 - accuracy: 0.7385 - val_loss: 0.9310 - val_accuracy: 0.5938\n",
      "Epoch 137/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6836 - accuracy: 0.7301 - val_loss: 0.8778 - val_accuracy: 0.6445\n",
      "Epoch 138/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6875 - accuracy: 0.7198 - val_loss: 0.9753 - val_accuracy: 0.5742\n",
      "Epoch 139/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6721 - accuracy: 0.7337 - val_loss: 0.9250 - val_accuracy: 0.6328\n",
      "Epoch 140/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6868 - accuracy: 0.7258 - val_loss: 0.9639 - val_accuracy: 0.5703\n",
      "Epoch 141/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6423 - accuracy: 0.7302 - val_loss: 0.8507 - val_accuracy: 0.6211\n",
      "Epoch 142/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6621 - accuracy: 0.7371 - val_loss: 0.8420 - val_accuracy: 0.6133\n",
      "Epoch 143/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6441 - accuracy: 0.7400 - val_loss: 0.8693 - val_accuracy: 0.6172\n",
      "Epoch 144/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6716 - accuracy: 0.7198 - val_loss: 0.8171 - val_accuracy: 0.6484\n",
      "Epoch 145/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6234 - accuracy: 0.7389 - val_loss: 0.9335 - val_accuracy: 0.6406\n",
      "Epoch 146/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.6415 - accuracy: 0.7402 - val_loss: 0.9566 - val_accuracy: 0.5977\n",
      "Epoch 147/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6703 - accuracy: 0.7314 - val_loss: 0.8772 - val_accuracy: 0.5977\n",
      "Epoch 148/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6360 - accuracy: 0.7494 - val_loss: 0.9131 - val_accuracy: 0.6055\n",
      "Epoch 149/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6727 - accuracy: 0.7336 - val_loss: 1.0543 - val_accuracy: 0.5156\n",
      "Epoch 150/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6237 - accuracy: 0.7466 - val_loss: 0.8776 - val_accuracy: 0.6016\n",
      "Epoch 151/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6197 - accuracy: 0.7487 - val_loss: 0.9715 - val_accuracy: 0.6055\n",
      "Epoch 152/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6066 - accuracy: 0.7503 - val_loss: 0.9329 - val_accuracy: 0.6094\n",
      "Epoch 153/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6501 - accuracy: 0.7409 - val_loss: 0.8390 - val_accuracy: 0.5781\n",
      "Epoch 154/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6166 - accuracy: 0.7603 - val_loss: 0.9544 - val_accuracy: 0.5703\n",
      "Epoch 155/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6670 - accuracy: 0.7321 - val_loss: 0.8544 - val_accuracy: 0.5977\n",
      "Epoch 156/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.6554 - accuracy: 0.7330 - val_loss: 0.9288 - val_accuracy: 0.6250\n",
      "Epoch 157/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6122 - accuracy: 0.7612 - val_loss: 0.8635 - val_accuracy: 0.6367\n",
      "Epoch 158/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6430 - accuracy: 0.7497 - val_loss: 0.9204 - val_accuracy: 0.5859\n",
      "Epoch 159/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6483 - accuracy: 0.7350 - val_loss: 0.8157 - val_accuracy: 0.6406\n",
      "Epoch 160/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6405 - accuracy: 0.7472 - val_loss: 0.9054 - val_accuracy: 0.6055\n",
      "Epoch 161/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.6024 - accuracy: 0.7588 - val_loss: 0.9529 - val_accuracy: 0.5977\n",
      "Epoch 162/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5926 - accuracy: 0.7539 - val_loss: 1.0636 - val_accuracy: 0.6094\n",
      "Epoch 163/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5964 - accuracy: 0.7632 - val_loss: 0.8983 - val_accuracy: 0.6094\n",
      "Epoch 164/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6251 - accuracy: 0.7508 - val_loss: 0.9258 - val_accuracy: 0.6055\n",
      "Epoch 165/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6078 - accuracy: 0.7573 - val_loss: 0.8921 - val_accuracy: 0.5977\n",
      "Epoch 166/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6235 - accuracy: 0.7564 - val_loss: 0.9123 - val_accuracy: 0.5625\n",
      "Epoch 167/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5982 - accuracy: 0.7651 - val_loss: 0.8347 - val_accuracy: 0.6797\n",
      "Epoch 168/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6013 - accuracy: 0.7600 - val_loss: 0.9965 - val_accuracy: 0.6289\n",
      "Epoch 169/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.5896 - accuracy: 0.7626 - val_loss: 1.0081 - val_accuracy: 0.6055\n",
      "Epoch 170/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.5853 - accuracy: 0.7702 - val_loss: 0.9468 - val_accuracy: 0.6172\n",
      "Epoch 171/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5891 - accuracy: 0.7584 - val_loss: 1.1271 - val_accuracy: 0.6094\n",
      "Epoch 172/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5697 - accuracy: 0.7629 - val_loss: 1.0840 - val_accuracy: 0.5312\n",
      "Epoch 173/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5820 - accuracy: 0.7577 - val_loss: 1.0059 - val_accuracy: 0.6133\n",
      "Epoch 174/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5809 - accuracy: 0.7622 - val_loss: 0.8848 - val_accuracy: 0.5703\n",
      "Epoch 175/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5829 - accuracy: 0.7701 - val_loss: 0.8715 - val_accuracy: 0.5625\n",
      "Epoch 176/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6055 - accuracy: 0.7617 - val_loss: 0.9262 - val_accuracy: 0.5977\n",
      "Epoch 177/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.6060 - accuracy: 0.7619 - val_loss: 0.9157 - val_accuracy: 0.6289\n",
      "Epoch 178/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.6014 - accuracy: 0.7540 - val_loss: 1.0118 - val_accuracy: 0.5625\n",
      "Epoch 179/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5793 - accuracy: 0.7762 - val_loss: 0.8826 - val_accuracy: 0.6680\n",
      "Epoch 180/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5693 - accuracy: 0.7726 - val_loss: 0.9794 - val_accuracy: 0.5898\n",
      "Epoch 181/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5793 - accuracy: 0.7667 - val_loss: 1.0928 - val_accuracy: 0.5820\n",
      "Epoch 182/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5683 - accuracy: 0.7858 - val_loss: 0.8561 - val_accuracy: 0.6055\n",
      "Epoch 183/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5714 - accuracy: 0.7724 - val_loss: 0.8826 - val_accuracy: 0.6641\n",
      "Epoch 184/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5868 - accuracy: 0.7717 - val_loss: 0.9833 - val_accuracy: 0.5859\n",
      "Epoch 185/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5412 - accuracy: 0.7897 - val_loss: 1.0951 - val_accuracy: 0.5781\n",
      "Epoch 186/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5835 - accuracy: 0.7758 - val_loss: 1.0432 - val_accuracy: 0.6172\n",
      "Epoch 187/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5773 - accuracy: 0.7758 - val_loss: 0.9983 - val_accuracy: 0.6328\n",
      "Epoch 188/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5706 - accuracy: 0.7780 - val_loss: 0.9087 - val_accuracy: 0.6602\n",
      "Epoch 189/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5438 - accuracy: 0.7957 - val_loss: 0.8312 - val_accuracy: 0.6367\n",
      "Epoch 190/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5297 - accuracy: 0.7887 - val_loss: 1.0501 - val_accuracy: 0.5586\n",
      "Epoch 191/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5544 - accuracy: 0.7780 - val_loss: 1.0266 - val_accuracy: 0.6250\n",
      "Epoch 192/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5528 - accuracy: 0.7742 - val_loss: 0.9646 - val_accuracy: 0.5898\n",
      "Epoch 193/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5563 - accuracy: 0.7815 - val_loss: 1.0017 - val_accuracy: 0.5938\n",
      "Epoch 194/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5597 - accuracy: 0.7792 - val_loss: 1.0685 - val_accuracy: 0.6133\n",
      "Epoch 195/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5272 - accuracy: 0.8001 - val_loss: 0.8557 - val_accuracy: 0.6680\n",
      "Epoch 196/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5589 - accuracy: 0.7803 - val_loss: 0.9708 - val_accuracy: 0.5781\n",
      "Epoch 197/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5284 - accuracy: 0.7890 - val_loss: 1.1318 - val_accuracy: 0.5234\n",
      "Epoch 198/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5824 - accuracy: 0.7682 - val_loss: 0.9228 - val_accuracy: 0.5859\n",
      "Epoch 199/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5392 - accuracy: 0.7826 - val_loss: 1.0478 - val_accuracy: 0.6094\n",
      "Epoch 200/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5676 - accuracy: 0.7752 - val_loss: 0.9741 - val_accuracy: 0.5664\n",
      "Epoch 201/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5533 - accuracy: 0.7894 - val_loss: 1.0165 - val_accuracy: 0.5508\n",
      "Epoch 202/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5451 - accuracy: 0.7816 - val_loss: 0.9721 - val_accuracy: 0.5938\n",
      "Epoch 203/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5352 - accuracy: 0.7918 - val_loss: 0.9967 - val_accuracy: 0.6133\n",
      "Epoch 204/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.5179 - accuracy: 0.7960 - val_loss: 0.9550 - val_accuracy: 0.6094\n",
      "Epoch 205/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5774 - accuracy: 0.7765 - val_loss: 0.8752 - val_accuracy: 0.6758\n",
      "Epoch 206/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5206 - accuracy: 0.7973 - val_loss: 1.0889 - val_accuracy: 0.6094\n",
      "Epoch 207/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5395 - accuracy: 0.7887 - val_loss: 0.9620 - val_accuracy: 0.6289\n",
      "Epoch 208/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5369 - accuracy: 0.7923 - val_loss: 0.9405 - val_accuracy: 0.6484\n",
      "Epoch 209/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5143 - accuracy: 0.7862 - val_loss: 1.0417 - val_accuracy: 0.6055\n",
      "Epoch 210/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5056 - accuracy: 0.8079 - val_loss: 1.0276 - val_accuracy: 0.6445\n",
      "Epoch 211/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5122 - accuracy: 0.7992 - val_loss: 0.9613 - val_accuracy: 0.5781\n",
      "Epoch 212/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5286 - accuracy: 0.7951 - val_loss: 0.9403 - val_accuracy: 0.5898ss: 0.5283 - ac\n",
      "Epoch 213/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5339 - accuracy: 0.7903 - val_loss: 0.9527 - val_accuracy: 0.5742\n",
      "Epoch 214/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5352 - accuracy: 0.7806 - val_loss: 0.9324 - val_accuracy: 0.6211\n",
      "Epoch 215/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5050 - accuracy: 0.8040 - val_loss: 1.0112 - val_accuracy: 0.5977\n",
      "Epoch 216/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4906 - accuracy: 0.7985 - val_loss: 0.8379 - val_accuracy: 0.6406\n",
      "Epoch 217/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4925 - accuracy: 0.8036 - val_loss: 0.8889 - val_accuracy: 0.6484\n",
      "Epoch 218/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5288 - accuracy: 0.7863 - val_loss: 1.0438 - val_accuracy: 0.6289\n",
      "Epoch 219/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5201 - accuracy: 0.8008 - val_loss: 0.9156 - val_accuracy: 0.6289\n",
      "Epoch 220/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.5045 - accuracy: 0.7980 - val_loss: 0.9032 - val_accuracy: 0.6133\n",
      "Epoch 221/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5144 - accuracy: 0.7950 - val_loss: 0.9938 - val_accuracy: 0.6250\n",
      "Epoch 222/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4942 - accuracy: 0.8111 - val_loss: 0.9488 - val_accuracy: 0.5938\n",
      "Epoch 223/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5117 - accuracy: 0.7947 - val_loss: 1.0425 - val_accuracy: 0.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.5109 - accuracy: 0.7918 - val_loss: 0.9075 - val_accuracy: 0.6445\n",
      "Epoch 225/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.5138 - accuracy: 0.8034 - val_loss: 0.9891 - val_accuracy: 0.6406\n",
      "Epoch 226/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4846 - accuracy: 0.8044 - val_loss: 1.0380 - val_accuracy: 0.6133\n",
      "Epoch 227/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4942 - accuracy: 0.8092 - val_loss: 0.9286 - val_accuracy: 0.6094\n",
      "Epoch 228/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4977 - accuracy: 0.8077 - val_loss: 0.9890 - val_accuracy: 0.6484\n",
      "Epoch 229/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4709 - accuracy: 0.8180 - val_loss: 1.0424 - val_accuracy: 0.5977\n",
      "Epoch 230/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4632 - accuracy: 0.8270 - val_loss: 0.9685 - val_accuracy: 0.6133\n",
      "Epoch 231/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4763 - accuracy: 0.8120 - val_loss: 0.9211 - val_accuracy: 0.6523\n",
      "Epoch 232/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4736 - accuracy: 0.8090 - val_loss: 0.9787 - val_accuracy: 0.6094\n",
      "Epoch 233/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4752 - accuracy: 0.8134 - val_loss: 0.8651 - val_accuracy: 0.6523\n",
      "Epoch 234/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4751 - accuracy: 0.8213 - val_loss: 0.9905 - val_accuracy: 0.6406\n",
      "Epoch 235/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.4745 - accuracy: 0.8110 - val_loss: 1.1890 - val_accuracy: 0.5391\n",
      "Epoch 236/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.4941 - accuracy: 0.8122 - val_loss: 0.9914 - val_accuracy: 0.6250\n",
      "Epoch 237/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.4716 - accuracy: 0.8153 - val_loss: 1.2052 - val_accuracy: 0.5703\n",
      "Epoch 238/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4453 - accuracy: 0.8216 - val_loss: 1.0875 - val_accuracy: 0.5664\n",
      "Epoch 239/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4692 - accuracy: 0.8183 - val_loss: 0.9770 - val_accuracy: 0.5859\n",
      "Epoch 240/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4636 - accuracy: 0.8284 - val_loss: 0.9049 - val_accuracy: 0.6328\n",
      "Epoch 241/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4508 - accuracy: 0.8268 - val_loss: 0.9748 - val_accuracy: 0.6133\n",
      "Epoch 242/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4289 - accuracy: 0.8332 - val_loss: 0.8904 - val_accuracy: 0.6289\n",
      "Epoch 243/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4624 - accuracy: 0.8206 - val_loss: 1.0895 - val_accuracy: 0.6133\n",
      "Epoch 244/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.4876 - accuracy: 0.8125 - val_loss: 0.9874 - val_accuracy: 0.6133\n",
      "Epoch 245/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4648 - accuracy: 0.8139 - val_loss: 1.1723 - val_accuracy: 0.6133\n",
      "Epoch 246/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.4733 - accuracy: 0.8183 - val_loss: 1.0997 - val_accuracy: 0.6289\n",
      "Epoch 247/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.4671 - accuracy: 0.8214 - val_loss: 1.0234 - val_accuracy: 0.5820\n",
      "Epoch 248/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.4543 - accuracy: 0.8275 - val_loss: 0.9476 - val_accuracy: 0.6289\n",
      "Epoch 249/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4313 - accuracy: 0.8330 - val_loss: 1.1684 - val_accuracy: 0.5508\n",
      "Epoch 250/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4522 - accuracy: 0.8179 - val_loss: 1.0836 - val_accuracy: 0.6055\n",
      "Epoch 251/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4697 - accuracy: 0.8126 - val_loss: 1.1211 - val_accuracy: 0.6367\n",
      "Epoch 252/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4364 - accuracy: 0.8225 - val_loss: 1.0842 - val_accuracy: 0.6523\n",
      "Epoch 253/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.4604 - accuracy: 0.8185 - val_loss: 1.0575 - val_accuracy: 0.5781\n",
      "Epoch 254/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.4470 - accuracy: 0.8188 - val_loss: 1.1801 - val_accuracy: 0.6211\n",
      "Epoch 255/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4423 - accuracy: 0.8308 - val_loss: 1.1787 - val_accuracy: 0.5977\n",
      "Epoch 256/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4129 - accuracy: 0.8499 - val_loss: 1.0071 - val_accuracy: 0.6680\n",
      "Epoch 257/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4391 - accuracy: 0.8375 - val_loss: 1.0259 - val_accuracy: 0.6094\n",
      "Epoch 258/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4578 - accuracy: 0.8242 - val_loss: 0.9674 - val_accuracy: 0.6523\n",
      "Epoch 259/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4334 - accuracy: 0.8299 - val_loss: 1.0603 - val_accuracy: 0.6211\n",
      "Epoch 260/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4556 - accuracy: 0.8242 - val_loss: 1.0214 - val_accuracy: 0.6094\n",
      "Epoch 261/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4091 - accuracy: 0.8480 - val_loss: 0.9440 - val_accuracy: 0.6523\n",
      "Epoch 262/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4042 - accuracy: 0.8460 - val_loss: 1.1231 - val_accuracy: 0.6250\n",
      "Epoch 263/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4518 - accuracy: 0.8139 - val_loss: 1.0274 - val_accuracy: 0.6289\n",
      "Epoch 264/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4060 - accuracy: 0.8493 - val_loss: 1.0870 - val_accuracy: 0.5820\n",
      "Epoch 265/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4804 - accuracy: 0.8162 - val_loss: 1.0342 - val_accuracy: 0.6367\n",
      "Epoch 266/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4336 - accuracy: 0.8308 - val_loss: 1.0244 - val_accuracy: 0.6367\n",
      "Epoch 267/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4329 - accuracy: 0.8252 - val_loss: 1.0188 - val_accuracy: 0.7070\n",
      "Epoch 268/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.4462 - accuracy: 0.8341 - val_loss: 1.0508 - val_accuracy: 0.6484\n",
      "Epoch 269/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4303 - accuracy: 0.8361 - val_loss: 0.9607 - val_accuracy: 0.6445\n",
      "Epoch 270/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.4145 - accuracy: 0.8404 - val_loss: 1.2033 - val_accuracy: 0.5977\n",
      "Epoch 271/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4262 - accuracy: 0.8438 - val_loss: 1.1372 - val_accuracy: 0.6406\n",
      "Epoch 272/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4127 - accuracy: 0.8412 - val_loss: 1.0672 - val_accuracy: 0.6523\n",
      "Epoch 273/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4387 - accuracy: 0.8252 - val_loss: 0.9905 - val_accuracy: 0.6602\n",
      "Epoch 274/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4193 - accuracy: 0.8442 - val_loss: 1.2160 - val_accuracy: 0.6055\n",
      "Epoch 275/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4127 - accuracy: 0.8419 - val_loss: 1.0443 - val_accuracy: 0.6289\n",
      "Epoch 276/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4003 - accuracy: 0.8506 - val_loss: 0.9518 - val_accuracy: 0.6523\n",
      "Epoch 277/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4527 - accuracy: 0.8229 - val_loss: 1.0260 - val_accuracy: 0.6094\n",
      "Epoch 278/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3986 - accuracy: 0.8466 - val_loss: 1.1749 - val_accuracy: 0.5938\n",
      "Epoch 279/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4060 - accuracy: 0.8494 - val_loss: 1.0322 - val_accuracy: 0.6406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4006 - accuracy: 0.8459 - val_loss: 1.0467 - val_accuracy: 0.6055\n",
      "Epoch 281/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3790 - accuracy: 0.8491 - val_loss: 1.0424 - val_accuracy: 0.5820\n",
      "Epoch 282/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3898 - accuracy: 0.8471 - val_loss: 1.1558 - val_accuracy: 0.6289\n",
      "Epoch 283/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3692 - accuracy: 0.8613 - val_loss: 1.0305 - val_accuracy: 0.6016\n",
      "Epoch 284/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.3954 - accuracy: 0.8467 - val_loss: 1.2667 - val_accuracy: 0.6016\n",
      "Epoch 285/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4142 - accuracy: 0.8458 - val_loss: 1.1496 - val_accuracy: 0.6172\n",
      "Epoch 286/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3879 - accuracy: 0.8459 - val_loss: 0.9746 - val_accuracy: 0.6602\n",
      "Epoch 287/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4016 - accuracy: 0.8501 - val_loss: 0.9845 - val_accuracy: 0.6367\n",
      "Epoch 288/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4092 - accuracy: 0.8436 - val_loss: 1.1107 - val_accuracy: 0.6289\n",
      "Epoch 289/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3800 - accuracy: 0.8476 - val_loss: 1.0878 - val_accuracy: 0.6172\n",
      "Epoch 290/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4190 - accuracy: 0.8404 - val_loss: 1.1585 - val_accuracy: 0.5820\n",
      "Epoch 291/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3888 - accuracy: 0.8552 - val_loss: 1.0324 - val_accuracy: 0.6094\n",
      "Epoch 292/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3840 - accuracy: 0.8448 - val_loss: 0.9895 - val_accuracy: 0.5938\n",
      "Epoch 293/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3924 - accuracy: 0.8452 - val_loss: 1.0055 - val_accuracy: 0.6172\n",
      "Epoch 294/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3579 - accuracy: 0.8680 - val_loss: 1.1152 - val_accuracy: 0.6289\n",
      "Epoch 295/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3641 - accuracy: 0.8588 - val_loss: 1.1944 - val_accuracy: 0.5898\n",
      "Epoch 296/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.4082 - accuracy: 0.8357 - val_loss: 1.0585 - val_accuracy: 0.6367\n",
      "Epoch 297/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3805 - accuracy: 0.8548 - val_loss: 1.1134 - val_accuracy: 0.6133\n",
      "Epoch 298/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3901 - accuracy: 0.8498 - val_loss: 1.1212 - val_accuracy: 0.6367\n",
      "Epoch 299/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3921 - accuracy: 0.8506 - val_loss: 1.0161 - val_accuracy: 0.6055\n",
      "Epoch 300/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3701 - accuracy: 0.8607 - val_loss: 1.1496 - val_accuracy: 0.6016\n",
      "Epoch 301/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3866 - accuracy: 0.8625 - val_loss: 1.0266 - val_accuracy: 0.6289\n",
      "Epoch 302/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3762 - accuracy: 0.8508 - val_loss: 1.0890 - val_accuracy: 0.6055\n",
      "Epoch 303/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3559 - accuracy: 0.8634 - val_loss: 1.0101 - val_accuracy: 0.6211\n",
      "Epoch 304/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.4016 - accuracy: 0.8465 - val_loss: 1.0998 - val_accuracy: 0.5898\n",
      "Epoch 305/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3837 - accuracy: 0.8423 - val_loss: 1.1255 - val_accuracy: 0.6445\n",
      "Epoch 306/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3881 - accuracy: 0.8565 - val_loss: 1.0801 - val_accuracy: 0.6055\n",
      "Epoch 307/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3560 - accuracy: 0.8710 - val_loss: 1.0853 - val_accuracy: 0.6523\n",
      "Epoch 308/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4000 - accuracy: 0.8477 - val_loss: 1.0085 - val_accuracy: 0.6445\n",
      "Epoch 309/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3610 - accuracy: 0.8550 - val_loss: 1.0728 - val_accuracy: 0.6094\n",
      "Epoch 310/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3577 - accuracy: 0.8657 - val_loss: 1.2346 - val_accuracy: 0.6055\n",
      "Epoch 311/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3712 - accuracy: 0.8595 - val_loss: 1.0527 - val_accuracy: 0.6250\n",
      "Epoch 312/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3760 - accuracy: 0.8579 - val_loss: 1.1800 - val_accuracy: 0.6328\n",
      "Epoch 313/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3596 - accuracy: 0.8614 - val_loss: 1.0938 - val_accuracy: 0.6250\n",
      "Epoch 314/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3563 - accuracy: 0.8671 - val_loss: 1.1408 - val_accuracy: 0.6562\n",
      "Epoch 315/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3726 - accuracy: 0.8578 - val_loss: 1.0340 - val_accuracy: 0.5898\n",
      "Epoch 316/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3739 - accuracy: 0.8561 - val_loss: 1.0445 - val_accuracy: 0.6289\n",
      "Epoch 317/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3421 - accuracy: 0.8672 - val_loss: 1.0608 - val_accuracy: 0.6562\n",
      "Epoch 318/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3537 - accuracy: 0.8701 - val_loss: 1.0691 - val_accuracy: 0.6172\n",
      "Epoch 319/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.3353 - accuracy: 0.8656 - val_loss: 1.1024 - val_accuracy: 0.6289\n",
      "Epoch 320/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3524 - accuracy: 0.8679 - val_loss: 1.0865 - val_accuracy: 0.6211\n",
      "Epoch 321/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3344 - accuracy: 0.8708 - val_loss: 1.2197 - val_accuracy: 0.6055\n",
      "Epoch 322/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3407 - accuracy: 0.8694 - val_loss: 1.0960 - val_accuracy: 0.6602\n",
      "Epoch 323/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3641 - accuracy: 0.8650 - val_loss: 1.0670 - val_accuracy: 0.6445\n",
      "Epoch 324/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3341 - accuracy: 0.8708 - val_loss: 1.2828 - val_accuracy: 0.6133\n",
      "Epoch 325/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3308 - accuracy: 0.8718 - val_loss: 1.2293 - val_accuracy: 0.6289\n",
      "Epoch 326/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3815 - accuracy: 0.8633 - val_loss: 1.0451 - val_accuracy: 0.6445\n",
      "Epoch 327/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3477 - accuracy: 0.8663 - val_loss: 1.3343 - val_accuracy: 0.6328\n",
      "Epoch 328/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3390 - accuracy: 0.8672 - val_loss: 1.3260 - val_accuracy: 0.6328\n",
      "Epoch 329/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3481 - accuracy: 0.8682 - val_loss: 1.1874 - val_accuracy: 0.6133\n",
      "Epoch 330/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3702 - accuracy: 0.8645 - val_loss: 1.0719 - val_accuracy: 0.6445\n",
      "Epoch 331/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3135 - accuracy: 0.8892 - val_loss: 1.3438 - val_accuracy: 0.6016\n",
      "Epoch 332/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3323 - accuracy: 0.8705 - val_loss: 1.1683 - val_accuracy: 0.6289\n",
      "Epoch 333/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3289 - accuracy: 0.8747 - val_loss: 1.1650 - val_accuracy: 0.6445\n",
      "Epoch 334/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3337 - accuracy: 0.8709 - val_loss: 1.1333 - val_accuracy: 0.6172\n",
      "Epoch 335/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3385 - accuracy: 0.8667 - val_loss: 1.1682 - val_accuracy: 0.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3330 - accuracy: 0.8783 - val_loss: 1.1493 - val_accuracy: 0.6289\n",
      "Epoch 337/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3286 - accuracy: 0.8706 - val_loss: 1.3524 - val_accuracy: 0.6289\n",
      "Epoch 338/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3169 - accuracy: 0.8742 - val_loss: 1.0841 - val_accuracy: 0.6445\n",
      "Epoch 339/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3442 - accuracy: 0.8728 - val_loss: 1.1304 - val_accuracy: 0.6641\n",
      "Epoch 340/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3474 - accuracy: 0.8751 - val_loss: 1.2699 - val_accuracy: 0.6094\n",
      "Epoch 341/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3219 - accuracy: 0.8786 - val_loss: 1.0098 - val_accuracy: 0.6641\n",
      "Epoch 342/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3097 - accuracy: 0.8749 - val_loss: 1.3201 - val_accuracy: 0.6367\n",
      "Epoch 343/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3205 - accuracy: 0.8724 - val_loss: 1.1835 - val_accuracy: 0.6406\n",
      "Epoch 344/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3613 - accuracy: 0.8572 - val_loss: 1.1505 - val_accuracy: 0.6562\n",
      "Epoch 345/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2826 - accuracy: 0.8957 - val_loss: 1.1421 - val_accuracy: 0.6367\n",
      "Epoch 346/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3411 - accuracy: 0.8750 - val_loss: 1.2095 - val_accuracy: 0.6445\n",
      "Epoch 347/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3223 - accuracy: 0.8807 - val_loss: 1.0915 - val_accuracy: 0.6484\n",
      "Epoch 348/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3084 - accuracy: 0.8859 - val_loss: 1.2396 - val_accuracy: 0.5898\n",
      "Epoch 349/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2993 - accuracy: 0.8890 - val_loss: 1.2474 - val_accuracy: 0.6328\n",
      "Epoch 350/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3312 - accuracy: 0.8698 - val_loss: 1.1055 - val_accuracy: 0.5898\n",
      "Epoch 351/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3128 - accuracy: 0.8756 - val_loss: 1.1471 - val_accuracy: 0.6406\n",
      "Epoch 352/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3228 - accuracy: 0.8846 - val_loss: 1.1604 - val_accuracy: 0.6445\n",
      "Epoch 353/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2637 - accuracy: 0.9011 - val_loss: 1.1575 - val_accuracy: 0.6797\n",
      "Epoch 354/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2956 - accuracy: 0.8916 - val_loss: 1.2485 - val_accuracy: 0.6250\n",
      "Epoch 355/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3285 - accuracy: 0.8785 - val_loss: 1.2025 - val_accuracy: 0.6172\n",
      "Epoch 356/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3255 - accuracy: 0.8744 - val_loss: 1.0242 - val_accuracy: 0.6367\n",
      "Epoch 357/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2690 - accuracy: 0.8923 - val_loss: 1.2405 - val_accuracy: 0.6289\n",
      "Epoch 358/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3018 - accuracy: 0.8859 - val_loss: 1.1902 - val_accuracy: 0.6602\n",
      "Epoch 359/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3038 - accuracy: 0.8766 - val_loss: 1.1585 - val_accuracy: 0.6289\n",
      "Epoch 360/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2893 - accuracy: 0.8845 - val_loss: 1.2109 - val_accuracy: 0.6602\n",
      "Epoch 361/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.3072 - accuracy: 0.8851 - val_loss: 1.2280 - val_accuracy: 0.6406\n",
      "Epoch 362/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2797 - accuracy: 0.8948 - val_loss: 1.1859 - val_accuracy: 0.6406\n",
      "Epoch 363/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3144 - accuracy: 0.8800 - val_loss: 1.1491 - val_accuracy: 0.6680\n",
      "Epoch 364/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2926 - accuracy: 0.8891 - val_loss: 1.1284 - val_accuracy: 0.6211\n",
      "Epoch 365/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3040 - accuracy: 0.8815 - val_loss: 1.2268 - val_accuracy: 0.6328\n",
      "Epoch 366/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2882 - accuracy: 0.8834 - val_loss: 1.3060 - val_accuracy: 0.6250\n",
      "Epoch 367/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2962 - accuracy: 0.8868 - val_loss: 1.1622 - val_accuracy: 0.6523\n",
      "Epoch 368/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2891 - accuracy: 0.8894 - val_loss: 1.2200 - val_accuracy: 0.6367\n",
      "Epoch 369/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.3033 - accuracy: 0.8816 - val_loss: 1.3003 - val_accuracy: 0.6094\n",
      "Epoch 370/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2802 - accuracy: 0.8926 - val_loss: 1.2071 - val_accuracy: 0.6406\n",
      "Epoch 371/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2908 - accuracy: 0.8856 - val_loss: 1.1249 - val_accuracy: 0.6523\n",
      "Epoch 372/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2851 - accuracy: 0.8988 - val_loss: 1.2636 - val_accuracy: 0.6211\n",
      "Epoch 373/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.3036 - accuracy: 0.8858 - val_loss: 1.1132 - val_accuracy: 0.6172\n",
      "Epoch 374/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2850 - accuracy: 0.8943 - val_loss: 1.3933 - val_accuracy: 0.6133\n",
      "Epoch 375/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 0.2919 - accuracy: 0.8947 - val_loss: 1.3310 - val_accuracy: 0.6523\n",
      "Epoch 376/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.2572 - accuracy: 0.9085 - val_loss: 1.2514 - val_accuracy: 0.6289\n",
      "Epoch 377/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.2858 - accuracy: 0.8841 - val_loss: 1.2386 - val_accuracy: 0.6484\n",
      "Epoch 378/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.2828 - accuracy: 0.8935 - val_loss: 1.4203 - val_accuracy: 0.6328\n",
      "Epoch 379/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.3122 - accuracy: 0.8784 - val_loss: 1.2109 - val_accuracy: 0.6289\n",
      "Epoch 380/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.2938 - accuracy: 0.8987 - val_loss: 1.2798 - val_accuracy: 0.6641\n",
      "Epoch 381/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2762 - accuracy: 0.8857 - val_loss: 1.3082 - val_accuracy: 0.6523\n",
      "Epoch 382/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2786 - accuracy: 0.9116 - val_loss: 1.2046 - val_accuracy: 0.6094\n",
      "Epoch 383/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2874 - accuracy: 0.8856 - val_loss: 1.3096 - val_accuracy: 0.6602\n",
      "Epoch 384/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2912 - accuracy: 0.8886 - val_loss: 1.2940 - val_accuracy: 0.5898\n",
      "Epoch 385/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2665 - accuracy: 0.8978 - val_loss: 1.4012 - val_accuracy: 0.5938\n",
      "Epoch 386/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2528 - accuracy: 0.8993 - val_loss: 1.2108 - val_accuracy: 0.6523\n",
      "Epoch 387/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2562 - accuracy: 0.9032 - val_loss: 1.3297 - val_accuracy: 0.6055\n",
      "Epoch 388/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2719 - accuracy: 0.8990 - val_loss: 1.3485 - val_accuracy: 0.6094\n",
      "Epoch 389/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.2732 - accuracy: 0.9001 - val_loss: 1.1613 - val_accuracy: 0.6406\n",
      "Epoch 390/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2650 - accuracy: 0.8962 - val_loss: 1.3679 - val_accuracy: 0.6289\n",
      "Epoch 391/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2573 - accuracy: 0.9030 - val_loss: 1.2224 - val_accuracy: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2738 - accuracy: 0.8995 - val_loss: 1.2251 - val_accuracy: 0.6445\n",
      "Epoch 393/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2732 - accuracy: 0.8994 - val_loss: 1.2751 - val_accuracy: 0.6328\n",
      "Epoch 394/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2611 - accuracy: 0.9049 - val_loss: 1.1816 - val_accuracy: 0.6406\n",
      "Epoch 395/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2380 - accuracy: 0.9095 - val_loss: 1.1117 - val_accuracy: 0.6484\n",
      "Epoch 396/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2718 - accuracy: 0.9016 - val_loss: 1.4047 - val_accuracy: 0.5977\n",
      "Epoch 397/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2777 - accuracy: 0.8930 - val_loss: 1.3296 - val_accuracy: 0.6172\n",
      "Epoch 398/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2725 - accuracy: 0.8904 - val_loss: 1.2160 - val_accuracy: 0.6680\n",
      "Epoch 399/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2571 - accuracy: 0.9096 - val_loss: 1.4304 - val_accuracy: 0.6250\n",
      "Epoch 400/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2524 - accuracy: 0.9098 - val_loss: 1.4400 - val_accuracy: 0.6094\n",
      "Epoch 401/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2704 - accuracy: 0.8994 - val_loss: 1.4524 - val_accuracy: 0.6484\n",
      "Epoch 402/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2602 - accuracy: 0.9083 - val_loss: 1.4458 - val_accuracy: 0.6211\n",
      "Epoch 403/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2565 - accuracy: 0.9048 - val_loss: 1.3328 - val_accuracy: 0.6016\n",
      "Epoch 404/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2530 - accuracy: 0.9104 - val_loss: 1.4584 - val_accuracy: 0.5859\n",
      "Epoch 405/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2819 - accuracy: 0.9049 - val_loss: 1.3892 - val_accuracy: 0.5859\n",
      "Epoch 406/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.2789 - accuracy: 0.8933 - val_loss: 1.3880 - val_accuracy: 0.6133\n",
      "Epoch 407/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2654 - accuracy: 0.8957 - val_loss: 1.3190 - val_accuracy: 0.6172\n",
      "Epoch 408/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2159 - accuracy: 0.9216 - val_loss: 1.3735 - val_accuracy: 0.6367\n",
      "Epoch 409/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2601 - accuracy: 0.8958 - val_loss: 1.3660 - val_accuracy: 0.6094\n",
      "Epoch 410/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2521 - accuracy: 0.9037 - val_loss: 1.3060 - val_accuracy: 0.6523\n",
      "Epoch 411/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2495 - accuracy: 0.9050 - val_loss: 1.2523 - val_accuracy: 0.6406\n",
      "Epoch 412/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2399 - accuracy: 0.9090 - val_loss: 1.3477 - val_accuracy: 0.5820\n",
      "Epoch 413/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2588 - accuracy: 0.9034 - val_loss: 1.3369 - val_accuracy: 0.6133\n",
      "Epoch 414/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.2615 - accuracy: 0.8998 - val_loss: 1.2331 - val_accuracy: 0.6445\n",
      "Epoch 415/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2392 - accuracy: 0.9119 - val_loss: 1.1418 - val_accuracy: 0.6562\n",
      "Epoch 416/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.2570 - accuracy: 0.9128 - val_loss: 1.1868 - val_accuracy: 0.6484\n",
      "Epoch 417/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2445 - accuracy: 0.9077 - val_loss: 1.2413 - val_accuracy: 0.6250\n",
      "Epoch 418/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2297 - accuracy: 0.9125 - val_loss: 1.4848 - val_accuracy: 0.6367\n",
      "Epoch 419/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2470 - accuracy: 0.9060 - val_loss: 1.3917 - val_accuracy: 0.6133\n",
      "Epoch 420/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2321 - accuracy: 0.9169 - val_loss: 1.3305 - val_accuracy: 0.6641\n",
      "Epoch 421/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2519 - accuracy: 0.9075 - val_loss: 1.4469 - val_accuracy: 0.6328\n",
      "Epoch 422/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2293 - accuracy: 0.9170 - val_loss: 1.3053 - val_accuracy: 0.6719\n",
      "Epoch 423/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2518 - accuracy: 0.9078 - val_loss: 1.2745 - val_accuracy: 0.6367\n",
      "Epoch 424/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2645 - accuracy: 0.9035 - val_loss: 1.3647 - val_accuracy: 0.5664\n",
      "Epoch 425/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2145 - accuracy: 0.9191 - val_loss: 1.4491 - val_accuracy: 0.5781\n",
      "Epoch 426/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.2607 - accuracy: 0.9009 - val_loss: 1.2604 - val_accuracy: 0.6719\n",
      "Epoch 427/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2131 - accuracy: 0.9246 - val_loss: 1.3747 - val_accuracy: 0.6523\n",
      "Epoch 428/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2587 - accuracy: 0.9024 - val_loss: 1.3881 - val_accuracy: 0.6094\n",
      "Epoch 429/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2074 - accuracy: 0.9272 - val_loss: 1.5466 - val_accuracy: 0.6328\n",
      "Epoch 430/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.2485 - accuracy: 0.9091 - val_loss: 1.4763 - val_accuracy: 0.6133\n",
      "Epoch 431/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2447 - accuracy: 0.9101 - val_loss: 1.2559 - val_accuracy: 0.6250\n",
      "Epoch 432/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 0.2197 - accuracy: 0.9200 - val_loss: 1.4085 - val_accuracy: 0.6328\n",
      "Epoch 433/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2271 - accuracy: 0.9212 - val_loss: 1.3143 - val_accuracy: 0.6367\n",
      "Epoch 434/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2213 - accuracy: 0.9141 - val_loss: 1.2627 - val_accuracy: 0.6484\n",
      "Epoch 435/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.2200 - accuracy: 0.9191 - val_loss: 1.8534 - val_accuracy: 0.6016\n",
      "Epoch 436/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2394 - accuracy: 0.9113 - val_loss: 1.5032 - val_accuracy: 0.5977\n",
      "Epoch 437/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 0.2282 - accuracy: 0.9120 - val_loss: 1.6124 - val_accuracy: 0.6289\n",
      "Epoch 438/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 0.2338 - accuracy: 0.9126 - val_loss: 1.4713 - val_accuracy: 0.5938\n",
      "Epoch 439/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.2703 - accuracy: 0.9017 - val_loss: 1.5031 - val_accuracy: 0.6211\n",
      "Epoch 440/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2295 - accuracy: 0.9212 - val_loss: 1.4106 - val_accuracy: 0.6523\n",
      "Epoch 441/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2267 - accuracy: 0.9163 - val_loss: 1.4770 - val_accuracy: 0.6016\n",
      "Epoch 442/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 0.2309 - accuracy: 0.9144 - val_loss: 1.4086 - val_accuracy: 0.6523\n",
      "Epoch 443/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 0.2256 - accuracy: 0.9148 - val_loss: 1.3994 - val_accuracy: 0.5938\n",
      "Epoch 444/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2143 - accuracy: 0.9272 - val_loss: 1.3085 - val_accuracy: 0.6797\n",
      "Epoch 445/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.2360 - accuracy: 0.9141 - val_loss: 1.4069 - val_accuracy: 0.6367\n",
      "Epoch 446/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2386 - accuracy: 0.9108 - val_loss: 1.4491 - val_accuracy: 0.6484\n",
      "Epoch 447/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2209 - accuracy: 0.9127 - val_loss: 1.4045 - val_accuracy: 0.6133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/4000\n",
      "128/128 [==============================] - 8s 58ms/step - loss: 0.2456 - accuracy: 0.9132 - val_loss: 1.4265 - val_accuracy: 0.6328\n",
      "Epoch 449/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.2091 - accuracy: 0.9256 - val_loss: 1.3584 - val_accuracy: 0.6094\n",
      "Epoch 450/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2289 - accuracy: 0.9209 - val_loss: 1.2575 - val_accuracy: 0.6367\n",
      "Epoch 451/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2426 - accuracy: 0.9130 - val_loss: 1.3876 - val_accuracy: 0.6367\n",
      "Epoch 452/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2444 - accuracy: 0.9169 - val_loss: 1.4387 - val_accuracy: 0.6016\n",
      "Epoch 453/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2085 - accuracy: 0.9221 - val_loss: 1.4996 - val_accuracy: 0.6016\n",
      "Epoch 454/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2140 - accuracy: 0.9142 - val_loss: 1.4982 - val_accuracy: 0.5938\n",
      "Epoch 455/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.2151 - accuracy: 0.9223 - val_loss: 1.4419 - val_accuracy: 0.6250\n",
      "Epoch 456/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 0.2102 - accuracy: 0.9276 - val_loss: 1.4741 - val_accuracy: 0.6328\n",
      "Epoch 457/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 0.2085 - accuracy: 0.9233 - val_loss: 1.6102 - val_accuracy: 0.6328\n",
      "Epoch 458/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.1924 - accuracy: 0.9268 - val_loss: 1.4093 - val_accuracy: 0.6133\n",
      "Epoch 459/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 0.2257 - accuracy: 0.9135 - val_loss: 1.5121 - val_accuracy: 0.6211\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00459: early stopping\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 0.6472 - accuracy: 0.7329\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.8157 - accuracy: 0.6406\n",
      "Train: 0.733, Val: 0.641\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit model\n",
    "\n",
    "history = AlexNet.fit(training_set,\n",
    "        epochs=4000,\n",
    "        validation_data=val_set,\n",
    "        verbose = 1, \n",
    "        validation_steps = len(val_set),\n",
    "        callbacks = [es])\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = AlexNet.evaluate(training_set, verbose=1)\n",
    "_, val_acc = AlexNet.evaluate(val_set, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "AlexNet.save(r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Models\\Alex.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 2s 5ms/step - loss: 0.7521 - accuracy: 0.6965\n",
      "Test loss: 0.7520561218261719\n",
      "Test accuracy: 0.6964980363845825\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = AlexNet.evaluate(test_set)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = AlexNet.predict(test_set,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = test_set.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = test_set.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "alex_predictions = pd.DataFrame({'Filename': filenames,'AlexNet': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(alex_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del alex_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>AlexNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample3-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample4-sperm15.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm17.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm2.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>class3\\image_036.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>class3\\image_038.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>class3\\image_040.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>class3\\image_048.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>class3\\image_051.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test  Model_1  AlexNet\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     0        3        1\n",
       "1     class0\\ch00_p1-pl2-sample3-sperm4.tif      0     1        0        0\n",
       "2    class0\\ch00_p1-pl2-sample4-sperm15.tif      0     3        3        3\n",
       "3    class0\\ch00_p1-pl3-sample1-sperm17.tif      0     3        3        1\n",
       "4     class0\\ch00_p1-pl3-sample1-sperm2.tif      0     3        0        3\n",
       "..                                      ...    ...   ...      ...      ...\n",
       "252                    class3\\image_036.BMP      3     3        3        3\n",
       "253                    class3\\image_038.BMP      3     2        3        1\n",
       "254                    class3\\image_040.BMP      3     2        3        3\n",
       "255                    class3\\image_048.BMP      3     3        3        3\n",
       "256                    class3\\image_051.BMP      3     3        1        3\n",
       "\n",
       "[257 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  7  1 21]\n",
      " [ 7  6  2 42]\n",
      " [ 2  7  3 15]\n",
      " [25 16 12 89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.06      0.06      0.06        31\n",
      "      class1       0.17      0.11      0.13        57\n",
      "      class2       0.17      0.11      0.13        27\n",
      "      class3       0.53      0.63      0.58       142\n",
      "\n",
      "    accuracy                           0.39       257\n",
      "   macro avg       0.23      0.23      0.22       257\n",
      "weighted avg       0.36      0.39      0.37       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix and classification report\n",
    "class_labels = list(test_set.class_indices.keys())   \n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4096 images belonging to 4 classes.\n",
      "Found 256 images belonging to 4 classes.\n",
      "Found 257 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#resnet50 requires its own preprocessing \n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "#to play around with these\n",
    "res50train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   preprocessing_function=preprocess_input,\n",
    "                                   rotation_range = 5,\n",
    "                                   width_shift_range = 0.06, \n",
    "                                   height_shift_range = 0.06, \n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.2], \n",
    "                                   fill_mode='nearest',\n",
    "                                   zoom_range = 0.2,\n",
    "                                   ) \n",
    "\n",
    "res50val_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "res50test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "#test different color maps -  class modes and cross validation types\n",
    "res_train = res50train_datagen.flow_from_directory(path+'/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 color_mode = 'rgb',\n",
    "                                                 shuffle = True)\n",
    "\n",
    "res_val = res50val_datagen.flow_from_directory(path+'/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb',\n",
    "                                            shuffle = True)\n",
    "\n",
    "res_test = res50test_datagen.flow_from_directory(path+'/test',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb',\n",
    "                                            shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "res50model = Sequential()\n",
    "\n",
    "#Layer 1: RES50 without top layer\n",
    "res50model.add(ResNet50(weights='imagenet', input_shape= (32,32,3),\n",
    "                 include_top = False, classes=5,))\n",
    "\n",
    "#Layer 2: RES50 without top layer\n",
    "res50model.add(Flatten())\n",
    "res50model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "#freeze layers in resnet - weights obtained with IMAGENET challenge, we only train final layer\n",
    "res50model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res50model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res50model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "\n",
    "res50model.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "128/128 [==============================] - 12s 66ms/step - loss: 1.6307 - accuracy: 0.2371 - val_loss: 1.2577 - val_accuracy: 0.5547\n",
      "Epoch 2/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.3917 - accuracy: 0.2820 - val_loss: 1.3511 - val_accuracy: 0.2031\n",
      "Epoch 3/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.3579 - accuracy: 0.3119 - val_loss: 1.5565 - val_accuracy: 0.2305\n",
      "Epoch 4/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3789 - accuracy: 0.3316 - val_loss: 1.3511 - val_accuracy: 0.2227\n",
      "Epoch 5/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.3607 - accuracy: 0.3118 - val_loss: 1.3771 - val_accuracy: 0.2891\n",
      "Epoch 6/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3425 - accuracy: 0.3366 - val_loss: 1.3302 - val_accuracy: 0.3164\n",
      "Epoch 7/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3440 - accuracy: 0.3550 - val_loss: 1.2140 - val_accuracy: 0.5547\n",
      "Epoch 8/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.3630 - accuracy: 0.3446 - val_loss: 1.3284 - val_accuracy: 0.3945\n",
      "Epoch 9/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3458 - accuracy: 0.3480 - val_loss: 1.3081 - val_accuracy: 0.3281\n",
      "Epoch 10/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3381 - accuracy: 0.3620 - val_loss: 1.4454 - val_accuracy: 0.2031\n",
      "Epoch 11/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.3684 - accuracy: 0.3195 - val_loss: 1.3897 - val_accuracy: 0.2109\n",
      "Epoch 12/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3476 - accuracy: 0.3458 - val_loss: 1.2570 - val_accuracy: 0.4609\n",
      "Epoch 13/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3254 - accuracy: 0.3638 - val_loss: 1.4386 - val_accuracy: 0.2305\n",
      "Epoch 14/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3355 - accuracy: 0.3642 - val_loss: 1.2457 - val_accuracy: 0.5391\n",
      "Epoch 15/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3215 - accuracy: 0.3636 - val_loss: 1.3625 - val_accuracy: 0.3125\n",
      "Epoch 16/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3268 - accuracy: 0.3671 - val_loss: 1.2671 - val_accuracy: 0.5508\n",
      "Epoch 17/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3298 - accuracy: 0.3645 - val_loss: 1.2994 - val_accuracy: 0.4570\n",
      "Epoch 18/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3250 - accuracy: 0.3818 - val_loss: 1.4022 - val_accuracy: 0.2188\n",
      "Epoch 19/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3101 - accuracy: 0.3685 - val_loss: 1.2162 - val_accuracy: 0.5547\n",
      "Epoch 20/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3315 - accuracy: 0.3702 - val_loss: 1.4768 - val_accuracy: 0.2383\n",
      "Epoch 21/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3132 - accuracy: 0.3729 - val_loss: 1.4431 - val_accuracy: 0.2266\n",
      "Epoch 22/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3097 - accuracy: 0.3722 - val_loss: 1.4721 - val_accuracy: 0.2422\n",
      "Epoch 23/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3466 - accuracy: 0.3493 - val_loss: 1.4424 - val_accuracy: 0.2500\n",
      "Epoch 24/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3383 - accuracy: 0.3640 - val_loss: 1.3950 - val_accuracy: 0.2383\n",
      "Epoch 25/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3171 - accuracy: 0.3737 - val_loss: 1.2953 - val_accuracy: 0.4414\n",
      "Epoch 26/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3120 - accuracy: 0.3784 - val_loss: 1.3684 - val_accuracy: 0.2461\n",
      "Epoch 27/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2987 - accuracy: 0.3826 - val_loss: 1.2785 - val_accuracy: 0.4219\n",
      "Epoch 28/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3049 - accuracy: 0.3717 - val_loss: 1.6477 - val_accuracy: 0.2500\n",
      "Epoch 29/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3118 - accuracy: 0.3702 - val_loss: 1.3814 - val_accuracy: 0.2891\n",
      "Epoch 30/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3227 - accuracy: 0.3645 - val_loss: 1.4504 - val_accuracy: 0.2500\n",
      "Epoch 31/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3257 - accuracy: 0.3727 - val_loss: 1.3402 - val_accuracy: 0.2461\n",
      "Epoch 32/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3245 - accuracy: 0.3694 - val_loss: 1.1693 - val_accuracy: 0.5547\n",
      "Epoch 33/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.3247 - accuracy: 0.3730 - val_loss: 1.3800 - val_accuracy: 0.2734\n",
      "Epoch 34/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3035 - accuracy: 0.3731 - val_loss: 1.2699 - val_accuracy: 0.3711\n",
      "Epoch 35/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.3356 - accuracy: 0.3695 - val_loss: 1.1996 - val_accuracy: 0.5469\n",
      "Epoch 36/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.3135 - accuracy: 0.3782 - val_loss: 1.4306 - val_accuracy: 0.2227\n",
      "Epoch 37/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2971 - accuracy: 0.3828 - val_loss: 1.4795 - val_accuracy: 0.2109\n",
      "Epoch 38/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3016 - accuracy: 0.3716 - val_loss: 1.3662 - val_accuracy: 0.2930\n",
      "Epoch 39/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.3129 - accuracy: 0.3645 - val_loss: 1.3525 - val_accuracy: 0.2852\n",
      "Epoch 40/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.3046 - accuracy: 0.3766 - val_loss: 1.3642 - val_accuracy: 0.3359\n",
      "Epoch 41/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2929 - accuracy: 0.3674 - val_loss: 1.2190 - val_accuracy: 0.4805\n",
      "Epoch 42/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2806 - accuracy: 0.4001 - val_loss: 1.3316 - val_accuracy: 0.3594\n",
      "Epoch 43/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3029 - accuracy: 0.3830 - val_loss: 1.3787 - val_accuracy: 0.2383\n",
      "Epoch 44/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3035 - accuracy: 0.3871 - val_loss: 1.1662 - val_accuracy: 0.5781\n",
      "Epoch 45/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2881 - accuracy: 0.3893 - val_loss: 1.2792 - val_accuracy: 0.4844\n",
      "Epoch 46/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3075 - accuracy: 0.3695 - val_loss: 1.4972 - val_accuracy: 0.1484\n",
      "Epoch 47/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2983 - accuracy: 0.3915 - val_loss: 1.2941 - val_accuracy: 0.2891\n",
      "Epoch 48/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2881 - accuracy: 0.3902 - val_loss: 1.6079 - val_accuracy: 0.1758\n",
      "Epoch 49/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3039 - accuracy: 0.3869 - val_loss: 1.2162 - val_accuracy: 0.5156\n",
      "Epoch 50/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2996 - accuracy: 0.3860 - val_loss: 1.2988 - val_accuracy: 0.4883\n",
      "Epoch 51/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2880 - accuracy: 0.3848 - val_loss: 1.2244 - val_accuracy: 0.4688\n",
      "Epoch 52/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2947 - accuracy: 0.3969 - val_loss: 1.5987 - val_accuracy: 0.2227\n",
      "Epoch 53/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2884 - accuracy: 0.3990 - val_loss: 1.5878 - val_accuracy: 0.2461\n",
      "Epoch 54/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3083 - accuracy: 0.3880 - val_loss: 1.5461 - val_accuracy: 0.2656\n",
      "Epoch 55/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3024 - accuracy: 0.3768 - val_loss: 1.3927 - val_accuracy: 0.2656\n",
      "Epoch 56/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2798 - accuracy: 0.4037 - val_loss: 1.2282 - val_accuracy: 0.4062\n",
      "Epoch 57/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3025 - accuracy: 0.3798 - val_loss: 1.2191 - val_accuracy: 0.4531\n",
      "Epoch 58/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2877 - accuracy: 0.3920 - val_loss: 1.4136 - val_accuracy: 0.1523\n",
      "Epoch 59/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2907 - accuracy: 0.3975 - val_loss: 1.3491 - val_accuracy: 0.3633\n",
      "Epoch 60/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2794 - accuracy: 0.3829 - val_loss: 1.2695 - val_accuracy: 0.4023\n",
      "Epoch 61/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2697 - accuracy: 0.4107 - val_loss: 1.2509 - val_accuracy: 0.4102\n",
      "Epoch 62/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2806 - accuracy: 0.3959 - val_loss: 1.3556 - val_accuracy: 0.2852\n",
      "Epoch 63/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2780 - accuracy: 0.3908 - val_loss: 1.3614 - val_accuracy: 0.3555\n",
      "Epoch 64/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2745 - accuracy: 0.3999 - val_loss: 1.3914 - val_accuracy: 0.2656\n",
      "Epoch 65/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2638 - accuracy: 0.4148 - val_loss: 1.5013 - val_accuracy: 0.2266\n",
      "Epoch 66/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.3091 - accuracy: 0.3846 - val_loss: 1.3676 - val_accuracy: 0.3047\n",
      "Epoch 67/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2999 - accuracy: 0.3736 - val_loss: 1.3759 - val_accuracy: 0.2695\n",
      "Epoch 68/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2749 - accuracy: 0.4062 - val_loss: 1.2011 - val_accuracy: 0.5430\n",
      "Epoch 69/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2888 - accuracy: 0.3996 - val_loss: 1.2964 - val_accuracy: 0.4141\n",
      "Epoch 70/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2962 - accuracy: 0.3960 - val_loss: 1.5557 - val_accuracy: 0.1484\n",
      "Epoch 71/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.3191 - accuracy: 0.3757 - val_loss: 1.4008 - val_accuracy: 0.2617\n",
      "Epoch 72/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2779 - accuracy: 0.3833 - val_loss: 1.2477 - val_accuracy: 0.4141\n",
      "Epoch 73/4000\n",
      "128/128 [==============================] - 8s 58ms/step - loss: 1.2755 - accuracy: 0.3892 - val_loss: 1.2321 - val_accuracy: 0.5273\n",
      "Epoch 74/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.3047 - accuracy: 0.3839 - val_loss: 1.2296 - val_accuracy: 0.4922\n",
      "Epoch 75/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2731 - accuracy: 0.4057 - val_loss: 1.2474 - val_accuracy: 0.4180\n",
      "Epoch 76/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2945 - accuracy: 0.3759 - val_loss: 1.3599 - val_accuracy: 0.2539\n",
      "Epoch 77/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2695 - accuracy: 0.4140 - val_loss: 1.5957 - val_accuracy: 0.2500\n",
      "Epoch 78/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2789 - accuracy: 0.4090 - val_loss: 1.4465 - val_accuracy: 0.2227\n",
      "Epoch 79/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2813 - accuracy: 0.4060 - val_loss: 1.3283 - val_accuracy: 0.3398\n",
      "Epoch 80/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2732 - accuracy: 0.4200 - val_loss: 1.5819 - val_accuracy: 0.2305\n",
      "Epoch 81/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2872 - accuracy: 0.3862 - val_loss: 1.3733 - val_accuracy: 0.3203\n",
      "Epoch 82/4000\n",
      "128/128 [==============================] - 8s 58ms/step - loss: 1.2930 - accuracy: 0.3990 - val_loss: 1.1816 - val_accuracy: 0.5508\n",
      "Epoch 83/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2765 - accuracy: 0.3977 - val_loss: 1.2488 - val_accuracy: 0.5039\n",
      "Epoch 84/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2772 - accuracy: 0.4007 - val_loss: 1.4146 - val_accuracy: 0.2773\n",
      "Epoch 85/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2676 - accuracy: 0.4045 - val_loss: 1.1106 - val_accuracy: 0.5742\n",
      "Epoch 86/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2897 - accuracy: 0.3926 - val_loss: 1.4370 - val_accuracy: 0.2500\n",
      "Epoch 87/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2935 - accuracy: 0.3886 - val_loss: 1.3850 - val_accuracy: 0.2930\n",
      "Epoch 88/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2688 - accuracy: 0.4083 - val_loss: 1.4206 - val_accuracy: 0.2578\n",
      "Epoch 89/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2688 - accuracy: 0.3987 - val_loss: 1.3136 - val_accuracy: 0.3750\n",
      "Epoch 90/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2671 - accuracy: 0.4021 - val_loss: 1.2735 - val_accuracy: 0.3398\n",
      "Epoch 91/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2653 - accuracy: 0.4102 - val_loss: 1.4025 - val_accuracy: 0.2734\n",
      "Epoch 92/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2896 - accuracy: 0.3938 - val_loss: 1.2530 - val_accuracy: 0.3594\n",
      "Epoch 93/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2845 - accuracy: 0.4027 - val_loss: 1.4911 - val_accuracy: 0.2578\n",
      "Epoch 94/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2676 - accuracy: 0.4073 - val_loss: 1.2477 - val_accuracy: 0.3828\n",
      "Epoch 95/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2669 - accuracy: 0.4122 - val_loss: 1.3301 - val_accuracy: 0.3203\n",
      "Epoch 96/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2693 - accuracy: 0.4053 - val_loss: 1.1374 - val_accuracy: 0.5469\n",
      "Epoch 97/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2477 - accuracy: 0.4275 - val_loss: 1.7677 - val_accuracy: 0.2539\n",
      "Epoch 98/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.3080 - accuracy: 0.3924 - val_loss: 1.3751 - val_accuracy: 0.3086\n",
      "Epoch 99/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2752 - accuracy: 0.3910 - val_loss: 1.4209 - val_accuracy: 0.2422\n",
      "Epoch 100/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2541 - accuracy: 0.4236 - val_loss: 1.6676 - val_accuracy: 0.2617\n",
      "Epoch 101/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2572 - accuracy: 0.4297 - val_loss: 1.3827 - val_accuracy: 0.2930\n",
      "Epoch 102/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2761 - accuracy: 0.4065 - val_loss: 1.4106 - val_accuracy: 0.2500\n",
      "Epoch 103/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2924 - accuracy: 0.3802 - val_loss: 1.1834 - val_accuracy: 0.5430\n",
      "Epoch 104/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2643 - accuracy: 0.4140 - val_loss: 1.5015 - val_accuracy: 0.2383\n",
      "Epoch 105/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2715 - accuracy: 0.4077 - val_loss: 1.3936 - val_accuracy: 0.3086\n",
      "Epoch 106/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2752 - accuracy: 0.4113 - val_loss: 1.3164 - val_accuracy: 0.3789\n",
      "Epoch 107/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2396 - accuracy: 0.4329 - val_loss: 1.2745 - val_accuracy: 0.4922\n",
      "Epoch 108/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2732 - accuracy: 0.4055 - val_loss: 1.3570 - val_accuracy: 0.3555\n",
      "Epoch 109/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2667 - accuracy: 0.4030 - val_loss: 1.4331 - val_accuracy: 0.2695\n",
      "Epoch 110/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2680 - accuracy: 0.4108 - val_loss: 1.3203 - val_accuracy: 0.3242\n",
      "Epoch 111/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2685 - accuracy: 0.4093 - val_loss: 1.3343 - val_accuracy: 0.3594\n",
      "Epoch 112/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2645 - accuracy: 0.4066 - val_loss: 1.1393 - val_accuracy: 0.5586\n",
      "Epoch 113/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2737 - accuracy: 0.4081 - val_loss: 1.3633 - val_accuracy: 0.2891\n",
      "Epoch 114/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2712 - accuracy: 0.4034 - val_loss: 1.1943 - val_accuracy: 0.5352\n",
      "Epoch 115/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2724 - accuracy: 0.4000 - val_loss: 1.4675 - val_accuracy: 0.2578\n",
      "Epoch 116/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2710 - accuracy: 0.4071 - val_loss: 1.1931 - val_accuracy: 0.5312\n",
      "Epoch 117/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2644 - accuracy: 0.4045 - val_loss: 1.3507 - val_accuracy: 0.3242\n",
      "Epoch 118/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2541 - accuracy: 0.4090 - val_loss: 1.2999 - val_accuracy: 0.3555\n",
      "Epoch 119/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2671 - accuracy: 0.4121 - val_loss: 1.2437 - val_accuracy: 0.4570\n",
      "Epoch 120/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2896 - accuracy: 0.4145 - val_loss: 1.3936 - val_accuracy: 0.2891\n",
      "Epoch 121/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2862 - accuracy: 0.3979 - val_loss: 1.1321 - val_accuracy: 0.5586\n",
      "Epoch 122/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2516 - accuracy: 0.4271 - val_loss: 1.1675 - val_accuracy: 0.5469\n",
      "Epoch 123/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2924 - accuracy: 0.3951 - val_loss: 1.3914 - val_accuracy: 0.2266\n",
      "Epoch 124/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2584 - accuracy: 0.4096 - val_loss: 1.3586 - val_accuracy: 0.3594\n",
      "Epoch 125/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2617 - accuracy: 0.4164 - val_loss: 1.6659 - val_accuracy: 0.2070\n",
      "Epoch 126/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2815 - accuracy: 0.4109 - val_loss: 1.2376 - val_accuracy: 0.4648\n",
      "Epoch 127/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2365 - accuracy: 0.4350 - val_loss: 1.3309 - val_accuracy: 0.4414\n",
      "Epoch 128/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2729 - accuracy: 0.4026 - val_loss: 1.1793 - val_accuracy: 0.4883\n",
      "Epoch 129/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2548 - accuracy: 0.4249 - val_loss: 1.1501 - val_accuracy: 0.5586\n",
      "Epoch 130/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2598 - accuracy: 0.4092 - val_loss: 1.0912 - val_accuracy: 0.5508\n",
      "Epoch 131/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2899 - accuracy: 0.3954 - val_loss: 1.3932 - val_accuracy: 0.2070\n",
      "Epoch 132/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2718 - accuracy: 0.4044 - val_loss: 1.2654 - val_accuracy: 0.4648\n",
      "Epoch 133/4000\n",
      "128/128 [==============================] - 8s 58ms/step - loss: 1.2593 - accuracy: 0.4082 - val_loss: 1.3415 - val_accuracy: 0.2773\n",
      "Epoch 134/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2681 - accuracy: 0.3992 - val_loss: 1.2189 - val_accuracy: 0.4531\n",
      "Epoch 135/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2767 - accuracy: 0.4098 - val_loss: 1.3350 - val_accuracy: 0.3203\n",
      "Epoch 136/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2732 - accuracy: 0.4084 - val_loss: 1.3178 - val_accuracy: 0.3281\n",
      "Epoch 137/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2446 - accuracy: 0.4228 - val_loss: 1.3196 - val_accuracy: 0.2930\n",
      "Epoch 138/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2825 - accuracy: 0.3945 - val_loss: 1.2337 - val_accuracy: 0.5469\n",
      "Epoch 139/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2963 - accuracy: 0.3855 - val_loss: 1.1632 - val_accuracy: 0.5039\n",
      "Epoch 140/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2605 - accuracy: 0.4207 - val_loss: 1.3085 - val_accuracy: 0.4453\n",
      "Epoch 141/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2845 - accuracy: 0.4029 - val_loss: 1.4382 - val_accuracy: 0.2773\n",
      "Epoch 142/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2668 - accuracy: 0.4050 - val_loss: 1.0776 - val_accuracy: 0.5625\n",
      "Epoch 143/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2601 - accuracy: 0.4049 - val_loss: 1.5125 - val_accuracy: 0.2188\n",
      "Epoch 144/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2671 - accuracy: 0.4157 - val_loss: 1.2507 - val_accuracy: 0.4492\n",
      "Epoch 145/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2684 - accuracy: 0.4121 - val_loss: 1.4352 - val_accuracy: 0.2617\n",
      "Epoch 146/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2556 - accuracy: 0.4148 - val_loss: 1.2581 - val_accuracy: 0.4727\n",
      "Epoch 147/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2497 - accuracy: 0.4219 - val_loss: 1.3658 - val_accuracy: 0.3320\n",
      "Epoch 148/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2646 - accuracy: 0.4266 - val_loss: 1.1775 - val_accuracy: 0.4883\n",
      "Epoch 149/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2566 - accuracy: 0.4170 - val_loss: 1.2373 - val_accuracy: 0.4258\n",
      "Epoch 150/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2474 - accuracy: 0.4044 - val_loss: 1.2873 - val_accuracy: 0.3828\n",
      "Epoch 151/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2802 - accuracy: 0.4036 - val_loss: 1.4560 - val_accuracy: 0.2617\n",
      "Epoch 152/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2800 - accuracy: 0.4025 - val_loss: 1.1936 - val_accuracy: 0.4805\n",
      "Epoch 153/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2770 - accuracy: 0.3921 - val_loss: 1.2849 - val_accuracy: 0.3867\n",
      "Epoch 154/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2532 - accuracy: 0.4086 - val_loss: 1.3455 - val_accuracy: 0.3164\n",
      "Epoch 155/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2401 - accuracy: 0.4323 - val_loss: 1.3477 - val_accuracy: 0.3086\n",
      "Epoch 156/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2582 - accuracy: 0.4210 - val_loss: 1.1896 - val_accuracy: 0.5195\n",
      "Epoch 157/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2706 - accuracy: 0.4079 - val_loss: 1.2661 - val_accuracy: 0.4609\n",
      "Epoch 158/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2622 - accuracy: 0.4142 - val_loss: 1.2024 - val_accuracy: 0.4844\n",
      "Epoch 159/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2796 - accuracy: 0.4111 - val_loss: 1.4196 - val_accuracy: 0.2539\n",
      "Epoch 160/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2665 - accuracy: 0.4075 - val_loss: 1.2122 - val_accuracy: 0.4727\n",
      "Epoch 161/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2713 - accuracy: 0.4064 - val_loss: 1.3495 - val_accuracy: 0.2969\n",
      "Epoch 162/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2597 - accuracy: 0.4180 - val_loss: 1.2967 - val_accuracy: 0.3281\n",
      "Epoch 163/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2491 - accuracy: 0.4334 - val_loss: 1.4536 - val_accuracy: 0.2383\n",
      "Epoch 164/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2480 - accuracy: 0.4223 - val_loss: 1.3389 - val_accuracy: 0.3125\n",
      "Epoch 165/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2561 - accuracy: 0.4203 - val_loss: 1.4943 - val_accuracy: 0.1953\n",
      "Epoch 166/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2746 - accuracy: 0.4017 - val_loss: 1.4797 - val_accuracy: 0.2812\n",
      "Epoch 167/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2664 - accuracy: 0.4136 - val_loss: 1.2844 - val_accuracy: 0.3359\n",
      "Epoch 168/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2617 - accuracy: 0.4071 - val_loss: 1.3285 - val_accuracy: 0.3906\n",
      "Epoch 169/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2504 - accuracy: 0.4197 - val_loss: 1.1895 - val_accuracy: 0.5391\n",
      "Epoch 170/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2810 - accuracy: 0.3854 - val_loss: 1.1765 - val_accuracy: 0.5078\n",
      "Epoch 171/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2481 - accuracy: 0.4318 - val_loss: 1.2707 - val_accuracy: 0.4141\n",
      "Epoch 172/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2622 - accuracy: 0.4133 - val_loss: 1.1554 - val_accuracy: 0.5547\n",
      "Epoch 173/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2956 - accuracy: 0.3951 - val_loss: 1.1524 - val_accuracy: 0.5430\n",
      "Epoch 174/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2633 - accuracy: 0.4068 - val_loss: 1.3760 - val_accuracy: 0.3125\n",
      "Epoch 175/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2705 - accuracy: 0.4037 - val_loss: 1.4693 - val_accuracy: 0.2227\n",
      "Epoch 176/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2505 - accuracy: 0.4081 - val_loss: 1.5247 - val_accuracy: 0.2617\n",
      "Epoch 177/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2494 - accuracy: 0.4162 - val_loss: 1.5038 - val_accuracy: 0.2812\n",
      "Epoch 178/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2563 - accuracy: 0.4145 - val_loss: 1.1795 - val_accuracy: 0.5469\n",
      "Epoch 179/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2584 - accuracy: 0.4236 - val_loss: 1.1916 - val_accuracy: 0.5391\n",
      "Epoch 180/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2458 - accuracy: 0.4168 - val_loss: 1.2936 - val_accuracy: 0.4219\n",
      "Epoch 181/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2562 - accuracy: 0.4274 - val_loss: 1.1065 - val_accuracy: 0.5742\n",
      "Epoch 182/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2638 - accuracy: 0.4139 - val_loss: 1.2214 - val_accuracy: 0.5547\n",
      "Epoch 183/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2459 - accuracy: 0.4243 - val_loss: 1.2283 - val_accuracy: 0.4336\n",
      "Epoch 184/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2907 - accuracy: 0.4025 - val_loss: 1.2583 - val_accuracy: 0.3984\n",
      "Epoch 185/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2726 - accuracy: 0.4081 - val_loss: 1.2415 - val_accuracy: 0.4180\n",
      "Epoch 186/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2369 - accuracy: 0.4380 - val_loss: 1.3506 - val_accuracy: 0.3125\n",
      "Epoch 187/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2620 - accuracy: 0.4117 - val_loss: 1.2652 - val_accuracy: 0.3398\n",
      "Epoch 188/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2456 - accuracy: 0.4186 - val_loss: 1.2814 - val_accuracy: 0.3672\n",
      "Epoch 189/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2787 - accuracy: 0.4004 - val_loss: 1.3896 - val_accuracy: 0.2969\n",
      "Epoch 190/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2601 - accuracy: 0.4128 - val_loss: 1.2396 - val_accuracy: 0.5391\n",
      "Epoch 191/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2745 - accuracy: 0.3862 - val_loss: 1.3230 - val_accuracy: 0.3008\n",
      "Epoch 192/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2529 - accuracy: 0.4040 - val_loss: 1.3890 - val_accuracy: 0.2656\n",
      "Epoch 193/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2494 - accuracy: 0.4277 - val_loss: 1.4041 - val_accuracy: 0.2695\n",
      "Epoch 194/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2510 - accuracy: 0.4224 - val_loss: 1.3866 - val_accuracy: 0.3086\n",
      "Epoch 195/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2568 - accuracy: 0.4173 - val_loss: 1.2201 - val_accuracy: 0.5195\n",
      "Epoch 196/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2555 - accuracy: 0.4046 - val_loss: 1.1297 - val_accuracy: 0.5742\n",
      "Epoch 197/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2815 - accuracy: 0.4094 - val_loss: 1.2557 - val_accuracy: 0.4453\n",
      "Epoch 198/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2705 - accuracy: 0.4100 - val_loss: 1.3169 - val_accuracy: 0.3086\n",
      "Epoch 199/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2663 - accuracy: 0.4157 - val_loss: 1.2558 - val_accuracy: 0.4609\n",
      "Epoch 200/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2437 - accuracy: 0.4221 - val_loss: 1.3528 - val_accuracy: 0.2930\n",
      "Epoch 201/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2701 - accuracy: 0.4000 - val_loss: 1.1744 - val_accuracy: 0.5508\n",
      "Epoch 202/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2698 - accuracy: 0.4066 - val_loss: 1.3406 - val_accuracy: 0.3164\n",
      "Epoch 203/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2561 - accuracy: 0.4155 - val_loss: 1.2195 - val_accuracy: 0.4805\n",
      "Epoch 204/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2418 - accuracy: 0.4224 - val_loss: 1.3775 - val_accuracy: 0.3203\n",
      "Epoch 205/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2452 - accuracy: 0.4260 - val_loss: 1.2423 - val_accuracy: 0.4727\n",
      "Epoch 206/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2550 - accuracy: 0.4198 - val_loss: 1.1373 - val_accuracy: 0.5508\n",
      "Epoch 207/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2716 - accuracy: 0.4059 - val_loss: 1.2845 - val_accuracy: 0.4219\n",
      "Epoch 208/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.3004 - accuracy: 0.3842 - val_loss: 1.2905 - val_accuracy: 0.4531\n",
      "Epoch 209/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2596 - accuracy: 0.4042 - val_loss: 1.3049 - val_accuracy: 0.4102\n",
      "Epoch 210/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2391 - accuracy: 0.4077 - val_loss: 1.3562 - val_accuracy: 0.2969\n",
      "Epoch 211/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2460 - accuracy: 0.4282 - val_loss: 1.2932 - val_accuracy: 0.3594\n",
      "Epoch 212/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2772 - accuracy: 0.3963 - val_loss: 1.2511 - val_accuracy: 0.3711\n",
      "Epoch 213/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2675 - accuracy: 0.4062 - val_loss: 1.3418 - val_accuracy: 0.3867\n",
      "Epoch 214/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2661 - accuracy: 0.4088 - val_loss: 1.3573 - val_accuracy: 0.3047\n",
      "Epoch 215/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2399 - accuracy: 0.4369 - val_loss: 1.2885 - val_accuracy: 0.3242\n",
      "Epoch 216/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2681 - accuracy: 0.4052 - val_loss: 1.4218 - val_accuracy: 0.2109\n",
      "Epoch 217/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2444 - accuracy: 0.4181 - val_loss: 1.4688 - val_accuracy: 0.23441.2441 - ac\n",
      "Epoch 218/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2417 - accuracy: 0.4318 - val_loss: 1.2588 - val_accuracy: 0.4258\n",
      "Epoch 219/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2496 - accuracy: 0.4268 - val_loss: 1.1946 - val_accuracy: 0.4922\n",
      "Epoch 220/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2406 - accuracy: 0.4338 - val_loss: 1.3709 - val_accuracy: 0.2930\n",
      "Epoch 221/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2549 - accuracy: 0.4244 - val_loss: 1.3550 - val_accuracy: 0.3125\n",
      "Epoch 222/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2600 - accuracy: 0.4113 - val_loss: 1.1514 - val_accuracy: 0.5391\n",
      "Epoch 223/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2492 - accuracy: 0.4258 - val_loss: 1.3591 - val_accuracy: 0.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2650 - accuracy: 0.4085 - val_loss: 1.2522 - val_accuracy: 0.4648\n",
      "Epoch 225/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2372 - accuracy: 0.4256 - val_loss: 1.3986 - val_accuracy: 0.2773\n",
      "Epoch 226/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2566 - accuracy: 0.4208 - val_loss: 1.3165 - val_accuracy: 0.3164\n",
      "Epoch 227/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2505 - accuracy: 0.4253 - val_loss: 1.1868 - val_accuracy: 0.5234\n",
      "Epoch 228/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2459 - accuracy: 0.4266 - val_loss: 1.2011 - val_accuracy: 0.5430\n",
      "Epoch 229/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2367 - accuracy: 0.4219 - val_loss: 1.4264 - val_accuracy: 0.2148\n",
      "Epoch 230/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2702 - accuracy: 0.4078 - val_loss: 1.3404 - val_accuracy: 0.3320\n",
      "Epoch 231/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2461 - accuracy: 0.4283 - val_loss: 1.3580 - val_accuracy: 0.3672\n",
      "Epoch 232/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2669 - accuracy: 0.3901 - val_loss: 1.4601 - val_accuracy: 0.2344\n",
      "Epoch 233/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2447 - accuracy: 0.4299 - val_loss: 1.3010 - val_accuracy: 0.3906\n",
      "Epoch 234/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2278 - accuracy: 0.4561 - val_loss: 1.5523 - val_accuracy: 0.2734\n",
      "Epoch 235/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2752 - accuracy: 0.3959 - val_loss: 1.3678 - val_accuracy: 0.2969\n",
      "Epoch 236/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2407 - accuracy: 0.4244 - val_loss: 1.2011 - val_accuracy: 0.5156\n",
      "Epoch 237/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2514 - accuracy: 0.4190 - val_loss: 1.2426 - val_accuracy: 0.4609\n",
      "Epoch 238/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2657 - accuracy: 0.3969 - val_loss: 1.3505 - val_accuracy: 0.3477\n",
      "Epoch 239/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2317 - accuracy: 0.4397 - val_loss: 1.3084 - val_accuracy: 0.4883\n",
      "Epoch 240/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2705 - accuracy: 0.4120 - val_loss: 1.2159 - val_accuracy: 0.4531\n",
      "Epoch 241/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2401 - accuracy: 0.4248 - val_loss: 1.2850 - val_accuracy: 0.3750\n",
      "Epoch 242/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2700 - accuracy: 0.4106 - val_loss: 1.2858 - val_accuracy: 0.3477\n",
      "Epoch 243/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2377 - accuracy: 0.4283 - val_loss: 1.3257 - val_accuracy: 0.3047\n",
      "Epoch 244/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2329 - accuracy: 0.4235 - val_loss: 1.3403 - val_accuracy: 0.3242\n",
      "Epoch 245/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2456 - accuracy: 0.4230 - val_loss: 1.3294 - val_accuracy: 0.4180\n",
      "Epoch 246/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2485 - accuracy: 0.4100 - val_loss: 1.3573 - val_accuracy: 0.2852\n",
      "Epoch 247/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2401 - accuracy: 0.4285 - val_loss: 1.3809 - val_accuracy: 0.2852\n",
      "Epoch 248/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2326 - accuracy: 0.4243 - val_loss: 1.3171 - val_accuracy: 0.3164\n",
      "Epoch 249/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2732 - accuracy: 0.4086 - val_loss: 1.1900 - val_accuracy: 0.5117\n",
      "Epoch 250/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2417 - accuracy: 0.4170 - val_loss: 1.2282 - val_accuracy: 0.4727\n",
      "Epoch 251/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2532 - accuracy: 0.4229 - val_loss: 1.2310 - val_accuracy: 0.4688\n",
      "Epoch 252/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2465 - accuracy: 0.4107 - val_loss: 1.1795 - val_accuracy: 0.4727\n",
      "Epoch 253/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2372 - accuracy: 0.4245 - val_loss: 1.2911 - val_accuracy: 0.3633\n",
      "Epoch 254/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2425 - accuracy: 0.4175 - val_loss: 1.3345 - val_accuracy: 0.2969\n",
      "Epoch 255/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2438 - accuracy: 0.4320 - val_loss: 1.5175 - val_accuracy: 0.1719\n",
      "Epoch 256/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2630 - accuracy: 0.4054 - val_loss: 1.2421 - val_accuracy: 0.4688\n",
      "Epoch 257/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2655 - accuracy: 0.4055 - val_loss: 1.2619 - val_accuracy: 0.4414\n",
      "Epoch 258/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2642 - accuracy: 0.4006 - val_loss: 1.2274 - val_accuracy: 0.4414\n",
      "Epoch 259/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2661 - accuracy: 0.4135 - val_loss: 1.5880 - val_accuracy: 0.2461\n",
      "Epoch 260/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2572 - accuracy: 0.4122 - val_loss: 1.3089 - val_accuracy: 0.2812\n",
      "Epoch 261/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2346 - accuracy: 0.4499 - val_loss: 1.2446 - val_accuracy: 0.4336\n",
      "Epoch 262/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2485 - accuracy: 0.4195 - val_loss: 1.4323 - val_accuracy: 0.2812\n",
      "Epoch 263/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2528 - accuracy: 0.4231 - val_loss: 1.2782 - val_accuracy: 0.3633\n",
      "Epoch 264/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2419 - accuracy: 0.4283 - val_loss: 1.2451 - val_accuracy: 0.4570\n",
      "Epoch 265/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2239 - accuracy: 0.4429 - val_loss: 1.4652 - val_accuracy: 0.2539\n",
      "Epoch 266/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2651 - accuracy: 0.4043 - val_loss: 1.4735 - val_accuracy: 0.2578\n",
      "Epoch 267/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2392 - accuracy: 0.4477 - val_loss: 1.4069 - val_accuracy: 0.2305\n",
      "Epoch 268/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2242 - accuracy: 0.4370 - val_loss: 1.2671 - val_accuracy: 0.3555\n",
      "Epoch 269/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2502 - accuracy: 0.4177 - val_loss: 1.2583 - val_accuracy: 0.2891\n",
      "Epoch 270/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2733 - accuracy: 0.4202 - val_loss: 1.1851 - val_accuracy: 0.4922\n",
      "Epoch 271/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2547 - accuracy: 0.4263 - val_loss: 1.1228 - val_accuracy: 0.5664\n",
      "Epoch 272/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2514 - accuracy: 0.4212 - val_loss: 1.2452 - val_accuracy: 0.4492\n",
      "Epoch 273/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2459 - accuracy: 0.4196 - val_loss: 1.3827 - val_accuracy: 0.2422\n",
      "Epoch 274/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2579 - accuracy: 0.4067 - val_loss: 1.4174 - val_accuracy: 0.2188\n",
      "Epoch 275/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2423 - accuracy: 0.4181 - val_loss: 1.2707 - val_accuracy: 0.4062\n",
      "Epoch 276/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2379 - accuracy: 0.4293 - val_loss: 1.2206 - val_accuracy: 0.5117\n",
      "Epoch 277/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2442 - accuracy: 0.4284 - val_loss: 1.3398 - val_accuracy: 0.2969\n",
      "Epoch 278/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2545 - accuracy: 0.4287 - val_loss: 1.2616 - val_accuracy: 0.4062\n",
      "Epoch 279/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2341 - accuracy: 0.4401 - val_loss: 1.5723 - val_accuracy: 0.2383\n",
      "Epoch 280/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2385 - accuracy: 0.4308 - val_loss: 1.2547 - val_accuracy: 0.4648\n",
      "Epoch 281/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2287 - accuracy: 0.4448 - val_loss: 1.3354 - val_accuracy: 0.3750\n",
      "Epoch 282/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2551 - accuracy: 0.4124 - val_loss: 1.3304 - val_accuracy: 0.3008\n",
      "Epoch 283/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2465 - accuracy: 0.4121 - val_loss: 1.1606 - val_accuracy: 0.5586\n",
      "Epoch 284/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2541 - accuracy: 0.4011 - val_loss: 1.6143 - val_accuracy: 0.2031\n",
      "Epoch 285/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2642 - accuracy: 0.4184 - val_loss: 1.2009 - val_accuracy: 0.5078\n",
      "Epoch 286/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2381 - accuracy: 0.4229 - val_loss: 1.4024 - val_accuracy: 0.2617\n",
      "Epoch 287/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2242 - accuracy: 0.4250 - val_loss: 1.2665 - val_accuracy: 0.4375\n",
      "Epoch 288/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2523 - accuracy: 0.4066 - val_loss: 1.1474 - val_accuracy: 0.5312\n",
      "Epoch 289/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2498 - accuracy: 0.4086 - val_loss: 1.2724 - val_accuracy: 0.3633\n",
      "Epoch 290/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2622 - accuracy: 0.4137 - val_loss: 1.3111 - val_accuracy: 0.3438\n",
      "Epoch 291/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2360 - accuracy: 0.4270 - val_loss: 1.1390 - val_accuracy: 0.5547\n",
      "Epoch 292/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2581 - accuracy: 0.4369 - val_loss: 1.2469 - val_accuracy: 0.4531\n",
      "Epoch 293/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2433 - accuracy: 0.4195 - val_loss: 1.3494 - val_accuracy: 0.2617\n",
      "Epoch 294/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2546 - accuracy: 0.4199 - val_loss: 1.2713 - val_accuracy: 0.4453\n",
      "Epoch 295/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2241 - accuracy: 0.4443 - val_loss: 1.6127 - val_accuracy: 0.2422\n",
      "Epoch 296/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2240 - accuracy: 0.4461 - val_loss: 1.1840 - val_accuracy: 0.4883\n",
      "Epoch 297/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2519 - accuracy: 0.4017 - val_loss: 1.3111 - val_accuracy: 0.3047\n",
      "Epoch 298/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2319 - accuracy: 0.4245 - val_loss: 1.6317 - val_accuracy: 0.2656\n",
      "Epoch 299/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2449 - accuracy: 0.4227 - val_loss: 1.2909 - val_accuracy: 0.3438\n",
      "Epoch 300/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2360 - accuracy: 0.4430 - val_loss: 1.1416 - val_accuracy: 0.5352\n",
      "Epoch 301/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2667 - accuracy: 0.4096 - val_loss: 1.2890 - val_accuracy: 0.3320\n",
      "Epoch 302/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2645 - accuracy: 0.4076 - val_loss: 1.2526 - val_accuracy: 0.4766\n",
      "Epoch 303/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2465 - accuracy: 0.4083 - val_loss: 1.5094 - val_accuracy: 0.2148\n",
      "Epoch 304/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2487 - accuracy: 0.4160 - val_loss: 1.2429 - val_accuracy: 0.4844\n",
      "Epoch 305/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2834 - accuracy: 0.4005 - val_loss: 1.3162 - val_accuracy: 0.3242\n",
      "Epoch 306/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2656 - accuracy: 0.4189 - val_loss: 1.1343 - val_accuracy: 0.5469\n",
      "Epoch 307/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2316 - accuracy: 0.4219 - val_loss: 1.2167 - val_accuracy: 0.5117\n",
      "Epoch 308/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2461 - accuracy: 0.4395 - val_loss: 1.1538 - val_accuracy: 0.4805\n",
      "Epoch 309/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2409 - accuracy: 0.4329 - val_loss: 1.3339 - val_accuracy: 0.3320\n",
      "Epoch 310/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2446 - accuracy: 0.4274 - val_loss: 1.3518 - val_accuracy: 0.2891\n",
      "Epoch 311/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2557 - accuracy: 0.4141 - val_loss: 1.2026 - val_accuracy: 0.4688\n",
      "Epoch 312/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2479 - accuracy: 0.4291 - val_loss: 1.3073 - val_accuracy: 0.3555\n",
      "Epoch 313/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2461 - accuracy: 0.4090 - val_loss: 1.4552 - val_accuracy: 0.2422\n",
      "Epoch 314/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2708 - accuracy: 0.4146 - val_loss: 1.1853 - val_accuracy: 0.4844\n",
      "Epoch 315/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2541 - accuracy: 0.4189 - val_loss: 1.3228 - val_accuracy: 0.3320\n",
      "Epoch 316/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2411 - accuracy: 0.4259 - val_loss: 1.6055 - val_accuracy: 0.2852\n",
      "Epoch 317/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2636 - accuracy: 0.4228 - val_loss: 1.3475 - val_accuracy: 0.2969\n",
      "Epoch 318/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2279 - accuracy: 0.4219 - val_loss: 1.3973 - val_accuracy: 0.2617\n",
      "Epoch 319/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2228 - accuracy: 0.4438 - val_loss: 1.1701 - val_accuracy: 0.5117\n",
      "Epoch 320/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2500 - accuracy: 0.4233 - val_loss: 1.2590 - val_accuracy: 0.4141\n",
      "Epoch 321/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2651 - accuracy: 0.4035 - val_loss: 1.1064 - val_accuracy: 0.5664\n",
      "Epoch 322/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2443 - accuracy: 0.4269 - val_loss: 1.1852 - val_accuracy: 0.4922\n",
      "Epoch 323/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2317 - accuracy: 0.4343 - val_loss: 1.0703 - val_accuracy: 0.5625\n",
      "Epoch 324/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2306 - accuracy: 0.4343 - val_loss: 1.3524 - val_accuracy: 0.2734\n",
      "Epoch 325/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2537 - accuracy: 0.4136 - val_loss: 1.3974 - val_accuracy: 0.2812\n",
      "Epoch 326/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2308 - accuracy: 0.4284 - val_loss: 1.2523 - val_accuracy: 0.4336\n",
      "Epoch 327/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2456 - accuracy: 0.4137 - val_loss: 1.2223 - val_accuracy: 0.5195\n",
      "Epoch 328/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2667 - accuracy: 0.4162 - val_loss: 1.1333 - val_accuracy: 0.5664\n",
      "Epoch 329/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2476 - accuracy: 0.4166 - val_loss: 1.1566 - val_accuracy: 0.5195\n",
      "Epoch 330/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2421 - accuracy: 0.4226 - val_loss: 1.2532 - val_accuracy: 0.4648\n",
      "Epoch 331/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2503 - accuracy: 0.4251 - val_loss: 1.5751 - val_accuracy: 0.2188\n",
      "Epoch 332/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2751 - accuracy: 0.4140 - val_loss: 1.3357 - val_accuracy: 0.3281\n",
      "Epoch 333/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2231 - accuracy: 0.4346 - val_loss: 1.1732 - val_accuracy: 0.5000\n",
      "Epoch 334/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2730 - accuracy: 0.4185 - val_loss: 1.2839 - val_accuracy: 0.4141\n",
      "Epoch 335/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2613 - accuracy: 0.4055 - val_loss: 1.2154 - val_accuracy: 0.4805\n",
      "Epoch 336/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2504 - accuracy: 0.4210 - val_loss: 1.3481 - val_accuracy: 0.2852\n",
      "Epoch 337/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2410 - accuracy: 0.4179 - val_loss: 1.2865 - val_accuracy: 0.4141\n",
      "Epoch 338/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2355 - accuracy: 0.4317 - val_loss: 1.4768 - val_accuracy: 0.2148\n",
      "Epoch 339/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2428 - accuracy: 0.4287 - val_loss: 1.1216 - val_accuracy: 0.5352\n",
      "Epoch 340/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2225 - accuracy: 0.4421 - val_loss: 1.4486 - val_accuracy: 0.2148\n",
      "Epoch 341/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2502 - accuracy: 0.4167 - val_loss: 1.1810 - val_accuracy: 0.4805\n",
      "Epoch 342/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2331 - accuracy: 0.4266 - val_loss: 1.2086 - val_accuracy: 0.4883\n",
      "Epoch 343/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2392 - accuracy: 0.4366 - val_loss: 1.4150 - val_accuracy: 0.2188\n",
      "Epoch 344/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2352 - accuracy: 0.4248 - val_loss: 1.2299 - val_accuracy: 0.4609\n",
      "Epoch 345/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2579 - accuracy: 0.4119 - val_loss: 1.2136 - val_accuracy: 0.4844\n",
      "Epoch 346/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2489 - accuracy: 0.4189 - val_loss: 1.2250 - val_accuracy: 0.4023\n",
      "Epoch 347/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2350 - accuracy: 0.4273 - val_loss: 1.3020 - val_accuracy: 0.3242\n",
      "Epoch 348/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2380 - accuracy: 0.4341 - val_loss: 1.4256 - val_accuracy: 0.2773\n",
      "Epoch 349/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2452 - accuracy: 0.4114 - val_loss: 1.1335 - val_accuracy: 0.5664- loss:\n",
      "Epoch 350/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2699 - accuracy: 0.3963 - val_loss: 1.2992 - val_accuracy: 0.3477\n",
      "Epoch 351/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 1.2605 - accuracy: 0.4223 - val_loss: 1.4071 - val_accuracy: 0.2461\n",
      "Epoch 352/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.2359 - accuracy: 0.4400 - val_loss: 1.3339 - val_accuracy: 0.2852\n",
      "Epoch 353/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.2398 - accuracy: 0.4266 - val_loss: 1.3021 - val_accuracy: 0.3516\n",
      "Epoch 354/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2483 - accuracy: 0.4252 - val_loss: 1.1252 - val_accuracy: 0.5352\n",
      "Epoch 355/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2772 - accuracy: 0.4232 - val_loss: 1.1379 - val_accuracy: 0.5352\n",
      "Epoch 356/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2292 - accuracy: 0.4411 - val_loss: 1.2700 - val_accuracy: 0.3438\n",
      "Epoch 357/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2380 - accuracy: 0.4217 - val_loss: 1.3745 - val_accuracy: 0.2852\n",
      "Epoch 358/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2415 - accuracy: 0.4285 - val_loss: 1.2267 - val_accuracy: 0.4453\n",
      "Epoch 359/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2229 - accuracy: 0.4385 - val_loss: 1.1191 - val_accuracy: 0.5273\n",
      "Epoch 360/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2442 - accuracy: 0.4196 - val_loss: 1.3826 - val_accuracy: 0.2891\n",
      "Epoch 361/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2164 - accuracy: 0.4479 - val_loss: 1.5362 - val_accuracy: 0.2422\n",
      "Epoch 362/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2531 - accuracy: 0.4190 - val_loss: 1.2608 - val_accuracy: 0.3828\n",
      "Epoch 363/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.2476 - accuracy: 0.4049 - val_loss: 1.3185 - val_accuracy: 0.3945\n",
      "Epoch 364/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.2327 - accuracy: 0.4185 - val_loss: 1.3010 - val_accuracy: 0.3438\n",
      "Epoch 365/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2447 - accuracy: 0.4253 - val_loss: 1.2474 - val_accuracy: 0.4062\n",
      "Epoch 366/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2369 - accuracy: 0.4372 - val_loss: 1.3773 - val_accuracy: 0.2734\n",
      "Epoch 367/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2272 - accuracy: 0.4362 - val_loss: 1.3550 - val_accuracy: 0.3125\n",
      "Epoch 368/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2622 - accuracy: 0.4166 - val_loss: 1.4526 - val_accuracy: 0.2695\n",
      "Epoch 369/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2248 - accuracy: 0.4246 - val_loss: 1.2880 - val_accuracy: 0.3477\n",
      "Epoch 370/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2486 - accuracy: 0.4256 - val_loss: 1.2284 - val_accuracy: 0.4648\n",
      "Epoch 371/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.2117 - accuracy: 0.4453 - val_loss: 1.2422 - val_accuracy: 0.4375\n",
      "Epoch 372/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2201 - accuracy: 0.4371 - val_loss: 1.2623 - val_accuracy: 0.4453\n",
      "Epoch 373/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2544 - accuracy: 0.4154 - val_loss: 1.1815 - val_accuracy: 0.4922\n",
      "Epoch 374/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2581 - accuracy: 0.4229 - val_loss: 1.2018 - val_accuracy: 0.4375\n",
      "Epoch 375/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2430 - accuracy: 0.4074 - val_loss: 1.2833 - val_accuracy: 0.4258\n",
      "Epoch 376/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2172 - accuracy: 0.4361 - val_loss: 1.3650 - val_accuracy: 0.3438\n",
      "Epoch 377/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2514 - accuracy: 0.4159 - val_loss: 1.3804 - val_accuracy: 0.2617\n",
      "Epoch 378/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2391 - accuracy: 0.4254 - val_loss: 1.2862 - val_accuracy: 0.4219\n",
      "Epoch 379/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2238 - accuracy: 0.4470 - val_loss: 1.3282 - val_accuracy: 0.3594\n",
      "Epoch 380/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2406 - accuracy: 0.4291 - val_loss: 1.1741 - val_accuracy: 0.5195\n",
      "Epoch 381/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2255 - accuracy: 0.4338 - val_loss: 1.0796 - val_accuracy: 0.5781\n",
      "Epoch 382/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2333 - accuracy: 0.4305 - val_loss: 1.3132 - val_accuracy: 0.2969\n",
      "Epoch 383/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2372 - accuracy: 0.4278 - val_loss: 1.3649 - val_accuracy: 0.2773\n",
      "Epoch 384/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2417 - accuracy: 0.4313 - val_loss: 1.2389 - val_accuracy: 0.4375\n",
      "Epoch 385/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2386 - accuracy: 0.4392 - val_loss: 1.2466 - val_accuracy: 0.4648\n",
      "Epoch 386/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2630 - accuracy: 0.4248 - val_loss: 1.2607 - val_accuracy: 0.3867\n",
      "Epoch 387/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2390 - accuracy: 0.4279 - val_loss: 1.3864 - val_accuracy: 0.3281\n",
      "Epoch 388/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2360 - accuracy: 0.4288 - val_loss: 1.2803 - val_accuracy: 0.4492\n",
      "Epoch 389/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2670 - accuracy: 0.4143 - val_loss: 1.3035 - val_accuracy: 0.3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2376 - accuracy: 0.4281 - val_loss: 1.2692 - val_accuracy: 0.4414\n",
      "Epoch 391/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2418 - accuracy: 0.4163 - val_loss: 1.2730 - val_accuracy: 0.3242\n",
      "Epoch 392/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2513 - accuracy: 0.4317 - val_loss: 1.4017 - val_accuracy: 0.2812\n",
      "Epoch 393/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2587 - accuracy: 0.4280 - val_loss: 1.2338 - val_accuracy: 0.4375\n",
      "Epoch 394/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2197 - accuracy: 0.4414 - val_loss: 1.5362 - val_accuracy: 0.1953\n",
      "Epoch 395/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2528 - accuracy: 0.4017 - val_loss: 1.3023 - val_accuracy: 0.4023\n",
      "Epoch 396/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2417 - accuracy: 0.4216 - val_loss: 1.4193 - val_accuracy: 0.2266\n",
      "Epoch 397/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2170 - accuracy: 0.4367 - val_loss: 1.4375 - val_accuracy: 0.2734\n",
      "Epoch 398/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2643 - accuracy: 0.4221 - val_loss: 1.2797 - val_accuracy: 0.3711\n",
      "Epoch 399/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2360 - accuracy: 0.4329 - val_loss: 1.2173 - val_accuracy: 0.4688\n",
      "Epoch 400/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.2215 - accuracy: 0.4410 - val_loss: 1.1514 - val_accuracy: 0.4883\n",
      "Epoch 401/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.2402 - accuracy: 0.4232 - val_loss: 1.3294 - val_accuracy: 0.3477\n",
      "Epoch 402/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.2213 - accuracy: 0.4211 - val_loss: 1.1862 - val_accuracy: 0.4727\n",
      "Epoch 403/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2429 - accuracy: 0.4159 - val_loss: 1.3917 - val_accuracy: 0.2773\n",
      "Epoch 404/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2383 - accuracy: 0.4288 - val_loss: 1.5084 - val_accuracy: 0.2617\n",
      "Epoch 405/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2281 - accuracy: 0.4415 - val_loss: 1.1805 - val_accuracy: 0.5000\n",
      "Epoch 406/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2235 - accuracy: 0.4437 - val_loss: 1.2064 - val_accuracy: 0.5234\n",
      "Epoch 407/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2426 - accuracy: 0.4280 - val_loss: 1.3021 - val_accuracy: 0.3906\n",
      "Epoch 408/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2434 - accuracy: 0.4331 - val_loss: 1.2948 - val_accuracy: 0.3203\n",
      "Epoch 409/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2671 - accuracy: 0.4220 - val_loss: 1.2281 - val_accuracy: 0.4844\n",
      "Epoch 410/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2297 - accuracy: 0.4237 - val_loss: 1.3272 - val_accuracy: 0.3516\n",
      "Epoch 411/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2320 - accuracy: 0.4332 - val_loss: 1.2332 - val_accuracy: 0.4766\n",
      "Epoch 412/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2422 - accuracy: 0.4251 - val_loss: 1.2452 - val_accuracy: 0.3398\n",
      "Epoch 413/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2472 - accuracy: 0.4196 - val_loss: 1.3864 - val_accuracy: 0.2383\n",
      "Epoch 414/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2057 - accuracy: 0.4580 - val_loss: 1.1949 - val_accuracy: 0.4609\n",
      "Epoch 415/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2705 - accuracy: 0.4078 - val_loss: 1.2061 - val_accuracy: 0.4531\n",
      "Epoch 416/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2298 - accuracy: 0.4377 - val_loss: 1.4229 - val_accuracy: 0.2656\n",
      "Epoch 417/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2376 - accuracy: 0.4371 - val_loss: 1.3349 - val_accuracy: 0.3711\n",
      "Epoch 418/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2611 - accuracy: 0.4207 - val_loss: 1.2931 - val_accuracy: 0.3242\n",
      "Epoch 419/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2258 - accuracy: 0.4477 - val_loss: 1.2582 - val_accuracy: 0.3477\n",
      "Epoch 420/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2312 - accuracy: 0.4315 - val_loss: 1.2339 - val_accuracy: 0.4883\n",
      "Epoch 421/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2533 - accuracy: 0.4164 - val_loss: 1.2125 - val_accuracy: 0.3906\n",
      "Epoch 422/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2274 - accuracy: 0.4473 - val_loss: 1.5370 - val_accuracy: 0.2539\n",
      "Epoch 423/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2286 - accuracy: 0.4419 - val_loss: 1.2358 - val_accuracy: 0.4062\n",
      "Epoch 424/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2485 - accuracy: 0.4259 - val_loss: 1.3668 - val_accuracy: 0.2734\n",
      "Epoch 425/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2493 - accuracy: 0.4307 - val_loss: 1.1645 - val_accuracy: 0.5156\n",
      "Epoch 426/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2268 - accuracy: 0.4282 - val_loss: 1.2911 - val_accuracy: 0.3633\n",
      "Epoch 427/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2160 - accuracy: 0.4529 - val_loss: 1.3703 - val_accuracy: 0.2773\n",
      "Epoch 428/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2184 - accuracy: 0.4382 - val_loss: 1.3036 - val_accuracy: 0.3398\n",
      "Epoch 429/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2423 - accuracy: 0.4356 - val_loss: 1.4042 - val_accuracy: 0.2773\n",
      "Epoch 430/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2149 - accuracy: 0.4423 - val_loss: 1.3762 - val_accuracy: 0.2891\n",
      "Epoch 431/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2369 - accuracy: 0.4313 - val_loss: 1.4789 - val_accuracy: 0.2695\n",
      "Epoch 432/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2353 - accuracy: 0.4471 - val_loss: 1.4435 - val_accuracy: 0.2891\n",
      "Epoch 433/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2381 - accuracy: 0.4207 - val_loss: 1.2735 - val_accuracy: 0.3555\n",
      "Epoch 434/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2352 - accuracy: 0.4254 - val_loss: 1.2033 - val_accuracy: 0.4844\n",
      "Epoch 435/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2077 - accuracy: 0.4472 - val_loss: 1.1373 - val_accuracy: 0.5312\n",
      "Epoch 436/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2419 - accuracy: 0.4247 - val_loss: 1.2505 - val_accuracy: 0.4258\n",
      "Epoch 437/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2476 - accuracy: 0.4240 - val_loss: 1.2319 - val_accuracy: 0.4609\n",
      "Epoch 438/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2319 - accuracy: 0.4308 - val_loss: 1.2049 - val_accuracy: 0.4922\n",
      "Epoch 439/4000\n",
      "128/128 [==============================] - 8s 58ms/step - loss: 1.2266 - accuracy: 0.4405 - val_loss: 1.2592 - val_accuracy: 0.4180\n",
      "Epoch 440/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2288 - accuracy: 0.4374 - val_loss: 1.2147 - val_accuracy: 0.4766\n",
      "Epoch 441/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2337 - accuracy: 0.4281 - val_loss: 1.2304 - val_accuracy: 0.3711\n",
      "Epoch 442/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2336 - accuracy: 0.4399 - val_loss: 1.2149 - val_accuracy: 0.4414\n",
      "Epoch 443/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2341 - accuracy: 0.4387 - val_loss: 1.1850 - val_accuracy: 0.5273\n",
      "Epoch 444/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2289 - accuracy: 0.4316 - val_loss: 1.3007 - val_accuracy: 0.3359\n",
      "Epoch 445/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2196 - accuracy: 0.4346 - val_loss: 1.6591 - val_accuracy: 0.2930\n",
      "Epoch 446/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2464 - accuracy: 0.4344 - val_loss: 1.1542 - val_accuracy: 0.5078\n",
      "Epoch 447/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2453 - accuracy: 0.4341 - val_loss: 1.2408 - val_accuracy: 0.4648\n",
      "Epoch 448/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2273 - accuracy: 0.4490 - val_loss: 1.3958 - val_accuracy: 0.2891\n",
      "Epoch 449/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2423 - accuracy: 0.4242 - val_loss: 1.3798 - val_accuracy: 0.3516\n",
      "Epoch 450/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2290 - accuracy: 0.4279 - val_loss: 1.2337 - val_accuracy: 0.3945\n",
      "Epoch 451/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2635 - accuracy: 0.4057 - val_loss: 1.4357 - val_accuracy: 0.2539\n",
      "Epoch 452/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2146 - accuracy: 0.4464 - val_loss: 1.2084 - val_accuracy: 0.4766\n",
      "Epoch 453/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2236 - accuracy: 0.4357 - val_loss: 1.3304 - val_accuracy: 0.2773\n",
      "Epoch 454/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2368 - accuracy: 0.4281 - val_loss: 1.2733 - val_accuracy: 0.3633\n",
      "Epoch 455/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2481 - accuracy: 0.4122 - val_loss: 1.3838 - val_accuracy: 0.2734\n",
      "Epoch 456/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2352 - accuracy: 0.4277 - val_loss: 1.3410 - val_accuracy: 0.3125\n",
      "Epoch 457/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2405 - accuracy: 0.4333 - val_loss: 1.6983 - val_accuracy: 0.2539\n",
      "Epoch 458/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2594 - accuracy: 0.4186 - val_loss: 1.2570 - val_accuracy: 0.4570\n",
      "Epoch 459/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2219 - accuracy: 0.4332 - val_loss: 1.2529 - val_accuracy: 0.4258\n",
      "Epoch 460/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2207 - accuracy: 0.4457 - val_loss: 1.1765 - val_accuracy: 0.5039\n",
      "Epoch 461/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2322 - accuracy: 0.4468 - val_loss: 1.2634 - val_accuracy: 0.4297\n",
      "Epoch 462/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2512 - accuracy: 0.4156 - val_loss: 1.2299 - val_accuracy: 0.4609\n",
      "Epoch 463/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2496 - accuracy: 0.4156 - val_loss: 1.3463 - val_accuracy: 0.3086\n",
      "Epoch 464/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2467 - accuracy: 0.4309 - val_loss: 1.2804 - val_accuracy: 0.4297\n",
      "Epoch 465/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2599 - accuracy: 0.4223 - val_loss: 1.5692 - val_accuracy: 0.2070\n",
      "Epoch 466/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2427 - accuracy: 0.4185 - val_loss: 1.2005 - val_accuracy: 0.4805\n",
      "Epoch 467/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2352 - accuracy: 0.4414 - val_loss: 1.4457 - val_accuracy: 0.2734\n",
      "Epoch 468/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2352 - accuracy: 0.4341 - val_loss: 1.4541 - val_accuracy: 0.2891\n",
      "Epoch 469/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2223 - accuracy: 0.4355 - val_loss: 1.2825 - val_accuracy: 0.3867\n",
      "Epoch 470/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2446 - accuracy: 0.4206 - val_loss: 1.3222 - val_accuracy: 0.3047\n",
      "Epoch 471/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2349 - accuracy: 0.4314 - val_loss: 1.1636 - val_accuracy: 0.5000\n",
      "Epoch 472/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2257 - accuracy: 0.4268 - val_loss: 1.3500 - val_accuracy: 0.2656\n",
      "Epoch 473/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2233 - accuracy: 0.4402 - val_loss: 1.1719 - val_accuracy: 0.4766\n",
      "Epoch 474/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2500 - accuracy: 0.4205 - val_loss: 1.1883 - val_accuracy: 0.4531\n",
      "Epoch 475/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2510 - accuracy: 0.4330 - val_loss: 1.1651 - val_accuracy: 0.5039\n",
      "Epoch 476/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2485 - accuracy: 0.4283 - val_loss: 1.2588 - val_accuracy: 0.4648\n",
      "Epoch 477/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2335 - accuracy: 0.4300 - val_loss: 1.2145 - val_accuracy: 0.4688\n",
      "Epoch 478/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2440 - accuracy: 0.4256 - val_loss: 1.2070 - val_accuracy: 0.4375\n",
      "Epoch 479/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2262 - accuracy: 0.4368 - val_loss: 1.2321 - val_accuracy: 0.4102\n",
      "Epoch 480/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2236 - accuracy: 0.4407 - val_loss: 1.2517 - val_accuracy: 0.3828\n",
      "Epoch 481/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2079 - accuracy: 0.4405 - val_loss: 1.1993 - val_accuracy: 0.4922\n",
      "Epoch 482/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2014 - accuracy: 0.4456 - val_loss: 1.3839 - val_accuracy: 0.2656\n",
      "Epoch 483/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2479 - accuracy: 0.4197 - val_loss: 1.3476 - val_accuracy: 0.2969\n",
      "Epoch 484/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2121 - accuracy: 0.4442 - val_loss: 1.2644 - val_accuracy: 0.3789\n",
      "Epoch 485/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2434 - accuracy: 0.4231 - val_loss: 1.1703 - val_accuracy: 0.4961\n",
      "Epoch 486/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2018 - accuracy: 0.4513 - val_loss: 1.3699 - val_accuracy: 0.2773\n",
      "Epoch 487/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2559 - accuracy: 0.4322 - val_loss: 1.1844 - val_accuracy: 0.4961\n",
      "Epoch 488/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2402 - accuracy: 0.4263 - val_loss: 1.3574 - val_accuracy: 0.2891\n",
      "Epoch 489/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2199 - accuracy: 0.4311 - val_loss: 1.3605 - val_accuracy: 0.3164\n",
      "Epoch 490/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2409 - accuracy: 0.4241 - val_loss: 1.2852 - val_accuracy: 0.3164\n",
      "Epoch 491/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2136 - accuracy: 0.4519 - val_loss: 1.1767 - val_accuracy: 0.5039\n",
      "Epoch 492/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2530 - accuracy: 0.4180 - val_loss: 1.5648 - val_accuracy: 0.2305\n",
      "Epoch 493/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2466 - accuracy: 0.4175 - val_loss: 1.2746 - val_accuracy: 0.3164\n",
      "Epoch 494/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2239 - accuracy: 0.4487 - val_loss: 1.2958 - val_accuracy: 0.4297\n",
      "Epoch 495/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2074 - accuracy: 0.4536 - val_loss: 1.3462 - val_accuracy: 0.3203\n",
      "Epoch 496/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2170 - accuracy: 0.4450 - val_loss: 1.0877 - val_accuracy: 0.5664\n",
      "Epoch 497/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2371 - accuracy: 0.4338 - val_loss: 1.3293 - val_accuracy: 0.3945\n",
      "Epoch 498/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2471 - accuracy: 0.4141 - val_loss: 1.3604 - val_accuracy: 0.2812\n",
      "Epoch 499/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2402 - accuracy: 0.4436 - val_loss: 1.4078 - val_accuracy: 0.2617\n",
      "Epoch 500/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2292 - accuracy: 0.4448 - val_loss: 1.4323 - val_accuracy: 0.2695\n",
      "Epoch 501/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2216 - accuracy: 0.4354 - val_loss: 1.2982 - val_accuracy: 0.3281\n",
      "Epoch 502/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2459 - accuracy: 0.4381 - val_loss: 1.2516 - val_accuracy: 0.4141\n",
      "Epoch 503/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2220 - accuracy: 0.4263 - val_loss: 1.0796 - val_accuracy: 0.5664\n",
      "Epoch 504/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2375 - accuracy: 0.4269 - val_loss: 1.2382 - val_accuracy: 0.4023\n",
      "Epoch 505/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2372 - accuracy: 0.4172 - val_loss: 1.5593 - val_accuracy: 0.3008\n",
      "Epoch 506/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2413 - accuracy: 0.4445 - val_loss: 1.4052 - val_accuracy: 0.2734\n",
      "Epoch 507/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2204 - accuracy: 0.4389 - val_loss: 1.4424 - val_accuracy: 0.2656\n",
      "Epoch 508/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2241 - accuracy: 0.4378 - val_loss: 1.1764 - val_accuracy: 0.4766\n",
      "Epoch 509/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2136 - accuracy: 0.4434 - val_loss: 1.1718 - val_accuracy: 0.5039\n",
      "Epoch 510/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2283 - accuracy: 0.4546 - val_loss: 1.1810 - val_accuracy: 0.4961\n",
      "Epoch 511/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2407 - accuracy: 0.4402 - val_loss: 1.4219 - val_accuracy: 0.2891\n",
      "Epoch 512/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2459 - accuracy: 0.4261 - val_loss: 1.2887 - val_accuracy: 0.3516\n",
      "Epoch 513/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2261 - accuracy: 0.4382 - val_loss: 1.3106 - val_accuracy: 0.3594\n",
      "Epoch 514/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2329 - accuracy: 0.4463 - val_loss: 1.3310 - val_accuracy: 0.3203\n",
      "Epoch 515/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2416 - accuracy: 0.4312 - val_loss: 1.2893 - val_accuracy: 0.4102\n",
      "Epoch 516/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2426 - accuracy: 0.4244 - val_loss: 1.2811 - val_accuracy: 0.3750\n",
      "Epoch 517/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2458 - accuracy: 0.4190 - val_loss: 1.1996 - val_accuracy: 0.4609\n",
      "Epoch 518/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2482 - accuracy: 0.4202 - val_loss: 1.1843 - val_accuracy: 0.5195\n",
      "Epoch 519/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2276 - accuracy: 0.4442 - val_loss: 1.4078 - val_accuracy: 0.2773\n",
      "Epoch 520/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2394 - accuracy: 0.4179 - val_loss: 1.4057 - val_accuracy: 0.2656\n",
      "Epoch 521/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2376 - accuracy: 0.4326 - val_loss: 1.3967 - val_accuracy: 0.2930\n",
      "Epoch 522/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2198 - accuracy: 0.4436 - val_loss: 1.3211 - val_accuracy: 0.3438\n",
      "Epoch 523/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2428 - accuracy: 0.4486 - val_loss: 1.2436 - val_accuracy: 0.3711\n",
      "Epoch 524/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2472 - accuracy: 0.4227 - val_loss: 1.3206 - val_accuracy: 0.3672\n",
      "Epoch 525/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2451 - accuracy: 0.4287 - val_loss: 1.2866 - val_accuracy: 0.3711\n",
      "Epoch 526/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2200 - accuracy: 0.4384 - val_loss: 1.2395 - val_accuracy: 0.4180\n",
      "Epoch 527/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2362 - accuracy: 0.4302 - val_loss: 1.3503 - val_accuracy: 0.2891\n",
      "Epoch 528/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2208 - accuracy: 0.4424 - val_loss: 1.2160 - val_accuracy: 0.4648\n",
      "Epoch 529/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2350 - accuracy: 0.4298 - val_loss: 1.2817 - val_accuracy: 0.3828\n",
      "Epoch 530/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2341 - accuracy: 0.4280 - val_loss: 1.2030 - val_accuracy: 0.4180\n",
      "Epoch 531/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2427 - accuracy: 0.4281 - val_loss: 1.3990 - val_accuracy: 0.2969\n",
      "Epoch 532/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2155 - accuracy: 0.4463 - val_loss: 1.4137 - val_accuracy: 0.2773\n",
      "Epoch 533/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2555 - accuracy: 0.4269 - val_loss: 1.1937 - val_accuracy: 0.4688\n",
      "Epoch 534/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2227 - accuracy: 0.4304 - val_loss: 1.3306 - val_accuracy: 0.3320\n",
      "Epoch 535/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2315 - accuracy: 0.4413 - val_loss: 1.1779 - val_accuracy: 0.5352\n",
      "Epoch 536/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2244 - accuracy: 0.4478 - val_loss: 1.2853 - val_accuracy: 0.3711\n",
      "Epoch 537/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2016 - accuracy: 0.4483 - val_loss: 1.2647 - val_accuracy: 0.4062\n",
      "Epoch 538/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2363 - accuracy: 0.4284 - val_loss: 1.1117 - val_accuracy: 0.5508\n",
      "Epoch 539/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2414 - accuracy: 0.4302 - val_loss: 1.2052 - val_accuracy: 0.4727\n",
      "Epoch 540/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2396 - accuracy: 0.4228 - val_loss: 1.2067 - val_accuracy: 0.4141\n",
      "Epoch 541/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2191 - accuracy: 0.4374 - val_loss: 1.2923 - val_accuracy: 0.3672\n",
      "Epoch 542/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2181 - accuracy: 0.4317 - val_loss: 1.2696 - val_accuracy: 0.3633\n",
      "Epoch 543/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2319 - accuracy: 0.4325 - val_loss: 1.1204 - val_accuracy: 0.5195\n",
      "Epoch 544/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2095 - accuracy: 0.4523 - val_loss: 1.1852 - val_accuracy: 0.4844\n",
      "Epoch 545/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2334 - accuracy: 0.4156 - val_loss: 1.1854 - val_accuracy: 0.5430\n",
      "Epoch 546/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2501 - accuracy: 0.4138 - val_loss: 1.2295 - val_accuracy: 0.4219\n",
      "Epoch 547/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2158 - accuracy: 0.4340 - val_loss: 1.2591 - val_accuracy: 0.4023\n",
      "Epoch 548/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2418 - accuracy: 0.4310 - val_loss: 1.1482 - val_accuracy: 0.5156\n",
      "Epoch 549/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2133 - accuracy: 0.4314 - val_loss: 1.2924 - val_accuracy: 0.3594\n",
      "Epoch 550/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2092 - accuracy: 0.4377 - val_loss: 1.3392 - val_accuracy: 0.3359\n",
      "Epoch 551/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2510 - accuracy: 0.4150 - val_loss: 1.1978 - val_accuracy: 0.4531\n",
      "Epoch 552/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2337 - accuracy: 0.4328 - val_loss: 1.1980 - val_accuracy: 0.4570\n",
      "Epoch 553/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2345 - accuracy: 0.4227 - val_loss: 1.3581 - val_accuracy: 0.2812\n",
      "Epoch 554/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2311 - accuracy: 0.4283 - val_loss: 1.1764 - val_accuracy: 0.4688\n",
      "Epoch 555/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2334 - accuracy: 0.4399 - val_loss: 1.3466 - val_accuracy: 0.3086\n",
      "Epoch 556/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2514 - accuracy: 0.4314 - val_loss: 1.1542 - val_accuracy: 0.5117\n",
      "Epoch 557/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2221 - accuracy: 0.4306 - val_loss: 1.3374 - val_accuracy: 0.3281\n",
      "Epoch 558/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2488 - accuracy: 0.4119 - val_loss: 1.1716 - val_accuracy: 0.4805\n",
      "Epoch 559/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2285 - accuracy: 0.4415 - val_loss: 1.2598 - val_accuracy: 0.3906\n",
      "Epoch 560/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2246 - accuracy: 0.4334 - val_loss: 1.2001 - val_accuracy: 0.4688\n",
      "Epoch 561/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2517 - accuracy: 0.4185 - val_loss: 1.5883 - val_accuracy: 0.2227\n",
      "Epoch 562/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2463 - accuracy: 0.4322 - val_loss: 1.2484 - val_accuracy: 0.3906\n",
      "Epoch 563/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2126 - accuracy: 0.4444 - val_loss: 1.1806 - val_accuracy: 0.4609\n",
      "Epoch 564/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2502 - accuracy: 0.4239 - val_loss: 1.2758 - val_accuracy: 0.4062\n",
      "Epoch 565/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2150 - accuracy: 0.4381 - val_loss: 1.5870 - val_accuracy: 0.2422\n",
      "Epoch 566/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2359 - accuracy: 0.4295 - val_loss: 1.2924 - val_accuracy: 0.3555\n",
      "Epoch 567/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2292 - accuracy: 0.4284 - val_loss: 1.3074 - val_accuracy: 0.3359\n",
      "Epoch 568/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2315 - accuracy: 0.4163 - val_loss: 1.2167 - val_accuracy: 0.3984\n",
      "Epoch 569/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2673 - accuracy: 0.4061 - val_loss: 1.2764 - val_accuracy: 0.3438\n",
      "Epoch 570/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2328 - accuracy: 0.4383 - val_loss: 1.4014 - val_accuracy: 0.2695\n",
      "Epoch 571/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2188 - accuracy: 0.4434 - val_loss: 1.3162 - val_accuracy: 0.3281\n",
      "Epoch 572/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2230 - accuracy: 0.4555 - val_loss: 1.3255 - val_accuracy: 0.2969\n",
      "Epoch 573/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2313 - accuracy: 0.4374 - val_loss: 1.2393 - val_accuracy: 0.4258\n",
      "Epoch 574/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2040 - accuracy: 0.4428 - val_loss: 1.1385 - val_accuracy: 0.5195\n",
      "Epoch 575/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2472 - accuracy: 0.4195 - val_loss: 1.2816 - val_accuracy: 0.3672\n",
      "Epoch 576/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2158 - accuracy: 0.4336 - val_loss: 1.1405 - val_accuracy: 0.5156\n",
      "Epoch 577/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2318 - accuracy: 0.4180 - val_loss: 1.1069 - val_accuracy: 0.5273\n",
      "Epoch 578/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2247 - accuracy: 0.4279 - val_loss: 1.1725 - val_accuracy: 0.4805\n",
      "Epoch 579/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2289 - accuracy: 0.4489 - val_loss: 1.3197 - val_accuracy: 0.3320\n",
      "Epoch 580/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2313 - accuracy: 0.4311 - val_loss: 1.1230 - val_accuracy: 0.5117\n",
      "Epoch 581/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2094 - accuracy: 0.4405 - val_loss: 1.2699 - val_accuracy: 0.4414\n",
      "Epoch 582/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2340 - accuracy: 0.4341 - val_loss: 1.2931 - val_accuracy: 0.3164\n",
      "Epoch 583/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2284 - accuracy: 0.4479 - val_loss: 1.2317 - val_accuracy: 0.4375\n",
      "Epoch 584/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2304 - accuracy: 0.4485 - val_loss: 1.1836 - val_accuracy: 0.5000\n",
      "Epoch 585/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2242 - accuracy: 0.4327 - val_loss: 1.2599 - val_accuracy: 0.3906\n",
      "Epoch 586/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2002 - accuracy: 0.4452 - val_loss: 1.1777 - val_accuracy: 0.5195\n",
      "Epoch 587/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2191 - accuracy: 0.4580 - val_loss: 1.1585 - val_accuracy: 0.5000\n",
      "Epoch 588/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2378 - accuracy: 0.4386 - val_loss: 1.2292 - val_accuracy: 0.4609\n",
      "Epoch 589/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2315 - accuracy: 0.4308 - val_loss: 1.3045 - val_accuracy: 0.3086\n",
      "Epoch 590/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2079 - accuracy: 0.4451 - val_loss: 1.2212 - val_accuracy: 0.4648\n",
      "Epoch 591/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2160 - accuracy: 0.4495 - val_loss: 1.2367 - val_accuracy: 0.3984\n",
      "Epoch 592/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2341 - accuracy: 0.4464 - val_loss: 1.1136 - val_accuracy: 0.5312\n",
      "Epoch 593/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2370 - accuracy: 0.4292 - val_loss: 1.2319 - val_accuracy: 0.4375\n",
      "Epoch 594/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2272 - accuracy: 0.4376 - val_loss: 1.2367 - val_accuracy: 0.4336\n",
      "Epoch 595/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2382 - accuracy: 0.4335 - val_loss: 1.2545 - val_accuracy: 0.3984\n",
      "Epoch 596/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2256 - accuracy: 0.4291 - val_loss: 1.3858 - val_accuracy: 0.2930\n",
      "Epoch 597/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2447 - accuracy: 0.4363 - val_loss: 1.3001 - val_accuracy: 0.3438\n",
      "Epoch 598/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2183 - accuracy: 0.4363 - val_loss: 1.2569 - val_accuracy: 0.3711\n",
      "Epoch 599/4000\n",
      "128/128 [==============================] - 7s 55ms/step - loss: 1.2133 - accuracy: 0.4410 - val_loss: 1.4044 - val_accuracy: 0.2969\n",
      "Epoch 600/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2087 - accuracy: 0.4489 - val_loss: 1.4245 - val_accuracy: 0.2422\n",
      "Epoch 601/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2543 - accuracy: 0.4199 - val_loss: 1.3919 - val_accuracy: 0.2812\n",
      "Epoch 602/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2480 - accuracy: 0.4301 - val_loss: 1.2649 - val_accuracy: 0.3711\n",
      "Epoch 603/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2058 - accuracy: 0.4444 - val_loss: 1.2182 - val_accuracy: 0.4297\n",
      "Epoch 604/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2331 - accuracy: 0.4344 - val_loss: 1.4202 - val_accuracy: 0.2930\n",
      "Epoch 605/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2293 - accuracy: 0.4404 - val_loss: 1.1839 - val_accuracy: 0.4805\n",
      "Epoch 606/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2347 - accuracy: 0.4346 - val_loss: 1.2485 - val_accuracy: 0.4453\n",
      "Epoch 607/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2588 - accuracy: 0.4215 - val_loss: 1.3308 - val_accuracy: 0.3516\n",
      "Epoch 608/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2302 - accuracy: 0.4440 - val_loss: 1.2416 - val_accuracy: 0.4023\n",
      "Epoch 609/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2364 - accuracy: 0.4363 - val_loss: 1.4165 - val_accuracy: 0.2891\n",
      "Epoch 610/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2244 - accuracy: 0.4459 - val_loss: 1.2651 - val_accuracy: 0.3867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2310 - accuracy: 0.4301 - val_loss: 1.2104 - val_accuracy: 0.4062\n",
      "Epoch 612/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2152 - accuracy: 0.4640 - val_loss: 1.2011 - val_accuracy: 0.4805\n",
      "Epoch 613/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2353 - accuracy: 0.4296 - val_loss: 1.2247 - val_accuracy: 0.4688\n",
      "Epoch 614/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2166 - accuracy: 0.4373 - val_loss: 1.1613 - val_accuracy: 0.5039\n",
      "Epoch 615/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2312 - accuracy: 0.4393 - val_loss: 1.1534 - val_accuracy: 0.4961\n",
      "Epoch 616/4000\n",
      "128/128 [==============================] - 8s 60ms/step - loss: 1.2406 - accuracy: 0.4313 - val_loss: 1.2785 - val_accuracy: 0.3789\n",
      "Epoch 617/4000\n",
      "128/128 [==============================] - 7s 58ms/step - loss: 1.2231 - accuracy: 0.4371 - val_loss: 1.2550 - val_accuracy: 0.4219\n",
      "Epoch 618/4000\n",
      "128/128 [==============================] - 8s 59ms/step - loss: 1.2421 - accuracy: 0.4316 - val_loss: 1.1794 - val_accuracy: 0.4883\n",
      "Epoch 619/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2152 - accuracy: 0.4327 - val_loss: 1.3784 - val_accuracy: 0.3008\n",
      "Epoch 620/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2076 - accuracy: 0.4606 - val_loss: 1.3038 - val_accuracy: 0.3203\n",
      "Epoch 621/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2351 - accuracy: 0.4358 - val_loss: 1.1415 - val_accuracy: 0.5195\n",
      "Epoch 622/4000\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 1.2437 - accuracy: 0.4204 - val_loss: 1.4581 - val_accuracy: 0.2461\n",
      "Epoch 623/4000\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 1.2347 - accuracy: 0.4265 - val_loss: 1.4139 - val_accuracy: 0.2812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00623: early stopping\n",
      "128/128 [==============================] - 7s 54ms/step - loss: 1.3075 - accuracy: 0.3635\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.1095 - accuracy: 0.5391\n",
      "Train: 0.364, Val: 0.539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit model\n",
    "\n",
    "res_history = res50model.fit(res_train,\n",
    "        epochs=4000,\n",
    "        validation_data=res_val,\n",
    "        verbose = 1, \n",
    "        validation_steps = len(val_set),\n",
    "        callbacks = [es])\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = res50model.evaluate(training_set, verbose=1)\n",
    "_, val_acc = res50model.evaluate(val_set, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calling `save('res50_net.h5')`.\n",
    "res50model.save(r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Models\\Res50_net.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 17ms/step - loss: 1.0059 - accuracy: 0.6265\n",
      "Test loss: 1.0058972835540771\n",
      "Test accuracy: 0.6264591217041016\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = res50model.evaluate(res_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = res50model.predict(res_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = res_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = res_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "res50_prebuilt_predictions = pd.DataFrame({'Filename': filenames,'ResNet50': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(res50_prebuilt_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del res50_prebuilt_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>AlexNet</th>\n",
       "      <th>ResNet50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample3-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample4-sperm15.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm17.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm2.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>class3\\image_036.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>class3\\image_038.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>class3\\image_040.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>class3\\image_048.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>class3\\image_051.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test  Model_1  AlexNet  \\\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     0        3        1   \n",
       "1     class0\\ch00_p1-pl2-sample3-sperm4.tif      0     1        0        0   \n",
       "2    class0\\ch00_p1-pl2-sample4-sperm15.tif      0     3        3        3   \n",
       "3    class0\\ch00_p1-pl3-sample1-sperm17.tif      0     3        3        1   \n",
       "4     class0\\ch00_p1-pl3-sample1-sperm2.tif      0     3        0        3   \n",
       "..                                      ...    ...   ...      ...      ...   \n",
       "252                    class3\\image_036.BMP      3     3        3        3   \n",
       "253                    class3\\image_038.BMP      3     2        3        1   \n",
       "254                    class3\\image_040.BMP      3     2        3        3   \n",
       "255                    class3\\image_048.BMP      3     3        3        3   \n",
       "256                    class3\\image_051.BMP      3     3        1        3   \n",
       "\n",
       "     ResNet50  \n",
       "0           3  \n",
       "1           2  \n",
       "2           1  \n",
       "3           0  \n",
       "4           3  \n",
       "..        ...  \n",
       "252         1  \n",
       "253         3  \n",
       "254         3  \n",
       "255         3  \n",
       "256         3  \n",
       "\n",
       "[257 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   4   3  21]\n",
      " [  0   6   8  43]\n",
      " [  0   2   5  20]\n",
      " [  2  20  13 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.60      0.10      0.17        31\n",
      "      class1       0.19      0.11      0.13        57\n",
      "      class2       0.17      0.19      0.18        27\n",
      "      class3       0.56      0.75      0.64       142\n",
      "\n",
      "    accuracy                           0.47       257\n",
      "   macro avg       0.38      0.29      0.28       257\n",
      "weighted avg       0.44      0.47      0.42       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix and classification report\n",
    "class_labels = list(test_set.class_indices.keys())   \n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET50 Trained from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50model_2 = Sequential()\n",
    "\n",
    "#Layer 1: RES50 without top layer\n",
    "res50model_2.add(ResNet50(weights=None, input_shape= (32,32,3),\n",
    "                 include_top = False, classes=5,))\n",
    "\n",
    "#Layer 2: RES50 without top layer\n",
    "res50model_2.add(Flatten())\n",
    "res50model_2.add(Dense(4, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 23,542,788\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res50model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "\n",
    "res50model_2.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "128/128 [==============================] - 15s 71ms/step - loss: 2.3391 - accuracy: 0.2787 - val_loss: 1.7503 - val_accuracy: 0.2188\n",
      "Epoch 2/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.5931 - accuracy: 0.3284 - val_loss: 1.4251 - val_accuracy: 0.1211\n",
      "Epoch 3/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.6480 - accuracy: 0.3613 - val_loss: 1.5202 - val_accuracy: 0.2461\n",
      "Epoch 4/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.5496 - accuracy: 0.3676 - val_loss: 1.2118 - val_accuracy: 0.5078\n",
      "Epoch 5/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.5390 - accuracy: 0.4045 - val_loss: 6.1870 - val_accuracy: 0.4023\n",
      "Epoch 6/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.5084 - accuracy: 0.3969 - val_loss: 1.2809 - val_accuracy: 0.3398\n",
      "Epoch 7/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4778 - accuracy: 0.4155 - val_loss: 1.4312 - val_accuracy: 0.1797\n",
      "Epoch 8/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.5430 - accuracy: 0.3989 - val_loss: 10.5480 - val_accuracy: 0.5586\n",
      "Epoch 9/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.5588 - accuracy: 0.3463 - val_loss: 1.3203 - val_accuracy: 0.3555\n",
      "Epoch 10/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.4924 - accuracy: 0.3777 - val_loss: 1.3915 - val_accuracy: 0.2383\n",
      "Epoch 11/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4716 - accuracy: 0.3889 - val_loss: 1.2137 - val_accuracy: 0.4727\n",
      "Epoch 12/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.4418 - accuracy: 0.3884 - val_loss: 1.4770 - val_accuracy: 0.2422\n",
      "Epoch 13/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 1.4281 - accuracy: 0.4224 - val_loss: 1.2464 - val_accuracy: 0.5234\n",
      "Epoch 14/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.6215 - accuracy: 0.2753 - val_loss: 1.1710 - val_accuracy: 0.5586\n",
      "Epoch 15/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.5857 - accuracy: 0.2769 - val_loss: 1.7583 - val_accuracy: 0.0977\n",
      "Epoch 16/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.7224 - accuracy: 0.2813 - val_loss: 1.3166 - val_accuracy: 0.5000\n",
      "Epoch 17/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.6340 - accuracy: 0.2765 - val_loss: 1.4334 - val_accuracy: 0.2266\n",
      "Epoch 18/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.5413 - accuracy: 0.2845 - val_loss: 6.5990 - val_accuracy: 0.0977\n",
      "Epoch 19/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.4960 - accuracy: 0.3200 - val_loss: 8.4816 - val_accuracy: 0.0977\n",
      "Epoch 20/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 1.6433 - accuracy: 0.3112 - val_loss: 2.4169 - val_accuracy: 0.4531\n",
      "Epoch 21/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 1.6149 - accuracy: 0.3030 - val_loss: 1.4949 - val_accuracy: 0.1914\n",
      "Epoch 22/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.5832 - accuracy: 0.3283 - val_loss: 1.3135 - val_accuracy: 0.3359\n",
      "Epoch 23/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.5844 - accuracy: 0.3520 - val_loss: 1.3264 - val_accuracy: 0.4336\n",
      "Epoch 24/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.4804 - accuracy: 0.3639 - val_loss: 1.3196 - val_accuracy: 0.3438\n",
      "Epoch 25/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5473 - accuracy: 0.3709 - val_loss: 1.3222 - val_accuracy: 0.5000\n",
      "Epoch 26/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4608 - accuracy: 0.3051 - val_loss: 1.2190 - val_accuracy: 0.3750\n",
      "Epoch 27/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4574 - accuracy: 0.3653 - val_loss: 1.1790 - val_accuracy: 0.4922\n",
      "Epoch 28/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.5533 - accuracy: 0.3961 - val_loss: 1.2300 - val_accuracy: 0.3633\n",
      "Epoch 29/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5909 - accuracy: 0.3629 - val_loss: 14.3272 - val_accuracy: 0.3164\n",
      "Epoch 30/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5710 - accuracy: 0.3059 - val_loss: 1.3794 - val_accuracy: 0.4258\n",
      "Epoch 31/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5449 - accuracy: 0.2895 - val_loss: 33.1134 - val_accuracy: 0.2188\n",
      "Epoch 32/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.5226 - accuracy: 0.2604 - val_loss: 4.0191 - val_accuracy: 0.1406\n",
      "Epoch 33/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.5606 - accuracy: 0.2788 - val_loss: 2.3394 - val_accuracy: 0.3633\n",
      "Epoch 34/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.5121 - accuracy: 0.2834 - val_loss: 1.3562 - val_accuracy: 0.1641\n",
      "Epoch 35/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.5171 - accuracy: 0.2932 - val_loss: 1.7783 - val_accuracy: 0.0938\n",
      "Epoch 36/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.5710 - accuracy: 0.2909 - val_loss: 1.3259 - val_accuracy: 0.2695\n",
      "Epoch 37/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4921 - accuracy: 0.3320 - val_loss: 1.3167 - val_accuracy: 0.5664\n",
      "Epoch 38/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.6093 - accuracy: 0.2828 - val_loss: 1.1662 - val_accuracy: 0.5703\n",
      "Epoch 39/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.5348 - accuracy: 0.3051 - val_loss: 1.2123 - val_accuracy: 0.5625\n",
      "Epoch 40/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4657 - accuracy: 0.3285 - val_loss: 11.5785 - val_accuracy: 0.0977\n",
      "Epoch 41/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.5350 - accuracy: 0.2776 - val_loss: 2.0594 - val_accuracy: 0.2109\n",
      "Epoch 42/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.4388 - accuracy: 0.3070 - val_loss: 1.3050 - val_accuracy: 0.2109\n",
      "Epoch 43/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5139 - accuracy: 0.3092 - val_loss: 1.2956 - val_accuracy: 0.2227\n",
      "Epoch 44/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4568 - accuracy: 0.3317 - val_loss: 1.2732 - val_accuracy: 0.5430\n",
      "Epoch 45/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.4803 - accuracy: 0.3619 - val_loss: 1.4388 - val_accuracy: 0.2070\n",
      "Epoch 46/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5181 - accuracy: 0.3601 - val_loss: 2.3766 - val_accuracy: 0.2930\n",
      "Epoch 47/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.3979 - accuracy: 0.3720 - val_loss: 33.7422 - val_accuracy: 0.1953\n",
      "Epoch 48/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.6688 - accuracy: 0.3273 - val_loss: 1.6179 - val_accuracy: 0.1328\n",
      "Epoch 49/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.4731 - accuracy: 0.3501 - val_loss: 1.3570 - val_accuracy: 0.3984\n",
      "Epoch 50/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.5705 - accuracy: 0.3079 - val_loss: 1.4035 - val_accuracy: 0.2031\n",
      "Epoch 51/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 1.5289 - accuracy: 0.3020 - val_loss: 1.5658 - val_accuracy: 0.1055\n",
      "Epoch 52/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.5170 - accuracy: 0.2728 - val_loss: 1.2565 - val_accuracy: 0.5547\n",
      "Epoch 53/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.4982 - accuracy: 0.3305 - val_loss: 1.3288 - val_accuracy: 0.5352\n",
      "Epoch 54/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.4986 - accuracy: 0.3423 - val_loss: 1.3349 - val_accuracy: 0.3203\n",
      "Epoch 55/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.4727 - accuracy: 0.3682 - val_loss: 1.2370 - val_accuracy: 0.5234\n",
      "Epoch 56/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4982 - accuracy: 0.3394 - val_loss: 1.2992 - val_accuracy: 0.5000\n",
      "Epoch 57/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4429 - accuracy: 0.3698 - val_loss: 1.2680 - val_accuracy: 0.4453\n",
      "Epoch 58/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.4624 - accuracy: 0.3298 - val_loss: 1.2859 - val_accuracy: 0.3672\n",
      "Epoch 59/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.4271 - accuracy: 0.3700 - val_loss: 1.3176 - val_accuracy: 0.4531\n",
      "Epoch 60/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.5159 - accuracy: 0.3554 - val_loss: 1.2508 - val_accuracy: 0.4297\n",
      "Epoch 61/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.4332 - accuracy: 0.3551 - val_loss: 1.4015 - val_accuracy: 0.1289\n",
      "Epoch 62/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.4105 - accuracy: 0.3615 - val_loss: 1.3695 - val_accuracy: 0.3359\n",
      "Epoch 63/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.4556 - accuracy: 0.3362 - val_loss: 1.3101 - val_accuracy: 0.3594\n",
      "Epoch 64/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.4524 - accuracy: 0.3531 - val_loss: 1.2339 - val_accuracy: 0.5078\n",
      "Epoch 65/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 1.4087 - accuracy: 0.3454 - val_loss: 1.2914 - val_accuracy: 0.2773\n",
      "Epoch 66/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 1.5486 - accuracy: 0.3681 - val_loss: 1.3152 - val_accuracy: 0.2578\n",
      "Epoch 67/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 1.3991 - accuracy: 0.3755 - val_loss: 1.2510 - val_accuracy: 0.4023\n",
      "Epoch 68/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4047 - accuracy: 0.3881 - val_loss: 1.2534 - val_accuracy: 0.4570\n",
      "Epoch 69/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4225 - accuracy: 0.3574 - val_loss: 1.5023 - val_accuracy: 0.1133\n",
      "Epoch 70/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.4926 - accuracy: 0.3419 - val_loss: 1.3345 - val_accuracy: 0.2812\n",
      "Epoch 71/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 1.4440 - accuracy: 0.3793 - val_loss: 1.4056 - val_accuracy: 0.3125\n",
      "Epoch 72/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 1.4708 - accuracy: 0.3906 - val_loss: 1.2443 - val_accuracy: 0.3594\n",
      "Epoch 73/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.3989 - accuracy: 0.3904 - val_loss: 1.2690 - val_accuracy: 0.3984\n",
      "Epoch 74/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.3845 - accuracy: 0.4011 - val_loss: 1.2391 - val_accuracy: 0.4375\n",
      "Epoch 75/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3459 - accuracy: 0.3939 - val_loss: 1.2185 - val_accuracy: 0.3477\n",
      "Epoch 76/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.3690 - accuracy: 0.4060 - val_loss: 1.2409 - val_accuracy: 0.3281\n",
      "Epoch 77/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3557 - accuracy: 0.4206 - val_loss: 1.3034 - val_accuracy: 0.2930\n",
      "Epoch 78/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 1.4462 - accuracy: 0.4191 - val_loss: 1.1999 - val_accuracy: 0.4805\n",
      "Epoch 79/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.3724 - accuracy: 0.4074 - val_loss: 1.2368 - val_accuracy: 0.2969\n",
      "Epoch 80/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4224 - accuracy: 0.4150 - val_loss: 2.7807 - val_accuracy: 0.2383\n",
      "Epoch 81/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 1.4523 - accuracy: 0.3775 - val_loss: 1.2158 - val_accuracy: 0.5664\n",
      "Epoch 82/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.5696 - accuracy: 0.3669 - val_loss: 1.2452 - val_accuracy: 0.3672\n",
      "Epoch 83/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4672 - accuracy: 0.3209 - val_loss: 1.3496 - val_accuracy: 0.5586\n",
      "Epoch 84/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4788 - accuracy: 0.2819 - val_loss: 1.3342 - val_accuracy: 0.3242\n",
      "Epoch 85/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.4253 - accuracy: 0.2973 - val_loss: 1.3494 - val_accuracy: 0.2891\n",
      "Epoch 86/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4964 - accuracy: 0.3151 - val_loss: 1.4164 - val_accuracy: 0.1328\n",
      "Epoch 87/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.5145 - accuracy: 0.2860 - val_loss: 1.3794 - val_accuracy: 0.4844\n",
      "Epoch 88/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.5561 - accuracy: 0.2933 - val_loss: 1.3138 - val_accuracy: 0.5000\n",
      "Epoch 89/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.4360 - accuracy: 0.3289 - val_loss: 1.3018 - val_accuracy: 0.3281\n",
      "Epoch 90/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.4942 - accuracy: 0.3153 - val_loss: 1.3425 - val_accuracy: 0.2812\n",
      "Epoch 91/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.4546 - accuracy: 0.2917 - val_loss: 1.3518 - val_accuracy: 0.1992\n",
      "Epoch 92/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.5025 - accuracy: 0.2977 - val_loss: 1.3361 - val_accuracy: 0.3047\n",
      "Epoch 93/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4334 - accuracy: 0.2940 - val_loss: 1.3270 - val_accuracy: 0.2500\n",
      "Epoch 94/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4531 - accuracy: 0.3032 - val_loss: 1.2971 - val_accuracy: 0.2852\n",
      "Epoch 95/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4413 - accuracy: 0.3010 - val_loss: 9.3837 - val_accuracy: 0.4453\n",
      "Epoch 96/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4515 - accuracy: 0.3215 - val_loss: 1.3539 - val_accuracy: 0.3828\n",
      "Epoch 97/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.4442 - accuracy: 0.3100 - val_loss: 1.3821 - val_accuracy: 0.3672\n",
      "Epoch 98/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4375 - accuracy: 0.3311 - val_loss: 1.3416 - val_accuracy: 0.4258\n",
      "Epoch 99/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4757 - accuracy: 0.3061 - val_loss: 1.6691 - val_accuracy: 0.5391\n",
      "Epoch 100/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4127 - accuracy: 0.3265 - val_loss: 1.5225 - val_accuracy: 0.4492\n",
      "Epoch 101/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.4507 - accuracy: 0.3513 - val_loss: 1.3086 - val_accuracy: 0.4766\n",
      "Epoch 102/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.4012 - accuracy: 0.3562 - val_loss: 2.3447 - val_accuracy: 0.3008\n",
      "Epoch 103/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4499 - accuracy: 0.3474 - val_loss: 1.4152 - val_accuracy: 0.4531\n",
      "Epoch 104/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4180 - accuracy: 0.3302 - val_loss: 3.0603 - val_accuracy: 0.4688\n",
      "Epoch 105/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.4154 - accuracy: 0.3635 - val_loss: 1.3383 - val_accuracy: 0.4570\n",
      "Epoch 106/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4733 - accuracy: 0.2809 - val_loss: 1.3395 - val_accuracy: 0.3750\n",
      "Epoch 107/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.5451 - accuracy: 0.2926 - val_loss: 1.3453 - val_accuracy: 0.3984\n",
      "Epoch 108/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4740 - accuracy: 0.2822 - val_loss: 2.9582 - val_accuracy: 0.3633\n",
      "Epoch 109/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4722 - accuracy: 0.2926 - val_loss: 1.4128 - val_accuracy: 0.4219\n",
      "Epoch 110/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.5033 - accuracy: 0.3216 - val_loss: 1.4524 - val_accuracy: 0.3828\n",
      "Epoch 111/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4043 - accuracy: 0.3301 - val_loss: 1.3588 - val_accuracy: 0.3945\n",
      "Epoch 112/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.4079 - accuracy: 0.3629 - val_loss: 10.2559 - val_accuracy: 0.2383\n",
      "Epoch 113/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 8s 63ms/step - loss: 1.4117 - accuracy: 0.3352 - val_loss: 1.2993 - val_accuracy: 0.4180\n",
      "Epoch 114/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4278 - accuracy: 0.3379 - val_loss: 1.3214 - val_accuracy: 0.4648\n",
      "Epoch 115/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3859 - accuracy: 0.3569 - val_loss: 1.4041 - val_accuracy: 0.1719\n",
      "Epoch 116/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.4019 - accuracy: 0.3528 - val_loss: 1.3213 - val_accuracy: 0.3594\n",
      "Epoch 117/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4678 - accuracy: 0.3581 - val_loss: 1.2762 - val_accuracy: 0.4102\n",
      "Epoch 118/4000\n",
      "128/128 [==============================] - 9s 67ms/step - loss: 1.3861 - accuracy: 0.3557 - val_loss: 3.0549 - val_accuracy: 0.3398\n",
      "Epoch 119/4000\n",
      "128/128 [==============================] - 8s 66ms/step - loss: 1.3805 - accuracy: 0.3346 - val_loss: 1.3092 - val_accuracy: 0.3789\n",
      "Epoch 120/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3819 - accuracy: 0.3721 - val_loss: 1.5902 - val_accuracy: 0.4727\n",
      "Epoch 121/4000\n",
      "128/128 [==============================] - 9s 66ms/step - loss: 1.4192 - accuracy: 0.3497 - val_loss: 1.2758 - val_accuracy: 0.3555\n",
      "Epoch 122/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4102 - accuracy: 0.3634 - val_loss: 1.2814 - val_accuracy: 0.4414\n",
      "Epoch 123/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.4185 - accuracy: 0.3399 - val_loss: 1.8823 - val_accuracy: 0.2930\n",
      "Epoch 124/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.4148 - accuracy: 0.3436 - val_loss: 2.5875 - val_accuracy: 0.3008\n",
      "Epoch 125/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.3804 - accuracy: 0.3448 - val_loss: 6.6306 - val_accuracy: 0.2812\n",
      "Epoch 126/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3724 - accuracy: 0.3435 - val_loss: 1.2804 - val_accuracy: 0.4570\n",
      "Epoch 127/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3713 - accuracy: 0.3480 - val_loss: 1.3689 - val_accuracy: 0.3789\n",
      "Epoch 128/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3491 - accuracy: 0.3583 - val_loss: 5.4996 - val_accuracy: 0.3242\n",
      "Epoch 129/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.3506 - accuracy: 0.3760 - val_loss: 3.5965 - val_accuracy: 0.3320\n",
      "Epoch 130/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3605 - accuracy: 0.3725 - val_loss: 1.2807 - val_accuracy: 0.4453\n",
      "Epoch 131/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3192 - accuracy: 0.3824 - val_loss: 1.2840 - val_accuracy: 0.2656\n",
      "Epoch 132/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3248 - accuracy: 0.3930 - val_loss: 1.2830 - val_accuracy: 0.2852\n",
      "Epoch 133/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3171 - accuracy: 0.3908 - val_loss: 1.2539 - val_accuracy: 0.2969\n",
      "Epoch 134/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2786 - accuracy: 0.4130 - val_loss: 1.2592 - val_accuracy: 0.3203\n",
      "Epoch 135/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.3058 - accuracy: 0.3990 - val_loss: 1.2443 - val_accuracy: 0.2812\n",
      "Epoch 136/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2887 - accuracy: 0.4145 - val_loss: 1.2020 - val_accuracy: 0.4180\n",
      "Epoch 137/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3028 - accuracy: 0.4045 - val_loss: 1.2209 - val_accuracy: 0.4922\n",
      "Epoch 138/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.3196 - accuracy: 0.3813 - val_loss: 1.2970 - val_accuracy: 0.2734\n",
      "Epoch 139/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2795 - accuracy: 0.4102 - val_loss: 1.2463 - val_accuracy: 0.3125\n",
      "Epoch 140/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2751 - accuracy: 0.4123 - val_loss: 1.2231 - val_accuracy: 0.3047\n",
      "Epoch 141/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2812 - accuracy: 0.4164 - val_loss: 1.3934 - val_accuracy: 0.3047\n",
      "Epoch 142/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2955 - accuracy: 0.4011 - val_loss: 1.2364 - val_accuracy: 0.2695\n",
      "Epoch 143/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2767 - accuracy: 0.4045 - val_loss: 1.2714 - val_accuracy: 0.2891\n",
      "Epoch 144/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2689 - accuracy: 0.4184 - val_loss: 1.2087 - val_accuracy: 0.4023\n",
      "Epoch 145/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2560 - accuracy: 0.4269 - val_loss: 1.2125 - val_accuracy: 0.4609ss: 1.2\n",
      "Epoch 146/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2755 - accuracy: 0.4142 - val_loss: 1.9640 - val_accuracy: 0.2852\n",
      "Epoch 147/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2743 - accuracy: 0.4217 - val_loss: 1.7914 - val_accuracy: 0.3281\n",
      "Epoch 148/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2626 - accuracy: 0.4155 - val_loss: 1.2303 - val_accuracy: 0.3242\n",
      "Epoch 149/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2757 - accuracy: 0.4351 - val_loss: 1.2255 - val_accuracy: 0.3750\n",
      "Epoch 150/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.2241 - accuracy: 0.4567 - val_loss: 1.1685 - val_accuracy: 0.4492\n",
      "Epoch 151/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2337 - accuracy: 0.4398 - val_loss: 1.2592 - val_accuracy: 0.2656\n",
      "Epoch 152/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2581 - accuracy: 0.4386 - val_loss: 1.2133 - val_accuracy: 0.3594\n",
      "Epoch 153/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2437 - accuracy: 0.4343 - val_loss: 1.4379 - val_accuracy: 0.4023\n",
      "Epoch 154/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2629 - accuracy: 0.4149 - val_loss: 1.2982 - val_accuracy: 0.3086\n",
      "Epoch 155/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 1.2598 - accuracy: 0.4273 - val_loss: 1.1876 - val_accuracy: 0.3711\n",
      "Epoch 156/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2395 - accuracy: 0.4362 - val_loss: 1.2094 - val_accuracy: 0.3398\n",
      "Epoch 157/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2247 - accuracy: 0.4313 - val_loss: 1.2572 - val_accuracy: 0.3281\n",
      "Epoch 158/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2472 - accuracy: 0.4392 - val_loss: 1.2328 - val_accuracy: 0.2812- loss: 1.2475 - accura\n",
      "Epoch 159/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2274 - accuracy: 0.4304 - val_loss: 1.4334 - val_accuracy: 0.3047\n",
      "Epoch 160/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2479 - accuracy: 0.4409 - val_loss: 1.1972 - val_accuracy: 0.3164\n",
      "Epoch 161/4000\n",
      "128/128 [==============================] - 8s 63ms/step - loss: 1.2197 - accuracy: 0.4499 - val_loss: 1.1987 - val_accuracy: 0.3086\n",
      "Epoch 162/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2353 - accuracy: 0.4446 - val_loss: 1.2162 - val_accuracy: 0.3516\n",
      "Epoch 163/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2013 - accuracy: 0.4623 - val_loss: 1.1475 - val_accuracy: 0.4375\n",
      "Epoch 164/4000\n",
      "128/128 [==============================] - 8s 64ms/step - loss: 1.2318 - accuracy: 0.4267 - val_loss: 1.1663 - val_accuracy: 0.3750\n",
      "Epoch 165/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1703 - accuracy: 0.4676 - val_loss: 1.1802 - val_accuracy: 0.3711\n",
      "Epoch 166/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.2044 - accuracy: 0.4583 - val_loss: 1.2402 - val_accuracy: 0.4062\n",
      "Epoch 167/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1738 - accuracy: 0.4682 - val_loss: 1.1243 - val_accuracy: 0.4492\n",
      "Epoch 168/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1875 - accuracy: 0.4412 - val_loss: 1.2361 - val_accuracy: 0.2930\n",
      "Epoch 169/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1467 - accuracy: 0.4801 - val_loss: 1.1689 - val_accuracy: 0.4258\n",
      "Epoch 170/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1810 - accuracy: 0.4689 - val_loss: 1.2996 - val_accuracy: 0.3242\n",
      "Epoch 171/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1415 - accuracy: 0.4815 - val_loss: 1.1974 - val_accuracy: 0.3906\n",
      "Epoch 172/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1675 - accuracy: 0.4921 - val_loss: 1.1251 - val_accuracy: 0.4141\n",
      "Epoch 173/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1596 - accuracy: 0.4750 - val_loss: 1.3133 - val_accuracy: 0.2266\n",
      "Epoch 174/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1240 - accuracy: 0.4923 - val_loss: 1.2842 - val_accuracy: 0.3750\n",
      "Epoch 175/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1249 - accuracy: 0.4976 - val_loss: 1.1707 - val_accuracy: 0.4141\n",
      "Epoch 176/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.1357 - accuracy: 0.4896 - val_loss: 1.2462 - val_accuracy: 0.3359\n",
      "Epoch 177/4000\n",
      "128/128 [==============================] - 8s 61ms/step - loss: 1.1054 - accuracy: 0.4955 - val_loss: 1.1671 - val_accuracy: 0.3789\n",
      "Epoch 178/4000\n",
      "128/128 [==============================] - 8s 62ms/step - loss: 1.0928 - accuracy: 0.5187 - val_loss: 1.1130 - val_accuracy: 0.4688\n",
      "Epoch 179/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 1.0926 - accuracy: 0.5197 - val_loss: 1.1846 - val_accuracy: 0.3555\n",
      "Epoch 180/4000\n",
      "128/128 [==============================] - 8s 65ms/step - loss: 1.0893 - accuracy: 0.5062 - val_loss: 1.0649 - val_accuracy: 0.4453\n",
      "Epoch 181/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 1.1062 - accuracy: 0.5024 - val_loss: 1.0676 - val_accuracy: 0.4375\n",
      "Epoch 182/4000\n",
      "128/128 [==============================] - 11s 84ms/step - loss: 1.0874 - accuracy: 0.4973 - val_loss: 1.4054 - val_accuracy: 0.3086\n",
      "Epoch 183/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 1.0896 - accuracy: 0.5068 - val_loss: 1.2154 - val_accuracy: 0.3125\n",
      "Epoch 184/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 1.0660 - accuracy: 0.5271 - val_loss: 1.1807 - val_accuracy: 0.3984\n",
      "Epoch 185/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 1.0664 - accuracy: 0.5169 - val_loss: 1.2257 - val_accuracy: 0.3555\n",
      "Epoch 186/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 1.0616 - accuracy: 0.5212 - val_loss: 1.3001 - val_accuracy: 0.2891\n",
      "Epoch 187/4000\n",
      "128/128 [==============================] - 12s 91ms/step - loss: 1.0691 - accuracy: 0.5370 - val_loss: 1.3049 - val_accuracy: 0.3164\n",
      "Epoch 188/4000\n",
      "128/128 [==============================] - 11s 89ms/step - loss: 1.0921 - accuracy: 0.5002 - val_loss: 1.1052 - val_accuracy: 0.4102\n",
      "Epoch 189/4000\n",
      "128/128 [==============================] - 11s 84ms/step - loss: 1.0380 - accuracy: 0.5300 - val_loss: 1.0842 - val_accuracy: 0.4609\n",
      "Epoch 190/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 1.0845 - accuracy: 0.5122 - val_loss: 1.0949 - val_accuracy: 0.4375\n",
      "Epoch 191/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 1.0456 - accuracy: 0.5305 - val_loss: 1.1315 - val_accuracy: 0.5234\n",
      "Epoch 192/4000\n",
      "128/128 [==============================] - 11s 85ms/step - loss: 1.0508 - accuracy: 0.5295 - val_loss: 1.0949 - val_accuracy: 0.3984\n",
      "Epoch 193/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 1.0363 - accuracy: 0.5418 - val_loss: 1.0905 - val_accuracy: 0.3945\n",
      "Epoch 194/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 1.0069 - accuracy: 0.5638 - val_loss: 0.9871 - val_accuracy: 0.4648\n",
      "Epoch 195/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.9961 - accuracy: 0.5634 - val_loss: 1.1535 - val_accuracy: 0.4766\n",
      "Epoch 196/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 1.0035 - accuracy: 0.5672 - val_loss: 1.1311 - val_accuracy: 0.4219\n",
      "Epoch 197/4000\n",
      "128/128 [==============================] - 13s 98ms/step - loss: 1.1103 - accuracy: 0.5039 - val_loss: 1.1845 - val_accuracy: 0.3281\n",
      "Epoch 198/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 1.0840 - accuracy: 0.5319 - val_loss: 1.0821 - val_accuracy: 0.4531\n",
      "Epoch 199/4000\n",
      "128/128 [==============================] - 12s 96ms/step - loss: 1.0547 - accuracy: 0.5384 - val_loss: 1.0420 - val_accuracy: 0.5352\n",
      "Epoch 200/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.9932 - accuracy: 0.5663 - val_loss: 1.0530 - val_accuracy: 0.4648\n",
      "Epoch 201/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.9921 - accuracy: 0.5685 - val_loss: 1.0377 - val_accuracy: 0.5000\n",
      "Epoch 202/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.9688 - accuracy: 0.5809 - val_loss: 1.1444 - val_accuracy: 0.4609\n",
      "Epoch 203/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.9959 - accuracy: 0.5623 - val_loss: 1.0071 - val_accuracy: 0.5039\n",
      "Epoch 204/4000\n",
      "128/128 [==============================] - 13s 105ms/step - loss: 0.9620 - accuracy: 0.5687 - val_loss: 1.1730 - val_accuracy: 0.4219\n",
      "Epoch 205/4000\n",
      "128/128 [==============================] - 12s 96ms/step - loss: 0.9505 - accuracy: 0.5866 - val_loss: 1.0273 - val_accuracy: 0.4648\n",
      "Epoch 206/4000\n",
      "128/128 [==============================] - 13s 98ms/step - loss: 0.9475 - accuracy: 0.5941 - val_loss: 1.0847 - val_accuracy: 0.5078\n",
      "Epoch 207/4000\n",
      "128/128 [==============================] - 12s 93ms/step - loss: 0.9366 - accuracy: 0.5923 - val_loss: 1.0710 - val_accuracy: 0.4883\n",
      "Epoch 208/4000\n",
      "128/128 [==============================] - 13s 98ms/step - loss: 0.9104 - accuracy: 0.6133 - val_loss: 0.9991 - val_accuracy: 0.5352\n",
      "Epoch 209/4000\n",
      "128/128 [==============================] - 13s 97ms/step - loss: 0.9181 - accuracy: 0.6100 - val_loss: 1.0655 - val_accuracy: 0.5000\n",
      "Epoch 210/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.9090 - accuracy: 0.6158 - val_loss: 0.9678 - val_accuracy: 0.5234\n",
      "Epoch 211/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.9018 - accuracy: 0.6063 - val_loss: 0.9766 - val_accuracy: 0.5352\n",
      "Epoch 212/4000\n",
      "128/128 [==============================] - 11s 85ms/step - loss: 0.8746 - accuracy: 0.6381 - val_loss: 1.0059 - val_accuracy: 0.5312\n",
      "Epoch 213/4000\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 0.9098 - accuracy: 0.5995 - val_loss: 0.8941 - val_accuracy: 0.5938\n",
      "Epoch 214/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.8821 - accuracy: 0.6273 - val_loss: 1.0576 - val_accuracy: 0.5039\n",
      "Epoch 215/4000\n",
      "128/128 [==============================] - 12s 91ms/step - loss: 0.8990 - accuracy: 0.6128 - val_loss: 0.9191 - val_accuracy: 0.5977\n",
      "Epoch 216/4000\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 0.9003 - accuracy: 0.6161 - val_loss: 0.9224 - val_accuracy: 0.5469\n",
      "Epoch 217/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.8699 - accuracy: 0.6245 - val_loss: 1.0029 - val_accuracy: 0.5547\n",
      "Epoch 218/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.8362 - accuracy: 0.6547 - val_loss: 1.0369 - val_accuracy: 0.5312\n",
      "Epoch 219/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.8696 - accuracy: 0.6247 - val_loss: 0.8685 - val_accuracy: 0.5859\n",
      "Epoch 220/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.8604 - accuracy: 0.6375 - val_loss: 0.9326 - val_accuracy: 0.5664\n",
      "Epoch 221/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.8232 - accuracy: 0.6520 - val_loss: 0.9431 - val_accuracy: 0.5547\n",
      "Epoch 222/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.8177 - accuracy: 0.6545 - val_loss: 0.9201 - val_accuracy: 0.5742\n",
      "Epoch 223/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 9s 70ms/step - loss: 0.8156 - accuracy: 0.6482 - val_loss: 0.9136 - val_accuracy: 0.5625\n",
      "Epoch 224/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.8370 - accuracy: 0.6460 - val_loss: 0.9602 - val_accuracy: 0.5430\n",
      "Epoch 225/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.8010 - accuracy: 0.6784 - val_loss: 0.9671 - val_accuracy: 0.5547\n",
      "Epoch 226/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.8268 - accuracy: 0.6451 - val_loss: 0.9507 - val_accuracy: 0.5703\n",
      "Epoch 227/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.8118 - accuracy: 0.6592 - val_loss: 0.9105 - val_accuracy: 0.5898\n",
      "Epoch 228/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.8182 - accuracy: 0.6563 - val_loss: 0.9639 - val_accuracy: 0.5430\n",
      "Epoch 229/4000\n",
      "128/128 [==============================] - 11s 84ms/step - loss: 0.7966 - accuracy: 0.6658 - val_loss: 0.8752 - val_accuracy: 0.5859\n",
      "Epoch 230/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.7818 - accuracy: 0.6706 - val_loss: 1.0069 - val_accuracy: 0.5000\n",
      "Epoch 231/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.7862 - accuracy: 0.6627 - val_loss: 0.8379 - val_accuracy: 0.6445\n",
      "Epoch 232/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.7497 - accuracy: 0.6880 - val_loss: 0.9040 - val_accuracy: 0.5664\n",
      "Epoch 233/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.7806 - accuracy: 0.6569 - val_loss: 0.9397 - val_accuracy: 0.5742\n",
      "Epoch 234/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.8034 - accuracy: 0.6598 - val_loss: 1.2072 - val_accuracy: 0.4805\n",
      "Epoch 235/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.7777 - accuracy: 0.6751 - val_loss: 0.9769 - val_accuracy: 0.5664\n",
      "Epoch 236/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.7855 - accuracy: 0.6630 - val_loss: 0.9119 - val_accuracy: 0.5703\n",
      "Epoch 237/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.7731 - accuracy: 0.6656 - val_loss: 0.9338 - val_accuracy: 0.5586\n",
      "Epoch 238/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.7705 - accuracy: 0.6773 - val_loss: 0.7801 - val_accuracy: 0.6445\n",
      "Epoch 239/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.7645 - accuracy: 0.6774 - val_loss: 0.9693 - val_accuracy: 0.5469\n",
      "Epoch 240/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.7279 - accuracy: 0.6976 - val_loss: 0.8498 - val_accuracy: 0.6211\n",
      "Epoch 241/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.7625 - accuracy: 0.6787 - val_loss: 0.9400 - val_accuracy: 0.5508\n",
      "Epoch 242/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.7548 - accuracy: 0.7003 - val_loss: 0.8454 - val_accuracy: 0.5703\n",
      "Epoch 243/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.7251 - accuracy: 0.6964 - val_loss: 0.8450 - val_accuracy: 0.6211\n",
      "Epoch 244/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.7373 - accuracy: 0.6901 - val_loss: 0.9780 - val_accuracy: 0.5352\n",
      "Epoch 245/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.7178 - accuracy: 0.7010 - val_loss: 0.8961 - val_accuracy: 0.5938\n",
      "Epoch 246/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.7332 - accuracy: 0.6972 - val_loss: 0.8756 - val_accuracy: 0.5938\n",
      "Epoch 247/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.7226 - accuracy: 0.7011 - val_loss: 0.8719 - val_accuracy: 0.6055\n",
      "Epoch 248/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6950 - accuracy: 0.7139 - val_loss: 0.8876 - val_accuracy: 0.6016\n",
      "Epoch 249/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.7122 - accuracy: 0.7147 - val_loss: 0.8753 - val_accuracy: 0.6094\n",
      "Epoch 250/4000\n",
      "128/128 [==============================] - 11s 84ms/step - loss: 0.7044 - accuracy: 0.7003 - val_loss: 0.8886 - val_accuracy: 0.6055\n",
      "Epoch 251/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.6986 - accuracy: 0.7059 - val_loss: 0.9295 - val_accuracy: 0.5859\n",
      "Epoch 252/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.7013 - accuracy: 0.7060 - val_loss: 0.8633 - val_accuracy: 0.6094\n",
      "Epoch 253/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6985 - accuracy: 0.7120 - val_loss: 0.8217 - val_accuracy: 0.6250\n",
      "Epoch 254/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.6940 - accuracy: 0.7049 - val_loss: 0.8035 - val_accuracy: 0.6484\n",
      "Epoch 255/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.6745 - accuracy: 0.7151 - val_loss: 0.8975 - val_accuracy: 0.5703\n",
      "Epoch 256/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.6683 - accuracy: 0.7296 - val_loss: 0.8260 - val_accuracy: 0.6211\n",
      "Epoch 257/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 0.7007 - accuracy: 0.7004 - val_loss: 0.7961 - val_accuracy: 0.6055- loss: 0.7010 - accuracy: 0.\n",
      "Epoch 258/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.6540 - accuracy: 0.7365 - val_loss: 0.9268 - val_accuracy: 0.6055\n",
      "Epoch 259/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.6876 - accuracy: 0.7118 - val_loss: 0.8411 - val_accuracy: 0.6406\n",
      "Epoch 260/4000\n",
      "128/128 [==============================] - 11s 85ms/step - loss: 0.6536 - accuracy: 0.7355 - val_loss: 0.9136 - val_accuracy: 0.5820\n",
      "Epoch 261/4000\n",
      "128/128 [==============================] - 11s 89ms/step - loss: 0.6434 - accuracy: 0.7412 - val_loss: 0.9037 - val_accuracy: 0.5938\n",
      "Epoch 262/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.6534 - accuracy: 0.7286 - val_loss: 0.8423 - val_accuracy: 0.6055\n",
      "Epoch 263/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6599 - accuracy: 0.7317 - val_loss: 0.8667 - val_accuracy: 0.6016\n",
      "Epoch 264/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6829 - accuracy: 0.7215 - val_loss: 0.8260 - val_accuracy: 0.6562\n",
      "Epoch 265/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6604 - accuracy: 0.7303 - val_loss: 0.8247 - val_accuracy: 0.6484\n",
      "Epoch 266/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6407 - accuracy: 0.7285 - val_loss: 0.8644 - val_accuracy: 0.6016\n",
      "Epoch 267/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.6086 - accuracy: 0.7511 - val_loss: 0.8902 - val_accuracy: 0.5820\n",
      "Epoch 268/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.6473 - accuracy: 0.7258 - val_loss: 0.8601 - val_accuracy: 0.5781\n",
      "Epoch 269/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6159 - accuracy: 0.7450 - val_loss: 0.8109 - val_accuracy: 0.6445\n",
      "Epoch 270/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.6422 - accuracy: 0.7441 - val_loss: 0.8105 - val_accuracy: 0.6367\n",
      "Epoch 271/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6157 - accuracy: 0.7588 - val_loss: 0.9498 - val_accuracy: 0.5859\n",
      "Epoch 272/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6087 - accuracy: 0.7548 - val_loss: 0.8375 - val_accuracy: 0.6250\n",
      "Epoch 273/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6285 - accuracy: 0.7453 - val_loss: 0.8378 - val_accuracy: 0.6016\n",
      "Epoch 274/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.6363 - accuracy: 0.7278 - val_loss: 0.8454 - val_accuracy: 0.5938\n",
      "Epoch 275/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.5948 - accuracy: 0.7551 - val_loss: 1.0135 - val_accuracy: 0.5820\n",
      "Epoch 276/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.6068 - accuracy: 0.7563 - val_loss: 0.9019 - val_accuracy: 0.6211\n",
      "Epoch 277/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.6077 - accuracy: 0.7452 - val_loss: 0.9456 - val_accuracy: 0.6055\n",
      "Epoch 278/4000\n",
      "128/128 [==============================] - 11s 84ms/step - loss: 0.6109 - accuracy: 0.7516 - val_loss: 0.7453 - val_accuracy: 0.6719\n",
      "Epoch 279/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.5665 - accuracy: 0.7655 - val_loss: 0.8678 - val_accuracy: 0.6367\n",
      "Epoch 280/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.5845 - accuracy: 0.7699 - val_loss: 0.8399 - val_accuracy: 0.6055\n",
      "Epoch 281/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.5994 - accuracy: 0.7546 - val_loss: 0.8633 - val_accuracy: 0.6484\n",
      "Epoch 282/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5607 - accuracy: 0.7705 - val_loss: 0.8691 - val_accuracy: 0.6133\n",
      "Epoch 283/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5802 - accuracy: 0.7654 - val_loss: 0.9003 - val_accuracy: 0.6406\n",
      "Epoch 284/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.5843 - accuracy: 0.7648 - val_loss: 0.8761 - val_accuracy: 0.6367\n",
      "Epoch 285/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.6000 - accuracy: 0.7628 - val_loss: 0.9038 - val_accuracy: 0.5977\n",
      "Epoch 286/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5831 - accuracy: 0.7599 - val_loss: 0.8672 - val_accuracy: 0.6289\n",
      "Epoch 287/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.5848 - accuracy: 0.7717 - val_loss: 0.7859 - val_accuracy: 0.6641\n",
      "Epoch 288/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.5537 - accuracy: 0.7784 - val_loss: 0.8634 - val_accuracy: 0.6250\n",
      "Epoch 289/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5351 - accuracy: 0.7742 - val_loss: 0.7936 - val_accuracy: 0.6719\n",
      "Epoch 290/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.5611 - accuracy: 0.7770 - val_loss: 0.8920 - val_accuracy: 0.5977\n",
      "Epoch 291/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5531 - accuracy: 0.7729 - val_loss: 0.7883 - val_accuracy: 0.6562\n",
      "Epoch 292/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.5284 - accuracy: 0.7821 - val_loss: 0.9035 - val_accuracy: 0.6094\n",
      "Epoch 293/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5320 - accuracy: 0.7875 - val_loss: 0.9423 - val_accuracy: 0.6055\n",
      "Epoch 294/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5487 - accuracy: 0.7842 - val_loss: 0.8865 - val_accuracy: 0.6250\n",
      "Epoch 295/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5061 - accuracy: 0.7938 - val_loss: 0.9267 - val_accuracy: 0.5938\n",
      "Epoch 296/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.5400 - accuracy: 0.7869 - val_loss: 0.8852 - val_accuracy: 0.6523\n",
      "Epoch 297/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5347 - accuracy: 0.7994 - val_loss: 0.9405 - val_accuracy: 0.5781\n",
      "Epoch 298/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.5127 - accuracy: 0.7877 - val_loss: 0.8376 - val_accuracy: 0.6641\n",
      "Epoch 299/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.5281 - accuracy: 0.7844 - val_loss: 0.8261 - val_accuracy: 0.6719\n",
      "Epoch 300/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.5042 - accuracy: 0.8000 - val_loss: 0.8930 - val_accuracy: 0.6484\n",
      "Epoch 301/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.5207 - accuracy: 0.7932 - val_loss: 0.9221 - val_accuracy: 0.6172\n",
      "Epoch 302/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.5192 - accuracy: 0.8001 - val_loss: 0.9345 - val_accuracy: 0.6211\n",
      "Epoch 303/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.5115 - accuracy: 0.8099 - val_loss: 0.8688 - val_accuracy: 0.6562\n",
      "Epoch 304/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.4885 - accuracy: 0.8040 - val_loss: 0.9889 - val_accuracy: 0.6133\n",
      "Epoch 305/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.4825 - accuracy: 0.8086 - val_loss: 1.0719 - val_accuracy: 0.5859\n",
      "Epoch 306/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5212 - accuracy: 0.7928 - val_loss: 0.8735 - val_accuracy: 0.6406\n",
      "Epoch 307/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.4956 - accuracy: 0.8026 - val_loss: 0.8792 - val_accuracy: 0.6328\n",
      "Epoch 308/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.4984 - accuracy: 0.8047 - val_loss: 0.9068 - val_accuracy: 0.6602\n",
      "Epoch 309/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.4701 - accuracy: 0.8137 - val_loss: 0.9459 - val_accuracy: 0.6406\n",
      "Epoch 310/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.5101 - accuracy: 0.7954 - val_loss: 0.8681 - val_accuracy: 0.6641\n",
      "Epoch 311/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.4828 - accuracy: 0.8164 - val_loss: 0.8990 - val_accuracy: 0.6367\n",
      "Epoch 312/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.4546 - accuracy: 0.8111 - val_loss: 0.9435 - val_accuracy: 0.6758\n",
      "Epoch 313/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.4821 - accuracy: 0.8151 - val_loss: 0.9340 - val_accuracy: 0.6719\n",
      "Epoch 314/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.4582 - accuracy: 0.8189 - val_loss: 0.8720 - val_accuracy: 0.6992\n",
      "Epoch 315/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.4759 - accuracy: 0.8011 - val_loss: 0.9581 - val_accuracy: 0.6484\n",
      "Epoch 316/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.5275 - accuracy: 0.7929 - val_loss: 1.1048 - val_accuracy: 0.5781\n",
      "Epoch 317/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.4467 - accuracy: 0.8230 - val_loss: 1.0077 - val_accuracy: 0.6172\n",
      "Epoch 318/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.4705 - accuracy: 0.8112 - val_loss: 0.9716 - val_accuracy: 0.6484\n",
      "Epoch 319/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.4882 - accuracy: 0.8130 - val_loss: 0.9612 - val_accuracy: 0.6055\n",
      "Epoch 320/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.4644 - accuracy: 0.8119 - val_loss: 0.9892 - val_accuracy: 0.6406\n",
      "Epoch 321/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.4659 - accuracy: 0.8224 - val_loss: 1.0012 - val_accuracy: 0.5898\n",
      "Epoch 322/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.4320 - accuracy: 0.8194 - val_loss: 1.0254 - val_accuracy: 0.6328\n",
      "Epoch 323/4000\n",
      "128/128 [==============================] - 11s 84ms/step - loss: 0.4452 - accuracy: 0.8353 - val_loss: 0.9717 - val_accuracy: 0.5977\n",
      "Epoch 324/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.4637 - accuracy: 0.8155 - val_loss: 0.9341 - val_accuracy: 0.6562\n",
      "Epoch 325/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.4665 - accuracy: 0.8104 - val_loss: 0.9952 - val_accuracy: 0.6250\n",
      "Epoch 326/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.4300 - accuracy: 0.8335 - val_loss: 0.9852 - val_accuracy: 0.6211\n",
      "Epoch 327/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.4357 - accuracy: 0.8337 - val_loss: 0.9658 - val_accuracy: 0.6758\n",
      "Epoch 328/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.4452 - accuracy: 0.8309 - val_loss: 1.0527 - val_accuracy: 0.6094\n",
      "Epoch 329/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.4327 - accuracy: 0.8404 - val_loss: 1.1316 - val_accuracy: 0.6133\n",
      "Epoch 330/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.4309 - accuracy: 0.8316 - val_loss: 1.0037 - val_accuracy: 0.6719\n",
      "Epoch 331/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.4255 - accuracy: 0.8309 - val_loss: 1.0843 - val_accuracy: 0.6289\n",
      "Epoch 332/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.4283 - accuracy: 0.8366 - val_loss: 1.0029 - val_accuracy: 0.6523\n",
      "Epoch 333/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 10s 74ms/step - loss: 0.4197 - accuracy: 0.8267 - val_loss: 1.0588 - val_accuracy: 0.6328\n",
      "Epoch 334/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.4112 - accuracy: 0.8390 - val_loss: 0.9354 - val_accuracy: 0.6758\n",
      "Epoch 335/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.4278 - accuracy: 0.8330 - val_loss: 1.0361 - val_accuracy: 0.6562\n",
      "Epoch 336/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.4302 - accuracy: 0.8241 - val_loss: 1.0165 - val_accuracy: 0.6602\n",
      "Epoch 337/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.4172 - accuracy: 0.8303 - val_loss: 1.0373 - val_accuracy: 0.6250\n",
      "Epoch 338/4000\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 0.4213 - accuracy: 0.8416 - val_loss: 0.9657 - val_accuracy: 0.6562\n",
      "Epoch 339/4000\n",
      "128/128 [==============================] - 12s 92ms/step - loss: 0.4058 - accuracy: 0.8488 - val_loss: 1.0182 - val_accuracy: 0.6875\n",
      "Epoch 340/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.3868 - accuracy: 0.8490 - val_loss: 1.0005 - val_accuracy: 0.6523\n",
      "Epoch 341/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.4028 - accuracy: 0.8440 - val_loss: 1.0070 - val_accuracy: 0.6680\n",
      "Epoch 342/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.4074 - accuracy: 0.8365 - val_loss: 0.9932 - val_accuracy: 0.6406\n",
      "Epoch 343/4000\n",
      "128/128 [==============================] - 11s 89ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 1.0434 - val_accuracy: 0.6758\n",
      "Epoch 344/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.3968 - accuracy: 0.8491 - val_loss: 1.0494 - val_accuracy: 0.6484\n",
      "Epoch 345/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.4053 - accuracy: 0.8462 - val_loss: 1.0432 - val_accuracy: 0.6523\n",
      "Epoch 346/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.4444 - accuracy: 0.8368 - val_loss: 0.9860 - val_accuracy: 0.6484\n",
      "Epoch 347/4000\n",
      "128/128 [==============================] - 11s 89ms/step - loss: 0.3730 - accuracy: 0.8564 - val_loss: 1.1327 - val_accuracy: 0.6406\n",
      "Epoch 348/4000\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 0.3800 - accuracy: 0.8500 - val_loss: 1.1068 - val_accuracy: 0.6211\n",
      "Epoch 349/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.3605 - accuracy: 0.8641 - val_loss: 1.0015 - val_accuracy: 0.6211\n",
      "Epoch 350/4000\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 0.3864 - accuracy: 0.8508 - val_loss: 1.0959 - val_accuracy: 0.6328\n",
      "Epoch 351/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3621 - accuracy: 0.8506 - val_loss: 1.0394 - val_accuracy: 0.6562\n",
      "Epoch 352/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.3487 - accuracy: 0.8651 - val_loss: 1.0321 - val_accuracy: 0.6367\n",
      "Epoch 353/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.3786 - accuracy: 0.8414 - val_loss: 1.0592 - val_accuracy: 0.6523\n",
      "Epoch 354/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.3782 - accuracy: 0.8451 - val_loss: 1.1294 - val_accuracy: 0.6484\n",
      "Epoch 355/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.3445 - accuracy: 0.8685 - val_loss: 1.0464 - val_accuracy: 0.6445\n",
      "Epoch 356/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.3689 - accuracy: 0.8547 - val_loss: 1.0413 - val_accuracy: 0.6758\n",
      "Epoch 357/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.3481 - accuracy: 0.8743 - val_loss: 1.0320 - val_accuracy: 0.6406\n",
      "Epoch 358/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.3284 - accuracy: 0.8762 - val_loss: 1.1243 - val_accuracy: 0.6523\n",
      "Epoch 359/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.3574 - accuracy: 0.8652 - val_loss: 1.1572 - val_accuracy: 0.6562\n",
      "Epoch 360/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.3762 - accuracy: 0.8487 - val_loss: 1.1447 - val_accuracy: 0.6484\n",
      "Epoch 361/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.3326 - accuracy: 0.8695 - val_loss: 1.0888 - val_accuracy: 0.6875\n",
      "Epoch 362/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3460 - accuracy: 0.8682 - val_loss: 1.1222 - val_accuracy: 0.6602\n",
      "Epoch 363/4000\n",
      "128/128 [==============================] - 11s 85ms/step - loss: 0.3486 - accuracy: 0.8638 - val_loss: 1.1606 - val_accuracy: 0.6094\n",
      "Epoch 364/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.3540 - accuracy: 0.8684 - val_loss: 1.0089 - val_accuracy: 0.6250\n",
      "Epoch 365/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.3685 - accuracy: 0.8567 - val_loss: 1.1556 - val_accuracy: 0.6367\n",
      "Epoch 366/4000\n",
      "128/128 [==============================] - 12s 89ms/step - loss: 0.3500 - accuracy: 0.8777 - val_loss: 1.2080 - val_accuracy: 0.6406\n",
      "Epoch 367/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3529 - accuracy: 0.8628 - val_loss: 1.1210 - val_accuracy: 0.6562\n",
      "Epoch 368/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3525 - accuracy: 0.8647 - val_loss: 1.0524 - val_accuracy: 0.6484\n",
      "Epoch 369/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.3265 - accuracy: 0.8798 - val_loss: 1.2761 - val_accuracy: 0.6641\n",
      "Epoch 370/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3332 - accuracy: 0.8698 - val_loss: 1.2478 - val_accuracy: 0.6367\n",
      "Epoch 371/4000\n",
      "128/128 [==============================] - 13s 102ms/step - loss: 0.3392 - accuracy: 0.8751 - val_loss: 1.0635 - val_accuracy: 0.6875\n",
      "Epoch 372/4000\n",
      "128/128 [==============================] - 14s 111ms/step - loss: 0.3331 - accuracy: 0.8723 - val_loss: 1.0900 - val_accuracy: 0.6328\n",
      "Epoch 373/4000\n",
      "128/128 [==============================] - 15s 117ms/step - loss: 0.3269 - accuracy: 0.8787 - val_loss: 1.1261 - val_accuracy: 0.6211\n",
      "Epoch 374/4000\n",
      "128/128 [==============================] - 11s 89ms/step - loss: 0.3250 - accuracy: 0.8799 - val_loss: 1.0623 - val_accuracy: 0.6289\n",
      "Epoch 375/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.3156 - accuracy: 0.8764 - val_loss: 0.9798 - val_accuracy: 0.6875\n",
      "Epoch 376/4000\n",
      "128/128 [==============================] - 12s 90ms/step - loss: 0.2919 - accuracy: 0.8884 - val_loss: 1.0630 - val_accuracy: 0.6680oss: 0.2912 - accuracy: \n",
      "Epoch 377/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.3028 - accuracy: 0.8814 - val_loss: 1.1191 - val_accuracy: 0.6602\n",
      "Epoch 378/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.3149 - accuracy: 0.8828 - val_loss: 1.0427 - val_accuracy: 0.6875\n",
      "Epoch 379/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3421 - accuracy: 0.8682 - val_loss: 1.2030 - val_accuracy: 0.6289\n",
      "Epoch 380/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.3047 - accuracy: 0.8881 - val_loss: 1.2005 - val_accuracy: 0.6641\n",
      "Epoch 381/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.2860 - accuracy: 0.8918 - val_loss: 1.2772 - val_accuracy: 0.6328\n",
      "Epoch 382/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.3186 - accuracy: 0.8844 - val_loss: 1.1419 - val_accuracy: 0.6328\n",
      "Epoch 383/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3134 - accuracy: 0.8733 - val_loss: 1.1850 - val_accuracy: 0.6523\n",
      "Epoch 384/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3106 - accuracy: 0.8755 - val_loss: 1.1294 - val_accuracy: 0.6523\n",
      "Epoch 385/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.3182 - accuracy: 0.8824 - val_loss: 1.2074 - val_accuracy: 0.6406\n",
      "Epoch 386/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.2786 - accuracy: 0.8907 - val_loss: 1.2346 - val_accuracy: 0.6680\n",
      "Epoch 387/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.2983 - accuracy: 0.8888 - val_loss: 1.2765 - val_accuracy: 0.6328\n",
      "Epoch 388/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.3115 - accuracy: 0.8886 - val_loss: 1.1388 - val_accuracy: 0.6094\n",
      "Epoch 389/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.2979 - accuracy: 0.8854 - val_loss: 1.1521 - val_accuracy: 0.6680\n",
      "Epoch 390/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.2887 - accuracy: 0.8905 - val_loss: 1.0559 - val_accuracy: 0.6641\n",
      "Epoch 391/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.2564 - accuracy: 0.9009 - val_loss: 1.2371 - val_accuracy: 0.6719\n",
      "Epoch 392/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.2887 - accuracy: 0.8915 - val_loss: 1.1342 - val_accuracy: 0.6680\n",
      "Epoch 393/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.3013 - accuracy: 0.8837 - val_loss: 1.1098 - val_accuracy: 0.6719\n",
      "Epoch 394/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.2933 - accuracy: 0.8899 - val_loss: 1.1902 - val_accuracy: 0.6523\n",
      "Epoch 395/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.2836 - accuracy: 0.8904 - val_loss: 1.0532 - val_accuracy: 0.6758\n",
      "Epoch 396/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.2778 - accuracy: 0.8988 - val_loss: 1.2387 - val_accuracy: 0.6211\n",
      "Epoch 397/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.2896 - accuracy: 0.8899 - val_loss: 1.2073 - val_accuracy: 0.6133\n",
      "Epoch 398/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2985 - accuracy: 0.8869 - val_loss: 1.0533 - val_accuracy: 0.6836\n",
      "Epoch 399/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.2868 - accuracy: 0.8955 - val_loss: 1.0953 - val_accuracy: 0.6641\n",
      "Epoch 400/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.2567 - accuracy: 0.9012 - val_loss: 1.0970 - val_accuracy: 0.6484\n",
      "Epoch 401/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.2907 - accuracy: 0.8969 - val_loss: 1.1561 - val_accuracy: 0.6602\n",
      "Epoch 402/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.2844 - accuracy: 0.8900 - val_loss: 1.1743 - val_accuracy: 0.6367\n",
      "Epoch 403/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.2730 - accuracy: 0.9002 - val_loss: 1.1722 - val_accuracy: 0.6406\n",
      "Epoch 404/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.2728 - accuracy: 0.8976 - val_loss: 1.2576 - val_accuracy: 0.6367\n",
      "Epoch 405/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.3113 - accuracy: 0.8831 - val_loss: 1.2609 - val_accuracy: 0.6484\n",
      "Epoch 406/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.2816 - accuracy: 0.8954 - val_loss: 1.2062 - val_accuracy: 0.6680\n",
      "Epoch 407/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2610 - accuracy: 0.8961 - val_loss: 1.1017 - val_accuracy: 0.6719\n",
      "Epoch 408/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2412 - accuracy: 0.9099 - val_loss: 1.2531 - val_accuracy: 0.6562\n",
      "Epoch 409/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.2654 - accuracy: 0.8980 - val_loss: 1.2656 - val_accuracy: 0.6250\n",
      "Epoch 410/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.2598 - accuracy: 0.9048 - val_loss: 1.1444 - val_accuracy: 0.6758\n",
      "Epoch 411/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.2592 - accuracy: 0.9060 - val_loss: 1.2192 - val_accuracy: 0.6445\n",
      "Epoch 412/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.2616 - accuracy: 0.8982 - val_loss: 1.0949 - val_accuracy: 0.6602\n",
      "Epoch 413/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.2632 - accuracy: 0.9019 - val_loss: 1.1902 - val_accuracy: 0.6367\n",
      "Epoch 414/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.2576 - accuracy: 0.9079 - val_loss: 1.2352 - val_accuracy: 0.6836\n",
      "Epoch 415/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.2447 - accuracy: 0.9111 - val_loss: 1.1931 - val_accuracy: 0.6328\n",
      "Epoch 416/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2701 - accuracy: 0.9025 - val_loss: 1.3251 - val_accuracy: 0.6289\n",
      "Epoch 417/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.2352 - accuracy: 0.9145 - val_loss: 1.3032 - val_accuracy: 0.6641\n",
      "Epoch 418/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.2581 - accuracy: 0.9049 - val_loss: 1.2765 - val_accuracy: 0.6445\n",
      "Epoch 419/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.2421 - accuracy: 0.9144 - val_loss: 1.2094 - val_accuracy: 0.6523\n",
      "Epoch 420/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.2535 - accuracy: 0.9024 - val_loss: 1.3247 - val_accuracy: 0.6055\n",
      "Epoch 421/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.2370 - accuracy: 0.9101 - val_loss: 1.2792 - val_accuracy: 0.6562\n",
      "Epoch 422/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2439 - accuracy: 0.9125 - val_loss: 1.3621 - val_accuracy: 0.6484\n",
      "Epoch 423/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2278 - accuracy: 0.9154 - val_loss: 1.1358 - val_accuracy: 0.6680\n",
      "Epoch 424/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 0.2427 - accuracy: 0.9087 - val_loss: 1.1751 - val_accuracy: 0.6758\n",
      "Epoch 425/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 0.2093 - accuracy: 0.9253 - val_loss: 1.1316 - val_accuracy: 0.6758\n",
      "Epoch 426/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.2681 - accuracy: 0.9010 - val_loss: 1.2613 - val_accuracy: 0.6797\n",
      "Epoch 427/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2460 - accuracy: 0.9108 - val_loss: 1.2790 - val_accuracy: 0.6680\n",
      "Epoch 428/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2158 - accuracy: 0.9218 - val_loss: 1.2099 - val_accuracy: 0.6797\n",
      "Epoch 429/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 0.2417 - accuracy: 0.9085 - val_loss: 1.2805 - val_accuracy: 0.6953\n",
      "Epoch 430/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.2207 - accuracy: 0.9229 - val_loss: 1.3140 - val_accuracy: 0.6758\n",
      "Epoch 431/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2361 - accuracy: 0.9174 - val_loss: 1.3272 - val_accuracy: 0.6562\n",
      "Epoch 432/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2294 - accuracy: 0.9165 - val_loss: 1.1667 - val_accuracy: 0.6172\n",
      "Epoch 433/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.2446 - accuracy: 0.9137 - val_loss: 1.2541 - val_accuracy: 0.6602\n",
      "Epoch 434/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2194 - accuracy: 0.9196 - val_loss: 1.1044 - val_accuracy: 0.6875\n",
      "Epoch 435/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.2302 - accuracy: 0.9136 - val_loss: 1.2545 - val_accuracy: 0.6836\n",
      "Epoch 436/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.1908 - accuracy: 0.9321 - val_loss: 1.4808 - val_accuracy: 0.6602\n",
      "Epoch 437/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.2392 - accuracy: 0.9110 - val_loss: 1.6196 - val_accuracy: 0.6211\n",
      "Epoch 438/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.2364 - accuracy: 0.9138 - val_loss: 1.3566 - val_accuracy: 0.6797\n",
      "Epoch 439/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2182 - accuracy: 0.9226 - val_loss: 1.2516 - val_accuracy: 0.6328\n",
      "Epoch 440/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2539 - accuracy: 0.9099 - val_loss: 1.2346 - val_accuracy: 0.6758\n",
      "Epoch 441/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.2039 - accuracy: 0.9237 - val_loss: 1.3313 - val_accuracy: 0.6562\n",
      "Epoch 442/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.2127 - accuracy: 0.9244 - val_loss: 1.2780 - val_accuracy: 0.6602\n",
      "Epoch 443/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 11s 83ms/step - loss: 0.2073 - accuracy: 0.9231 - val_loss: 1.1725 - val_accuracy: 0.6953\n",
      "Epoch 444/4000\n",
      "128/128 [==============================] - 12s 91ms/step - loss: 0.2955 - accuracy: 0.9028 - val_loss: 1.1842 - val_accuracy: 0.6641\n",
      "Epoch 445/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.2338 - accuracy: 0.9129 - val_loss: 1.2024 - val_accuracy: 0.6328\n",
      "Epoch 446/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.1906 - accuracy: 0.9290 - val_loss: 1.1614 - val_accuracy: 0.6484\n",
      "Epoch 447/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1816 - accuracy: 0.9324 - val_loss: 1.1792 - val_accuracy: 0.6836\n",
      "Epoch 448/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1866 - accuracy: 0.9347 - val_loss: 1.1744 - val_accuracy: 0.6836\n",
      "Epoch 449/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1855 - accuracy: 0.9310 - val_loss: 1.2900 - val_accuracy: 0.6445\n",
      "Epoch 450/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1959 - accuracy: 0.9237 - val_loss: 1.3888 - val_accuracy: 0.6250\n",
      "Epoch 451/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.2041 - accuracy: 0.9237 - val_loss: 1.2266 - val_accuracy: 0.6602\n",
      "Epoch 452/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1936 - accuracy: 0.9270 - val_loss: 1.4562 - val_accuracy: 0.6328\n",
      "Epoch 453/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1862 - accuracy: 0.9367 - val_loss: 1.4986 - val_accuracy: 0.6328\n",
      "Epoch 454/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1933 - accuracy: 0.9303 - val_loss: 1.3340 - val_accuracy: 0.6602\n",
      "Epoch 455/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1866 - accuracy: 0.9217 - val_loss: 1.4598 - val_accuracy: 0.6484\n",
      "Epoch 456/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.2034 - accuracy: 0.9290 - val_loss: 1.3328 - val_accuracy: 0.6562\n",
      "Epoch 457/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1988 - accuracy: 0.9196 - val_loss: 1.2523 - val_accuracy: 0.6328\n",
      "Epoch 458/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 0.1875 - accuracy: 0.9375 - val_loss: 1.3455 - val_accuracy: 0.6445\n",
      "Epoch 459/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.2070 - accuracy: 0.9354 - val_loss: 1.2785 - val_accuracy: 0.6406\n",
      "Epoch 460/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1906 - accuracy: 0.9337 - val_loss: 1.2968 - val_accuracy: 0.6289\n",
      "Epoch 461/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1796 - accuracy: 0.9363 - val_loss: 1.1925 - val_accuracy: 0.6641\n",
      "Epoch 462/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1875 - accuracy: 0.9316 - val_loss: 1.3640 - val_accuracy: 0.6367\n",
      "Epoch 463/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.2386 - accuracy: 0.9136 - val_loss: 1.2580 - val_accuracy: 0.6641\n",
      "Epoch 464/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.2003 - accuracy: 0.9230 - val_loss: 1.4778 - val_accuracy: 0.6719\n",
      "Epoch 465/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1786 - accuracy: 0.9366 - val_loss: 1.2663 - val_accuracy: 0.6797\n",
      "Epoch 466/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1882 - accuracy: 0.9325 - val_loss: 1.3469 - val_accuracy: 0.6914\n",
      "Epoch 467/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1992 - accuracy: 0.9253 - val_loss: 1.2773 - val_accuracy: 0.6445\n",
      "Epoch 468/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1934 - accuracy: 0.9315 - val_loss: 1.2590 - val_accuracy: 0.6719\n",
      "Epoch 469/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1882 - accuracy: 0.9246 - val_loss: 1.3425 - val_accuracy: 0.6602\n",
      "Epoch 470/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1889 - accuracy: 0.9282 - val_loss: 1.4267 - val_accuracy: 0.6680\n",
      "Epoch 471/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1703 - accuracy: 0.9356 - val_loss: 1.3141 - val_accuracy: 0.6602\n",
      "Epoch 472/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1719 - accuracy: 0.9386 - val_loss: 1.5227 - val_accuracy: 0.6445\n",
      "Epoch 473/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1877 - accuracy: 0.9321 - val_loss: 1.5284 - val_accuracy: 0.6875\n",
      "Epoch 474/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1731 - accuracy: 0.9383 - val_loss: 1.4468 - val_accuracy: 0.6641\n",
      "Epoch 475/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1702 - accuracy: 0.9367 - val_loss: 1.4609 - val_accuracy: 0.6445\n",
      "Epoch 476/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.2001 - accuracy: 0.9304 - val_loss: 1.3169 - val_accuracy: 0.6562\n",
      "Epoch 477/4000\n",
      "128/128 [==============================] - 9s 71ms/step - loss: 0.1657 - accuracy: 0.9329 - val_loss: 1.3673 - val_accuracy: 0.6133\n",
      "Epoch 478/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1606 - accuracy: 0.9425 - val_loss: 1.4616 - val_accuracy: 0.6289\n",
      "Epoch 479/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1866 - accuracy: 0.9346 - val_loss: 1.4205 - val_accuracy: 0.6250\n",
      "Epoch 480/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1600 - accuracy: 0.9338 - val_loss: 1.3686 - val_accuracy: 0.6641\n",
      "Epoch 481/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1754 - accuracy: 0.9344 - val_loss: 1.2559 - val_accuracy: 0.6172\n",
      "Epoch 482/4000\n",
      "128/128 [==============================] - 9s 70ms/step - loss: 0.1712 - accuracy: 0.9376 - val_loss: 1.3737 - val_accuracy: 0.6289\n",
      "Epoch 483/4000\n",
      "128/128 [==============================] - 9s 68ms/step - loss: 0.1937 - accuracy: 0.9284 - val_loss: 1.2775 - val_accuracy: 0.6523\n",
      "Epoch 484/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1569 - accuracy: 0.9361 - val_loss: 1.5490 - val_accuracy: 0.6289\n",
      "Epoch 485/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 1.2328 - val_accuracy: 0.6641\n",
      "Epoch 486/4000\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.1570 - accuracy: 0.9500 - val_loss: 1.2112 - val_accuracy: 0.6484\n",
      "Epoch 487/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.1762 - accuracy: 0.9392 - val_loss: 1.5075 - val_accuracy: 0.6562\n",
      "Epoch 488/4000\n",
      "128/128 [==============================] - 11s 85ms/step - loss: 0.1668 - accuracy: 0.9393 - val_loss: 1.6327 - val_accuracy: 0.6719\n",
      "Epoch 489/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.1689 - accuracy: 0.9356 - val_loss: 1.4079 - val_accuracy: 0.6680\n",
      "Epoch 490/4000\n",
      "128/128 [==============================] - 12s 91ms/step - loss: 0.1670 - accuracy: 0.9358 - val_loss: 1.5726 - val_accuracy: 0.6211\n",
      "Epoch 491/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.1738 - accuracy: 0.9402 - val_loss: 1.4364 - val_accuracy: 0.6445\n",
      "Epoch 492/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1491 - accuracy: 0.9447 - val_loss: 1.4962 - val_accuracy: 0.6484\n",
      "Epoch 493/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1729 - accuracy: 0.9330 - val_loss: 1.2934 - val_accuracy: 0.6523\n",
      "Epoch 494/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1911 - accuracy: 0.9375 - val_loss: 1.3908 - val_accuracy: 0.6406\n",
      "Epoch 495/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1439 - accuracy: 0.9458 - val_loss: 1.5608 - val_accuracy: 0.6172\n",
      "Epoch 496/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1760 - accuracy: 0.9424 - val_loss: 1.3989 - val_accuracy: 0.6328\n",
      "Epoch 497/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1530 - accuracy: 0.9438 - val_loss: 1.3371 - val_accuracy: 0.6797\n",
      "Epoch 498/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1593 - accuracy: 0.9417 - val_loss: 1.3226 - val_accuracy: 0.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1579 - accuracy: 0.9418 - val_loss: 1.3938 - val_accuracy: 0.6328\n",
      "Epoch 500/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1501 - accuracy: 0.9417 - val_loss: 1.5759 - val_accuracy: 0.6094\n",
      "Epoch 501/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1428 - accuracy: 0.9482 - val_loss: 1.5866 - val_accuracy: 0.6133\n",
      "Epoch 502/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1573 - accuracy: 0.9475 - val_loss: 1.4802 - val_accuracy: 0.6328\n",
      "Epoch 503/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1605 - accuracy: 0.9372 - val_loss: 1.4174 - val_accuracy: 0.6367\n",
      "Epoch 504/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1443 - accuracy: 0.9458 - val_loss: 1.5298 - val_accuracy: 0.6367\n",
      "Epoch 505/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1523 - accuracy: 0.9430 - val_loss: 1.4546 - val_accuracy: 0.6211\n",
      "Epoch 506/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1528 - accuracy: 0.9446 - val_loss: 1.5699 - val_accuracy: 0.6328\n",
      "Epoch 507/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.2059 - accuracy: 0.9307 - val_loss: 1.4001 - val_accuracy: 0.6641\n",
      "Epoch 508/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.2032 - accuracy: 0.9166 - val_loss: 1.3596 - val_accuracy: 0.6641\n",
      "Epoch 509/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.1582 - accuracy: 0.9481 - val_loss: 1.1365 - val_accuracy: 0.6484\n",
      "Epoch 510/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1560 - accuracy: 0.9414 - val_loss: 1.2580 - val_accuracy: 0.6602\n",
      "Epoch 511/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1646 - accuracy: 0.9401 - val_loss: 1.3224 - val_accuracy: 0.6445\n",
      "Epoch 512/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1517 - accuracy: 0.9450 - val_loss: 1.4200 - val_accuracy: 0.6250\n",
      "Epoch 513/4000\n",
      "128/128 [==============================] - 12s 95ms/step - loss: 0.1429 - accuracy: 0.9472 - val_loss: 1.3052 - val_accuracy: 0.6367\n",
      "Epoch 514/4000\n",
      "128/128 [==============================] - 12s 93ms/step - loss: 0.1272 - accuracy: 0.9540 - val_loss: 1.4024 - val_accuracy: 0.6602\n",
      "Epoch 515/4000\n",
      "128/128 [==============================] - 12s 91ms/step - loss: 0.1351 - accuracy: 0.9506 - val_loss: 1.3697 - val_accuracy: 0.5898\n",
      "Epoch 516/4000\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 0.1471 - accuracy: 0.9471 - val_loss: 1.5068 - val_accuracy: 0.6836\n",
      "Epoch 517/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.1290 - accuracy: 0.9531 - val_loss: 1.4978 - val_accuracy: 0.6211\n",
      "Epoch 518/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1656 - accuracy: 0.9406 - val_loss: 1.4854 - val_accuracy: 0.6562\n",
      "Epoch 519/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1374 - accuracy: 0.9511 - val_loss: 1.4550 - val_accuracy: 0.6602\n",
      "Epoch 520/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.1579 - accuracy: 0.9385 - val_loss: 1.3962 - val_accuracy: 0.6680\n",
      "Epoch 521/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1549 - accuracy: 0.9424 - val_loss: 1.4539 - val_accuracy: 0.6680\n",
      "Epoch 522/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.1638 - accuracy: 0.9389 - val_loss: 1.4753 - val_accuracy: 0.6367\n",
      "Epoch 523/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1517 - accuracy: 0.9429 - val_loss: 1.3408 - val_accuracy: 0.6445\n",
      "Epoch 524/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.1391 - accuracy: 0.9503 - val_loss: 1.3128 - val_accuracy: 0.6797\n",
      "Epoch 525/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1094 - accuracy: 0.9649 - val_loss: 1.4887 - val_accuracy: 0.6250\n",
      "Epoch 526/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.1406 - accuracy: 0.9520 - val_loss: 1.3908 - val_accuracy: 0.6680\n",
      "Epoch 527/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.1412 - accuracy: 0.9488 - val_loss: 1.4482 - val_accuracy: 0.6719\n",
      "Epoch 528/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.1234 - accuracy: 0.9534 - val_loss: 1.7958 - val_accuracy: 0.6406\n",
      "Epoch 529/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.1810 - accuracy: 0.9366 - val_loss: 1.6180 - val_accuracy: 0.5938\n",
      "Epoch 530/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.1274 - accuracy: 0.9530 - val_loss: 1.5415 - val_accuracy: 0.6289\n",
      "Epoch 531/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.1318 - accuracy: 0.9513 - val_loss: 1.5368 - val_accuracy: 0.6719\n",
      "Epoch 532/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.1134 - accuracy: 0.9607 - val_loss: 1.4562 - val_accuracy: 0.6367\n",
      "Epoch 533/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.1433 - accuracy: 0.9496 - val_loss: 1.4694 - val_accuracy: 0.6758\n",
      "Epoch 534/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1299 - accuracy: 0.9529 - val_loss: 1.5218 - val_accuracy: 0.6484\n",
      "Epoch 535/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1394 - accuracy: 0.9522 - val_loss: 1.6966 - val_accuracy: 0.6211\n",
      "Epoch 536/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1216 - accuracy: 0.9585 - val_loss: 1.4927 - val_accuracy: 0.6328\n",
      "Epoch 537/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1625 - accuracy: 0.9437 - val_loss: 1.5340 - val_accuracy: 0.6406\n",
      "Epoch 538/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1458 - accuracy: 0.9492 - val_loss: 1.5698 - val_accuracy: 0.6172\n",
      "Epoch 539/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1544 - accuracy: 0.9486 - val_loss: 1.5847 - val_accuracy: 0.6133\n",
      "Epoch 540/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1016 - accuracy: 0.9668 - val_loss: 1.4316 - val_accuracy: 0.6328\n",
      "Epoch 541/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1344 - accuracy: 0.9548 - val_loss: 1.5007 - val_accuracy: 0.6445\n",
      "Epoch 542/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1452 - accuracy: 0.9527 - val_loss: 1.4103 - val_accuracy: 0.6328\n",
      "Epoch 543/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1148 - accuracy: 0.9561 - val_loss: 1.5558 - val_accuracy: 0.6367\n",
      "Epoch 544/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1572 - accuracy: 0.9470 - val_loss: 1.6271 - val_accuracy: 0.6289\n",
      "Epoch 545/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1481 - accuracy: 0.9418 - val_loss: 1.7299 - val_accuracy: 0.6484- los\n",
      "Epoch 546/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1379 - accuracy: 0.9542 - val_loss: 1.5679 - val_accuracy: 0.6484\n",
      "Epoch 547/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1267 - accuracy: 0.9573 - val_loss: 1.6457 - val_accuracy: 0.6602\n",
      "Epoch 548/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1227 - accuracy: 0.9516 - val_loss: 1.5517 - val_accuracy: 0.6602\n",
      "Epoch 549/4000\n",
      "128/128 [==============================] - 10s 81ms/step - loss: 0.1163 - accuracy: 0.9557 - val_loss: 1.5596 - val_accuracy: 0.6523\n",
      "Epoch 550/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1301 - accuracy: 0.9580 - val_loss: 1.6065 - val_accuracy: 0.6250\n",
      "Epoch 551/4000\n",
      "128/128 [==============================] - 10s 78ms/step - loss: 0.1227 - accuracy: 0.9572 - val_loss: 1.4917 - val_accuracy: 0.6484\n",
      "Epoch 552/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1363 - accuracy: 0.9510 - val_loss: 1.4831 - val_accuracy: 0.6523\n",
      "Epoch 553/4000\n",
      "128/128 [==============================] - 10s 74ms/step - loss: 0.1450 - accuracy: 0.9465 - val_loss: 1.5421 - val_accuracy: 0.6680\n",
      "Epoch 554/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1151 - accuracy: 0.9604 - val_loss: 1.5100 - val_accuracy: 0.6445\n",
      "Epoch 555/4000\n",
      "128/128 [==============================] - 9s 74ms/step - loss: 0.1311 - accuracy: 0.9536 - val_loss: 1.5353 - val_accuracy: 0.6562\n",
      "Epoch 556/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1040 - accuracy: 0.9633 - val_loss: 1.5323 - val_accuracy: 0.6445\n",
      "Epoch 557/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.1321 - accuracy: 0.9468 - val_loss: 1.5251 - val_accuracy: 0.6523\n",
      "Epoch 558/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1001 - accuracy: 0.9661 - val_loss: 1.6160 - val_accuracy: 0.6523\n",
      "Epoch 559/4000\n",
      "128/128 [==============================] - 9s 72ms/step - loss: 0.1200 - accuracy: 0.9559 - val_loss: 1.6247 - val_accuracy: 0.6328\n",
      "Epoch 560/4000\n",
      "128/128 [==============================] - 9s 73ms/step - loss: 0.1131 - accuracy: 0.9619 - val_loss: 1.5233 - val_accuracy: 0.6445\n",
      "Epoch 561/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.1462 - accuracy: 0.9485 - val_loss: 1.4379 - val_accuracy: 0.6680\n",
      "Epoch 562/4000\n",
      "128/128 [==============================] - 11s 85ms/step - loss: 0.1426 - accuracy: 0.9523 - val_loss: 1.3646 - val_accuracy: 0.6680\n",
      "Epoch 563/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.1009 - accuracy: 0.9659 - val_loss: 1.4181 - val_accuracy: 0.6523\n",
      "Epoch 564/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.1235 - accuracy: 0.9597 - val_loss: 1.4122 - val_accuracy: 0.6797\n",
      "Epoch 565/4000\n",
      "128/128 [==============================] - 10s 77ms/step - loss: 0.1179 - accuracy: 0.9651 - val_loss: 1.4848 - val_accuracy: 0.6211\n",
      "Epoch 566/4000\n",
      "128/128 [==============================] - 10s 75ms/step - loss: 0.0963 - accuracy: 0.9667 - val_loss: 1.4335 - val_accuracy: 0.6094\n",
      "Epoch 567/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.1156 - accuracy: 0.9597 - val_loss: 1.6888 - val_accuracy: 0.6172\n",
      "Epoch 568/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.1052 - accuracy: 0.9607 - val_loss: 1.7584 - val_accuracy: 0.6055\n",
      "Epoch 569/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.1928 - accuracy: 0.9322 - val_loss: 1.4673 - val_accuracy: 0.6250\n",
      "Epoch 570/4000\n",
      "128/128 [==============================] - 10s 76ms/step - loss: 0.1142 - accuracy: 0.9583 - val_loss: 1.6918 - val_accuracy: 0.6797\n",
      "Epoch 571/4000\n",
      "128/128 [==============================] - 10s 80ms/step - loss: 0.1194 - accuracy: 0.9531 - val_loss: 1.7264 - val_accuracy: 0.6328\n",
      "Epoch 572/4000\n",
      "128/128 [==============================] - 11s 83ms/step - loss: 0.1178 - accuracy: 0.9594 - val_loss: 1.4694 - val_accuracy: 0.6562\n",
      "Epoch 573/4000\n",
      "128/128 [==============================] - 11s 86ms/step - loss: 0.0966 - accuracy: 0.9637 - val_loss: 1.5003 - val_accuracy: 0.6406\n",
      "Epoch 574/4000\n",
      "128/128 [==============================] - 11s 87ms/step - loss: 0.1145 - accuracy: 0.9604 - val_loss: 1.6765 - val_accuracy: 0.6406\n",
      "Epoch 575/4000\n",
      "128/128 [==============================] - 11s 82ms/step - loss: 0.0961 - accuracy: 0.9708 - val_loss: 1.5913 - val_accuracy: 0.6523\n",
      "Epoch 576/4000\n",
      "128/128 [==============================] - 10s 79ms/step - loss: 0.1278 - accuracy: 0.9552 - val_loss: 1.8337 - val_accuracy: 0.6172\n",
      "Epoch 577/4000\n",
      "128/128 [==============================] - 11s 89ms/step - loss: 0.1080 - accuracy: 0.9597 - val_loss: 1.5194 - val_accuracy: 0.6484\n",
      "Epoch 578/4000\n",
      "128/128 [==============================] - 11s 88ms/step - loss: 0.1062 - accuracy: 0.9631 - val_loss: 1.7873 - val_accuracy: 0.6289\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00578: early stopping\n",
      "128/128 [==============================] - 9s 69ms/step - loss: 0.5470 - accuracy: 0.7788\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.7453 - accuracy: 0.6719\n",
      "Train: 0.779, Val: 0.672\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABhDUlEQVR4nO2dd2AUZfrHvzOzfdOTTQKh99DBSFMRVIpU5VARFD1O7HLiiT+sgB6eh4h4KB7InZxiwwIIYkBFFAGlSAsdJBACpJNke5n5/TE7szO7s7vpZff9/JOdmXfeeefN7neeed7nfV6K4zgOBAKBQIh46MZuAIFAIBAaBiL4BAKBECUQwScQCIQogQg+gUAgRAlE8AkEAiFKIIJPIBAIUQIRfAKBQIgSVI3dgFCUlVnAstWfJpCcHIOSEnM9tKj5QfqCh/SDD9IXPJHYDzRNITHRGPR4kxZ8luVqJPjCuQQe0hc8pB98kL7gibZ+qJJL5+2338bYsWMxduxYLFq0KOD48ePHMWnSJIwaNQrPP/883G43AODSpUuYNm0aRo8ejUceeQQWi6VuW08gEAiEKhNW8Hft2oVffvkF69atw/r163H06FF89913sjJz5szBSy+9hC1btoDjOKxduxYAsGDBAkydOhXZ2dno2bMnli9fXj93QSAQCISwhBV8k8mEuXPnQqPRQK1Wo2PHjrh06ZJ4PD8/H3a7HX379gUATJo0CdnZ2XC5XNi7dy9GjRol208gEAiExiGsD79z587i59zcXHz77bf45JNPxH2FhYUwmUzitslkQkFBAcrKyhATEwOVSiXbTyAQCITGocqDtqdPn8ZDDz2EZ555Bu3atRP3sywLiqLEbY7jQFGU+FeK/3Y4kpNjqlVeiskUW+NzIw3SFzykH3yQvuCJtn6okuDv378fs2bNwnPPPYexY8fKjqWnp6OoqEjcLi4uRmpqKpKSklBZWQmPxwOGYVBUVITU1NRqNa6kxFyjUXSTKRZFRZXVPi8SIX3BQ/rBB+kLnkjsB5qmQhrKYX34ly9fxmOPPYbFixcHiD0AZGRkQKvVYv/+/QCADRs2YOjQoVCr1cjKysLmzZsBAOvXr8fQoUNreh+1wvbd27B8/nyjXJtAIBCaCmEt/P/85z9wOBx47bXXxH1TpkzBtm3bMGvWLPTq1QuLFy/GCy+8ALPZjB49emD69OkAgHnz5mHu3Ll499130aJFCyxZsqT+7iQE7nP7GuW6BAKB0JSgmvKKV3Xl0qlceT8AIPbB1XXUsuZDJL621gTSDz5IX/BEYj/U2qVDIBAIhMiACD6BQCBECUTwCQQCIUoggk8gEAhRAhF8AoFAiBIiTvBZ61UUbVoOzuNq7KYQCARCkyLiBN9z5RQqD/0Atpzk7SEQCAQpESf4oLy31HSnFxAIBEKjEIGC703QxrGN2w4CgUBoYkSc4FPEwicQCARFIk7wiYVPIBAaE8dva+E+f7Cxm6FIBAq+YOETwScQCA2P89Bm2LYsbexmKBKxgt+Ec8IRCARCoxCxgk8sfAKBQJATgYJPfPgEAoGgRAQKPonSIRAIBCUiUPCJhU8gEAhKRJzgkzh8AoFAUCbiBJ9Y+AQCgaBM2EXMAcBsNmPKlCn497//jVatWon7jx8/jrlz54rbpaWliI+Px6ZNm7Bu3Tq88cYbSE5OBgAMGzYMs2fPruPmK0AsfAKB0EhwTdzQDCv4hw4dwgsvvIDc3NyAY5mZmdiwYQMAwGaz4Y477sD8+fMBADk5OZg7dy7GjRtXpw0Oi9fCb+odTyAQIpAmbmiGdemsXbsW8+bNQ2pqashyK1aswLXXXousrCwAwJEjR7Bu3TqMHz8eTz/9NMrLy+umxeEIYeGTyVgEAqFeaeKGZlgLf+HChWErqaysxNq1a7Fx40Zxn8lkwowZM9C/f38sWbIEL7/8Mt54441qNS45OaZa5QHAycXACiAuVosYUyzfPqFNKUZQNFPtOps7Jm8/RDukH3yQvuCp635gXQ6Y66nuuqBKPvxwfP3117jllltEfz0AvPPOO+LnBx54ACNGjKh2vSUlZrBs9axyz1UbAKCi3ApbUaXsWFFRBSi6Tm652WAyxaLIrx+iEdIPPkhf8NRHP3Auu/i5MfqYpqmQhnKdROl8//33GDNmjLhdWVmJ1atXi9scx4FhGsiy9ovSYcuv+I4Rlw6BQKhPmrhLp9aCz3Ecjh49in79+on7DAYDVq1ahUOHDgEA1qxZUyMLvyZQklw6HMvC8pkviogIPoFAqFeauMbUSPBnzpyJI0eOAOBDMdVqNbRarXicYRgsXboU8+fPx6233oqjR49izpw5ddPicEgHbTmP/FgT/2cQCITmTVOPDqyyQ3vbtm3i5/fee0/8nJycjJ07dwaUz8rKwrp162rZvBogden4d34T/2cQCIRmThM3KiNwpq2QD58FWH+Bb9r/DAKB0Mxp4kZlxAo+79Lxt/CJ4BMIhHokwMhsWkSg4PtcOhxLfPgEAqEhadoaE4GCH9zCb+oDKgQCoZlDLPwGRjpo69/5xMInEAj1StPWmIgTfAqC4CuEZTbxfwaBQGjmEAu/gaElLh1i4RMIhAaEAxH8BobE4RMIhEZCkvurKWbnjTzBp4U4fA4csfAJBEJDIjUqm6CBGXmCL7PwSVgmgUBoQCQib9u8uHqnOm1w7PkcnMdd160SiTzBp33J0wKfsETwCQRCPSIxKj2XjlfrVMe+r+A8+A3cZ3bXdatEIk/wEWrQtum9YhEIhAiiFhrDOfm1POpzvlDkCb4sDp+4dAgEQgPiP9mzOu4Z77n1uSpfxAk+RVEAKD61QsBMWyL4BAKh/gjQGLej6icLHgmq/mQ54gQfAO/HJ8nTCARCQ+NvZLqd1TjX65Eggl9NKEo5tUITnxRBIBCaOf5GpqsGFr6/K7oOiUjBpyiaf7UiYZkEAqGecZ8/CE/ZJX7DT2O46rh0vA8LjiVhmdWDosGW5Yuj3iJE8AkEQh1j27IU1s+f4zcCXDpVF3xxzNHtqqumBVDlJQ6bFRTgyTsMT95h+X4i+AQCoT7x15hquXS8HglP/Ql+lSx8s9mMcePG4eLFiwHH3n77bQwfPhwTJ07ExIkT8dFHHwEALl26hGnTpmH06NF45JFHYLFY6rbloQiWsa6a8a2OAxvh+G1tHTSIQCBEIgFRObUatOXr4hpT8A8dOoS7774bubm5isdzcnKwZMkSbNiwARs2bMC0adMAAAsWLMDUqVORnZ2Nnj17Yvny5XXa8FAE5NDxHalWPc69X8J5aHPtG0QgECITf3H2Nyqr48P31uX8/Wt4inNr164ghBX8tWvXYt68eUhNTVU8npOTgxUrVmD8+PF4+eWX4XA44HK5sHfvXowaNQoAMGnSJGRnZ9dty0MRbJSbuHQIBEJdIhF8juMCLH77T/8B57KHrIK9ehlseYHP38+64c79vc6bClTBh79w4cKgxywWCzIzMzFnzhy0bdsWc+fOxfLlyzFt2jTExMRApeKrN5lMKCgoqHbjkpNjqn0OAFQGseQT4vXQmWKrUQ+PqRrnNEWae/vrCtIPPkhf8NS2H9wVTpi9n1MS1LCVamEHQOuMYO0WgPVAV3AQcf1GKJ7PcRzOrXoR8IvMiUlMREI9/I9qNWhrNBrx3nvvidszZszAc889h6lTp3pnvPrw364KJSVmsGzdWeVlZWaodJXhC/pRVFT9c5oKJlNss25/XUH6wQfpC56q9gPnccG5bx00/caD0uhlx9jyUvFzUd5leMqtAADdmGdg/WoeAMBsBxxBrsM5LAFiDwAWFw1XDf5HNE2FNJRrFZZ56dIlfPHFF+I2x3FQqVRISkpCZWUlPB7etVJUVBTUJdSgBHHpcBwHx4GNYMuvKB+vx4kQBAKhaeM6vQvOQ5vh2L8+4BgnCaHk7BU+Hz7js6XtOz+E2z9i0Atrvaq43//BUlfUSvB1Oh1ef/115OXlgeM4fPTRRxgxYgTUajWysrKweTM/4Ll+/XoMHTq0ThpcO4IIvr0Szr1fwrp5MZyHvwVbUSQvEMYHRyAQIhdhnWzOYQ48KBmU5Zw20aikpOkRHBbYvl2iWDdnLVe+proJCf7MmTNx5MgRJCUl4eWXX8YjjzyC0aNHg+M4/PnPfwYAzJs3D2vXrsWYMWOwb98+PPnkk3XZ7poRbNBWmOFmLoPj189g/WaR/DARfAIh4uA4Dp6iXDh+/zp0QZWG/6sQYikLofS4fRY+RcEwOfj4p3h+A1v4Vfbhb9u2Tfws9duPGjVKjMaRkpGRgQ8//LCWzatjgsXhi1nqAHAAZy2Tn1YHgu++mAMmvQso4ctDIBAaDWfOd8g79h3cVwsBAJo+t4Ji1MqFVfx+zuWA+/xBMG16gy0+D0/hWdCxKWIxzuOSCD4NJik9oCr35ZNgy/Kh6X4Tf04QwYfGULMbC0NkplYIRjALXxg0EYTfP4d1LQXfU3oRts2L4di1plb1EAiE2sM5bXDs+lgUewDgbCEGSL264Mk7DNuWpXAd/QGu4z/BsecL+cQq1u3TmCAZL20b/wHHLx+I4Zustdz3BiGhSfrwmx3BBm3F17Igx521E3zOwc8yZq8qDwoTCISGQ3Hw1V4R/AS/KBrWXALOaeFz3rjlLh1O4tIJuIZEf7hKfpyQs5SBMiRCP+E56G78i3icIhZ+XRDEpRNmVRriwycQmh6e4vPwXL1U7fPcFw6BadMburY9xX2cLYTg++kDRdG8Ecd5ZAkaeZdOCAtfoiOWT5+Bp/g8WEsp6JgkqNK7QN31Bl/ZenL9RpfgB3PphMtdQQSfQGhyWL+aB+va56p/oscFShcLWuI2CeXSCQjLpijxrZ1zSnKEuey+h4OChe8puSDbZsuvgDOXgIpJDihbk3lLVSEys2UGIdgSh0rJiqT5eDiXLeA4gUBoenhKLoBObAWKDrRlnce3gzYm8ILPqEAzvjLVsfAhWPgAOIdV3C1LtOi18FXtroE7dz8AwH32N1k1nMMCznIVtETwqZhkcOaSkPdYG6JK8INb+AouHanfrh7zUxMIhKrDOSzwFJ2DqlXPgGOe4vOwfjUPmmtuh/aaiQHHHTtW8x80eoBRg9b4BJ8NJfisgkEoCr5CbD58cfi6EY8BHhes6/8O1zE+0pE2tQdbdA5s8QUAHKiYJPE84+S/V2/RlGoSZS6davjwJYJPZtoSCE0D248rYdu8mI9u8YP1DoSyJedDV+JxA7QKlNbn0nEd/jZoUAXnkf/+ObcT8PruOVsloNYFunC82xRFg1JpwbTqIR7S3/IooNbDU3wOAOQWvkYP2pAQuv21ILoEP1gUjtIT3C7xzfkJPsdxcOz5InBGLoFAqFe4ymL+r01hhqpguNFhHBceN+/S8Qt9dF84oGxd+0XpSGPnPXmHwaR2DDzHb9BWGnVDaQyg9HFgyy7z27qaJYmsCREn+GZbCPdLNVw6nF0yiOP/D7dXwnlwE9zn6yeFKYFAUEYQR86u4EoRfqc0AwBw5x6A+8pphVo43qXjtfBV7bMAAI5fP4P5/UcDFy3x0wfOIp+Yqc4cFqgt/oKvlYRZqvWg9LGAh78OpdYptLF+iDjBP5OvnJsCQBXi8CX7pE96f5eOd5sjvn0CoUGhtF7BV5ihynmFWZgxa9v6FmxfK6c3oBi1b9a7Wi8+JMB54L54RF6vfxy+pVS2TStE2fi7eCit0feZpkHr43wHieDXnBhdkOnRQPV8+NKkSBLBd+cfg+XTOd7zqij4ZOEVQhTAsR5Y1i0ImhmyLqB0vHCyXteODMEypxm4wi0gwqgACKLMyQSaM5fCffmkL1LP38I3ywUfGgXBDnDpGOXbOl+ue0qlDd3WOiTyBN8QSvCr4dLxnzLtxbH7Y7F8lderrOZaugRCc4BjWZg/mQPX2T38tr0SbNE52Levqr+LMrxVLsxUlbXHO1/Gnbsf9q3/ClOPWiLyHCAZmHWfP+hNgbCa38G6fW8AQMDvWTGzZSiXDsBHCgkQwa85MfoQgl+NQVtZKKbUpSN9aHiI4BOiD2fO97D//D7gsoGrLIL95//yB8TfRv1MGgIg/haVLHzOycfEh4yp90IxKt/kJo6DVBvY0jwAgOvEz/xhjweUPj54XUouGf+oHT/BFwdxKVpxzkB9EXGCb9CFGKGvloUfzIcvqaOqPnwi+IQIwrHnc7hO/ATXmV/5HcL3m5XPMuXsZrD2Ol5ZS0HwxQmVIXJeSSdSAgBoFYzdBoNp3RvarEnibio2RfbA4Fg3H4fPhNAVdaCFHrDin79LR7DwG1gbIk7w6RBTkrk68OFLHxpcVS18/y8bgdCMYdI6AQBYIVUA5+fr9rozzB88DssHT9TptYUBVFkKcyGIIsgkKL6M32/cG6VjuPUp0LEpYNI687uT28qv57TxYZy0CrEProaq83UBVVNBMmPKymj9Bb9+kqOFI6pm2joPfgOuohDaAXfI9itH6UjEXPJAkKVnqKKFH/RBQyA0R0SB9c5V8a47Lf6O6igPjOvMrwCjgtobNim9tvQ3act+E57Cs6FzXvlF2lF+Frv+1tlgzSVwndghP89h5c/1lqcEa55RVz1oQ3o9Ied+PaU/DkdEC7524J2y/BZcRSGcB7+BuvdowOMGbUzkDyj944L58CG18IlLhxCF+At+gIVfN4Jv3/ZvAIAjPh2ULgbGiS8ovo178o+Gr8w/tNpvsRNKYwCTZIDHmCDbzzlt/O/cO5lLiK6hNHpwoeb8KKAf9SToxJbi+Y1BRAu+ps8YsJYyuHK+k+0XXjN1Nz0EdafBYX34cpeOpBCJ0iFEERzHARwn/h5EwYefhV/Hg7Zc+RVw3uk1NUlzwrHugFh6f8EXoAQjUDjXyVv4goVOp/AuH8WJX2FQte3ruw5x6dQdbkYLlccBs80F48A7QSe0hOOX/wWUs29bATomRdlSFwSfUQOcVPAlWTRr6cN3X8wBpdaJPlECoSlj/Xoh2KJc0IkZAKSC76WOXTqK+Au3BMqQAEprAFsmz5HPVZYECL6/S8dXh4Lge9yiS4fxCn5tjbjGEvwqDdqazWaMGzcOFy9eDDj2/fffY+LEiZgwYQIeffRRlJfzj+J169bh+uuvx8SJEzFx4kS8+eabddvyELhu+yeeL7sDJ86XgWLUUHe4NmhZzmlR/BIJPnxKpQ0epVNLl45t82JYN/y9anUQCApwHAdPcZhkYXUEW3CG/60IA6eS1MAAZILv+H2DpI3VF8egc1xCWPiUdPaqBMtn/wfr58/LdwYRfMHNK06Mclj5h4X3jYAy8pkt6aRWQdtRFRrLpRNW8A8dOoS7774bubm5AcfMZjPmz5+PlStX4uuvv0bXrl2xbNkyAEBOTg7mzp2LDRs2YMOGDZg9e3adNz4YXTplgDHEY/W3J1BYZg1pcXAsGyRKx/vlVWvlx6VROiQsk9DIuM/+CutX8+A6t7/BrimuAOe3ToSQ2oCzXIVz3zrfgRqkIFFymVi/XQLPpeNBz6E0+iq7fCg6mEsngf/rXZxcsPAp78QriqJgnLIIhnFzq3SdoDRVwV+7di3mzZuH1NTUgGMulwvz5s1DWloaAKBr1664fJnPAHfkyBGsW7cO48ePx9NPPy1a/g2BWkVj7j394eE4rP3xbOhXTNajaE0IIV4BXyJZlI78PHfeYbgvKgwg1XNYJltRiMqV98N9+WS9XofQ9GCv8r83YbJQQxB0gQ7BwvfPLisdD3NafQt42yqC5qHnFOL3Pd6UDUEnQTHqkG8A8rJBXDoqLaAxgDYmAaD4sEzWLStPx6WC0sVA1bYftEOm8ed5UxobbnsJ2qF/Dnt54QHCtO5dtfbWEWF9+AsXKicfAoDExESMGDECAGC327Fy5Urce++9AACTyYQZM2agf//+WLJkCV5++WW88cYb1WpccnLN04b27JKGWwe3w6Zf/kBMXC8EG2KJi9WinHLD/2vCluaB1hmhTUyFx1IOk4l/xbPSEMtSnFvcDwD532wCpVLD1G+QrK6KixrYAajVjKy88JWW7qsJFfm/wQJAdWEPTL2zAo7Xtv5IIRL7oSzWCCcAg5ZGUjXuryZ9EWoKlckUi4p8BnYg4I02KU4FdUIsbBeO4fKHL8I0YRZie92IPxbeDwBo/cjbAEVBnZgunmMzs/BzGIloTRmwXwg0IDUaNZxgA37LSiSnJojt9ocZOA4aU2sUXz4OHeOCFSx0Bn1g2Xte8N3jg0vgriyFNr09gD5VaAGQNHs1aI0OlCpUdoC6pU4GbSsrK/HYY4+hW7duuP322wEA77zzjnj8gQceEB8M1aGkxAyWrX7iMZMpFkVFlejYIhZuD4ddB/PRIUjZirJKuKyBXy3OYQXdohtcbg6s04miIv7rznp8X2bW5dsPAC6bDVCzsn0A4Kzg63e5PAHHACjuqw6uSt6CstudAXUJfVEXcBwHrvwK6IQWdVJfQ1KX/dCUcNp5ebOYrfBU8f6U+sKxbx1UbfuCMbUPfiKjUnZ/gv8OO6966/QT/JKCUjAuA6w/fAwAKL9wFvb0/uLxvHcfBwDEPrha3OcqCL7WhJvWg05pC9Zv7MLpdIF1Bx/UlVJ61YHUmCC/vcwxsAHg1HpYy8vhsVvhcNNhvj80wKQA1f2OWewA6m7NbJqmQhrKtZ5pW1hYiKlTp6Jr167i20BlZSVWr14tluE4DgzDBKmh/ujSKh6xBjVWbT4RtAzndvh8kn7QyW34pEnBXhP9XDqc26k8kFvHPnyOZeUDYcJU9nrOyuk+sxuWtc/CnXckfGFCwyAs9hFEiKsCx7Jw/r4B1nULQpaTZnhUJFgbvC4d0bUTZGYqa6+E+YMn4L6YE3rWLM3AMOF5RddJlcM2g4RlSqE0BnC2CnD2SlAxiWHLNwdqJfgejwcPP/wwbr31Vjz//PNi/giDwYBVq1bh0KFDAIA1a9bUyMKvLWoVgxemZ6FvJ1PwQm6HLI2CFDo2GaBVfj58VvZZFu7lccqy7vnK1a0Qm1fNgHVDcFdbfeEp4pdkY69eClOSUNe4TvwMT+EfgQeY2gt+uGgz6zeLYP7giaBCLRBsIiLn8v6+vAZSsAgc95lf+cWFDmcHhnxKoRlQKg2YpNaBx2rpw5ciDfGkjUlhSjcPauTSmTlzJmbNmoUrV67g2LFj8Hg82LJlCwCgZ8+eWLhwIZYuXYr58+fDbrejXbt2WLRoUZ02vKqYEvSYMbY7zP9RPs65nPwXUqUJnEjFqL0Wfogfk9sFaPhu5NxOvh5/6mHQli0869uQpnmtT8SHXT3GWTdDWFsF2NKLUGV0r9N6ObcTnMsOWh8nZqSUuj34i/P/k4CJRdW5Tpj5JJ78YwD8wh6VUgsEeehwDjPMHz0FTlg4xO1QbK/r2I/8dVRacc1YJfzTFFAxyeJAMpPUGp4C3ypXhttegqc0D46f3wfAT8b0lOVXKf8N1HqxXv8JWc2VKgv+tm3bxM/vvfceAKBXr144cULZXZKVlYV169YpHmtoKEYFpu8EnKY74OqRX+CxXsW16jMAvCFmbgcoYxI4d6nfeWpQjJ9Lx89a5zwuUPCGWLkdgEchVSpXRaujxghpXuv5MuLliOBLcR3fDuf+DYj5y0ox+qIucB78Bq5TvyBmaohgB0E4g4gta73Kr6GqZIgIVHHGOCe5BqU1ylad4jgu6JsCW3rRJ/bgLf6AGH743hzZ8iuh3UdChEtya+hvfQp0XCosn82FutNgqNr0gac0D7ZNiwBw/L1LJjmp2mdBO/DOqtyuLIc9FSEWfsRlywyGYcAk9Mnqi64TZyDX6VuSjLPzYWGKA5GMiveRhhB88TWV88bzK6VpaKg4/Pq+jnjrRPAFXH/sgfvCQf6hHip5Vw3gbOXgzCUyoQ0oIxwLYuFb1jwJW7jFQKqaIkQm+H4zRT2u4C4d/+UI3U4+KVkQ2IqCQB8+JX2Q+r5/qta9QcenI+aBVVB3uY4Pl2yZ6SuiUsszVVbjgSx9UNARYuFHjeALpCcZ0Co9QdwWcl8z6V0CC3tdOtLXTw7+Fr73x+KdXKL4aq3g0qnbh0BDmfbe6xC9F7F/vxys17cebPBfCudxwb77E18u+ZBlvTlrbCHmsAizXkNkfPVczAl9HYngh2yXxPXjn98dHldwC7+80O96DnGxEn/o5NaAxw22VDKrX62TP2AU/PQUHcRZQavk5wYrp4A4G1ata7SZsXVN1Ak+AGSk+SZuCIJPe2fWSaEYVWCUToCF7xV6YeBXyRpTGrStQRKoYNQkoVTNLiQIflR+bcLCSRbg4NwO2H74N1hLGTinDR7v4B9bfB6uI1vETJAhEcRcsoaqp/APVK68XxxAF79vrsDAgyon+JIIfpXaBQB++d05pxWegrOKRT1XTgVcL9igLJPRA4DXreOdYEVp9DIrvWrfd94qoRiVuPA5gGq53IQHRdjopGZEVP5ypYLPWr0z/dQ60Kb2vIUhQKv5L0gIwfdcOSUPx1QUfDbw3GqKtOuPvbB+/apy6KVwzfpeLJ0sxh4aSaoBtuwy3Gd/hSf/GGzZb8L6+XP8PAbJW0DAKkz+eL9TrMW32If7wkHv38PeOrwPBUm9rHegMWRoo4Qqp/mW4L+gh+WTOcFn+/q9zXIuB1ynflEsKhv49i4OTmkM8gdMlcbEvK+hjBqUXiLY1QkP1wiCX/MJoE2NqBR8o1HyeuZdOYdSa2G47SUY//SK75jEh+8TWrnoOXZ9BMfONT4Ln/MEumu827L91RR8tvg8bykp/ThFN1J9CzKx8EMhE3Pv/4mzm30Wrssud/uEE1ohDbFFmsrAF5HlOLgJrsPZsmu7zv4Gy8d/g/vSCZ+F741m4VwOZavfLyxZ+iAKNrdD6iZh2lRtZqkAW3Ie7rO/KR6jTe3FPDNMakcwLTOhu/Ev8gdMFX472hum84LNqPioH/EC1Xfp+D/cmjNR+ctVSo1KqbSB61AKYZmAz6pQ+AF4is7JB778VsgSLShpauUqfGlZcwmfIyfviE9A/Hyf7iunQg7q1S3eeyfJ4BThpKGEwmC+vVKM+eYcFpnrJVw4pGC9s+ZSxePOPV/4NryC78nnk4uxVy8FCL71q3kwf/B44HX8kpuxxbm+jSAPJZ+bhIKqbb+g90D7p/6WuFT0Y54W69FkTYJxyiLQulgxgILSx8Ew7v/ApHaotuBrut2I2PuXB4ZfVieKytsvRPCbOwpP+byrCl9swYcP+L5kShYPTct/NJKBW+eBjaIVhiAWvvPET4rNFCxD18kdkpS0Pt+nO/8YbF+/CueBTcHbVpcI1TfUmEEtYc0l9Tq+EWD9KljvnN0MSsW7JjiHBZwr8KEQFE+gD19ycfmmOKmJf6BQKo0vAaD3gcOWX1G+jp+Fb13/si/lcpA2ihY+zYBJbiPuV3W5QVZO3XmILKRR8Ier2mdB1aqnGOJLqbSg4/gEjcL6stLogOr78JWpjg9fcO+qOw0KU7L5EJ2CL0yrVutwKbYnAODTn/MDilGM2vcFEb9kCtYtRcsXPZdY3K5jvvkLcsH3lXH8/L7yIJZQD6MSZ/BKy4lZCwURqWfLWxS4ehZ81lwC+47VNfIti3VYy2H5+G9w7Pm8DlvmfxG/rJCKLp1KPsU2BMGXiKvESGDNpfI3BED8/7MWZQtfXtYl/wtKZuH7jxdwLgecOd/xaTqUIny8kUFckFnoogAzKjE3vHbQ3aBj5PHqFKOG8e7XQXnFXDiPjvcmShPeqiVv3aqW3fgPkjGI6lr4QamG4DPJbRAzY2XIN5jmRlQKvvQp3+WuJ3G0819wqpTB/pPy8DGphS9aFUpGNEXLc34Hc7GwwQdtlUL6hGtSjMoX7mkPPuW8/l07nKxd9YVjzxdwHd8O9/kDNa5DSK/rqc+8P35CGcylI/iQbd8skt2TVGgtHz8Fy5cvyusTo3QkPvxgs6o9Lt59KLH0BcHnzCUwr5ohqdcDx29r4dj1EZ9yWEnUBe9dsFBTRi2GLVMqDWIfXA1N71GBKQtoBhTNiK4VcWEhMSouUPCZ1n2guXYyNFmTfPukSd1qJfjVSy4QcsJaMyQqBV+aOImiVWjTi8/c9866HBzPLZWXC0hOFaj4FEXLLSFpLL701VsSXeAvmsoWvlcQaLXv9d4psfD9LfpaTK+vEg1k4QvuAs5cFqZkCMQQ0vqbNBBgGQcZtBUsfMC7apSAnw+fqyyW1ycIvjRnfIhoMNfxH8Wc8XDZg4Y+sk47PF4/PeewKC7kI7qeFMI9Af53Q6l1gS4Sym9b+P3QXsH3jkGJE5kEl47sN0lD22+cbLKTqm1fGO58FQBCZ/QMAhVrkrUjWonOu/cLzWqRbMCILN5f9/qnB8X9FK0C5Q0NE38AQXz4Ul8n53HDdXpXwA8uVJSO0o9TnBDDqHw/fqmF7/+jr28LX2h/fQu+dzEJ1hpa8DmnLfgENuHhWp8RRf4WvqIPv1IeJSItX0Ufvuwc71uEkqvF8csHkrY4Alak8tVhB+cN9WQrixT99JzTBo5lYV3/snLbaIZ/kPlbzP4TqoQHgvf/oPIu+EELic8UXDrBYBJawvCnV6C59k9hy/pjmPg89KOfrFoOnQgmKu/ef3kziqJw180KC4kzanFGofvUTrD2SmU/OUXLIi48V07B/uNK2Hd/LCvGlRfAfcWb2ClA8BVmHkpcBOLycdLYan/BqW8LX2hzAw3acpZAwbfv/gT2n/4Lzu2E+eOn4D69W/lcwWpVsPBdub8H+strQhCXDmsugesM3y7+/xVkMF2YtCcxIqQx90ouOtFN4woT4eOyB73Hit+3iLlt2PIC5QeP0wauojBwvwDN8IPRfhY+6/c/E98AvA8GTa9RiLnvHYmvP9DCDwWT3LpG+YpoQwJUbfpW+7xIIyoFX8maoCkKSXHagHKCe8F58BtYPnhCuT5KbuELy87xr8PyH7vta29aY3/RVLLwBWvJ41KM0gmw8moxyFklBKu1vh8sgh9aITrFdWQLXCd/5oXPaRNdE8Hq8Lfw2fIrsG/9l5h9sjYECLLXwrd+/aqYbgEcB9bqlxrB6/YQjQSJq8/y0eyQg+PiA1/Bepcl+PKP+ZdwdeeX4mf3md1w5WwVt4Ul9ziXDR6liVSigPMWfkCIs/8D1utC0d/8CNTdbwKd3EY5zLGKgk+oHVEu+PIv54IZA/D3BwaK2xTNVDkGV2olCb5YyhBk7U0o+PCdCoLvtfr5mbxu2T7/zwCUc/Er4Ck+H2CJ+cP6+5Olba5nC1/wfwdb7xSQuDaU2mk3g3MLYif/HwuWP1t2ufYNDeLS8X9QCW8qqs7XeXd4+0/4zvj70KUPer8cLqKFr7DmK+ewgEnrDCrWxE+yCvMWI0bKSFC168+nBXbavDNnKRgmviDOOgXjG8Sk1IEWvm7QFGiH3MMvHgSIlj0dnwbd9dNB+fvQhQdENQdTCTUjKgXf58eTW99GnRotU3wC7/awATlDlGAri8BKXn9Zs1fwJTk8Ak8K79IRLXy30xexIXXp+P2gObZqFr71q3mwrH026HH3hUOwfPI03Ll+UTJBFqmuKZzdDMe+dYEpBtw+/3dQXD73iRTWVgHzB4/7JiX5W5zC/74O3lL8B21Fi9rf6nU7oGp3DTR9Rgecz1qvygdl4QvD5Fg3aGOy/Byv4Ae8NXivQ+njQGn0fFvCCL520F0Bok9RNH++rRLuc/tBJ2aASesEVRvvYtuCYHMsmIzuYu4b8XxdDDQ9b5EIeRj3C+XLeUOof6JS8IWoCU2/cSGLPbviV1jY8K+aXEUh3Kd3idtseYH3Qwhh9BMcxUFbp8TCF6bZS106/gNk1Rm0ddnBsR44j28PcNGwV/kJOu78o35tFiz8ql3HdXKHWJcS9l1r4Px9AzwX/UInBSF1WoOGgEr95QD/9sF5XOAqi7z34LXg/QVfeHDWxUPLr79Fi1pJvBgV6IQM+T63E5Y1T8Kydq68HnOp6LKijAnyY4KFryT4AKDR8Za328EHGoQSXK0xMDEYzYDS6OA++yvYsnxoB04GAOiGzoDupofApLTzNoSFtu9Y6AbfHaRyr5CH9bf7ct4Q6p+oFHyKViH2wdXQ9g0t+CUVdmzdV4Pl/IRX+1A+9eoM2npcEpeORPD9HxJV8OFLo1rcZ36FY8dqOH/fKCsjJJvytzzFUMMqiCXHcbD/9B9Y1gdfJ1W854BFZSTusSChhaK4OizgnDZY1y2A+X+PB7gx2IIzcPy21rdD8pbC2ioUc8W4LxwWXXSstVyWf4a1lvva5J8awft/VxyAZFSgaBr60U/CMOF5eVv82sCaS8UUCJTBLw+7cM0gETiUSgeotXzfup3Q9B0H/ci/QtUxcLYopTGKicEE4WfSOgJq3o1EJ7UC07qPt14N1J0G+yz8qq7iFi4qphpROoTaE5WCX1XapsXim93na15BsAUhOE7Bh+8TfPel4/AUn5dPlxfENoSFXyWrVRJXbd/Or1zmkcaGA+KPMMClIlj2VbmOIEyh3ApCPf5WoMSnLW2D9P6kKQpYczHYkgu8Vasw0Os8tNl3nvDgtFXA8uEsOH79VN7s4vOwZS+BYxcfYWVZ81eYP/wrnIez4Tq9C7at/4J95xq+Dncwl06g4AuRYao2fUGndpSX94MtPid+pkOMAylBqbWgVFpx0RFKa4CqXT/F+HNKaxAFX931BsQ+uBp0fDrYolxxn39+KU2/CYBaDya1Q5iGVHX+g/dNIMrDJRsK0ssheGxST3RpnVD1E/xn5XlcynH7Hlegq0Py47dt+iesX82TDeqJYicTfP+p+FWw8BXit0X3h4DgQ7f5Cb6n6oLPBZmwI7+wcn4i6ZuRLLujVCClIauSgVtX7v4w15SvEOU6skVm5QsPUdlC7ZwHjl8/hf3HlWDLr/Cx69K6JO3jOFZurQox+JJ9FE0DFAPX8e2KTXSd+Nm3EWLhDcMdCgvZq3X8oKs3NQLltdaVLG1KaxQjhqTr1araX8NXlTk84BxVemfE/vndaqQMDpPfSTAuGmwRn+imSoJvNpsxbtw4XLx4MeDY8ePHMWnSJIwaNQrPP/883G7+R3Dp0iVMmzYNo0ePxiOPPAKLJcQq9E2UlHg9nvhTr6DH9aNny36Q0iXRgOAuHU/BGTj3fiEvq2AJi64Nj1PRbx5ggbtdQdPZ8m8VrOIyfJxfrhYxSqbsIqzfvuHzGwuCX5WxgqosmyeMS/i7RjwuUSilgi/LVSPpL7ayRJyq78lTXt3JduGYt13B88YA8AljsER0Douv3xXqgsshnzUq5GL3d1lwngCXGQBosm6XbSsNZqo6DoJh8itgEjOgG/E49Lf+zVderQUdKxnoFVL8Kgm+SuOLGJJMDtMNfxAxf/53LdMKCOsshxZyYSJWwApahHohrOAfOnQId999N3JzcxWPz5kzBy+99BK2bOEtpbVreX/pggULMHXqVGRnZ6Nnz55Yvnx5nTa8oTDq1ODGzce/bLcFHFO16QMmvau4LVtoAYD77G+KkSZKS85xSj5ZcValU1lkAx4SHFxHsgNcBZzTBvuPK2FeNSOoG0H2oJBcy5N3BE7B4qzGgGewpFvya/qFJwLwlOXDc/mUOK1eiEpyHNgI+47/Se7JyosUowFrLvaJbJDFMS5/+CKfoEwhkomzVYDzuGDb9m/xbYfj2KCzeIU3H8WkYy67PHWH1zdelYlFhttehKbfBGgH3uXbqRCuSCe2AOOdqapunyVftEetE7NOAr6c7kLOesPt8+XtFXzxEpcPxfBpE2pFFT062kF3wTj1jWq7rgg1I6zgr127FvPmzUNqamrAsfz8fNjtdvTt2xcAMGnSJGRnZ8PlcmHv3r0YNWqUbH9zwTBpAQy3vSRux7Vsh2sG9ceLZZPxFjtNXlgibP4WfjDrxn35ZMC+kDHTbmeVE6M5fv0M9m0rZPvMqx+BW5j5GSz5mizbp1zIKNr7662GSydYDhYZXrHhJBO6rJ8/D3AeUN6ZmMID07n3S1+eGPCWP6U1gI5JAldZXKX+YYvPB7HwK+C5fEocxOZ3csHHH5xWPrIpROoDAdH1UZVBSUYDiqKg6XMrHw8f5Dz/yBqpJS5NMwz4vpPq9tcg5v53wZjawTT+cWj6jOH3dxsKAFC1lKw0VQfohkwDndJW/jBSgKIZ0DHJIcsQ6o6w38KFCxX8hF4KCwthMpnEbZPJhIKCApSVlSEmJgYqlUq2v7okJ9d8aTGTqRbrUJp6Buy6Z2x3WJ0ebNp5DkjyXSOf8kCQP7VGBQ8ohPNbsoUKa3+6HEhJiQFFUQh4J2BdoDhWXitFI1g6ZPf5A0Hv3wgzlGQsKYaCKo4/p1RLQepkiYk1IN4UC7PXelarwvevzcrA6m1nsLIOmoMTQIyORrwpFpZTeyE4cHRx8bBcomFQc0gyxQb0iZq1gtIboYpNAusoB8f5/g9B27T1LahNbQL2x6gcoDUGWb8wcMEeIsIoyQhU6mgIjzVKpQHndiLBSKMIHjGJtj4+EeY8ICYuBgmSfkie8xFyX5cbD0mmBGiS+TKFMTEwA4iLN6LI79rxqamIkdTFeXRivyWkJEHbsgOEUIO0bj0kbiHvOabhiO3t9c+bsoDevpm3dYapL9Cjb93XW8fUSieaIbWKhWJZVjaKz3EcKIoS/0rx364KJSVmsGz1B3NMplgUFYWYtFND+nRI4gXfy6v//Q13232RMi6n2yvENYjxZt0oulIK9x975fuFSTR+ULEp8lwnap3MP3/+gwXQ3fgXpLaRx35XXLqgePniS4VgHLwf11EpfwswW1xwFJSLYZQuuzNs/7qLvTN5KSpoWbeTt7Yrr1bCWVQJp8QocDg8gFoLS3kFPArnO8qvAowWHK2Hx1IAhMktI+AqCrz/ioJCUMZEv3JB1mf1Unz+Atxl3nvUGKDpPx6OXz9DWVEp3E7vY4Ci4KB4l4rF5oYrTJ+VVThBs3wZh5t/+a4oq4S61yh+ERzvgHKlk4FNUpfUHVdu9YCx8L81VcdBKC4NfLzX1++juRGJ/UDTVEhDuVZROunp6Sgq8tkfxcXFSE1NRVJSEiorK+HxTvUvKipSdAk1N9q1iMWwvi3F7d1Hr+CEaaSvAMcBdPUfbALuc/vEUEkBOj6dr9fPPUTHmmTbKr8Zj568w3Ad+yEgWoat8LcXeaQzeAN80xRkWRAFHz5rvQrb98sDJ4ABvuRerCcwCsivHtGdJE1P4bSCUuvBOYOMOdgrQWn0oLQxfCqFmsycpSiAUYO1lQfP+x4E6/qX+XBPtQ6x9y8H43WJOA9sBFdeADqtE4zT3pS4dKowsUhaRkip7HZAN/huxN7vGwOjdHGy06TGFJPUGhRFIWbGSuiGP1iteyJEPrUS/IyMDGi1Wuzfz4fCbdiwAUOHDoVarUZWVhY2b+bjn9evX4+hQ4fWvrWNDEPTmD66m2zf8l/d+CPzzwC8k5qqGE+s6nJdgC/W/uPKwGtK1wSVpHmgxQUkvPW1C1yVhzIkgHX4TUSqDCL45hLfw8Bf8N0ueUoHr1A7D2fD/cce2LKXBtYrGRMImsZBEFnBhy+Nv3dYQam1gNuuOHjK2Sv4fOw6I+CwKkfMSFAcNFVpQenjwFnL5fcXsiK/N1dvdIsg7J5L/JqyTFJr0IYE36CtUq6YgLo0AZ+VMlkqhUSqe46E7pbHfBOpVJrAvDWEqKdG34iZM2fiyBF+OvzixYvxj3/8A6NHj4bVasX06dMBAPPmzcPatWsxZswY7Nu3D08++WSdNbqpMO/+awEAG3/zxmyzgYKv7jlCnGgj299xIHQ3PxL2GvxiD97JKZLcPELUBQBo+o0HndDS/1SAZsD6zzwNkvLWvn0VLJ/O4dMT+OeIcTt9E74YtRitI4id58opWDctEss79q+H+9IJWR2e0jx4hAySQr3CjGRxvoFk4NhpBdQ6voyS9e1xg9IYvMntOIDzgMnoATq5NWi/BTL0o2ej/dxPoe4tz2UDlwOUMRFsRaEvu2UY6CS/MQBvNEtAigKv31zcrzD4api8ELphMyXn+B5KQr54pQFNJcHXDZkKdYdrw7afEN1U2Ye/bZtvbdb33vO5Hbp164YvvvgioHxGRgY+/PDDWjavadM2PRbjh7TDod/4iT82hwtaP8FnUtpCN2QaL5rmUjFvCmVMDB4xI4HSxYKOTwNbfgWU1igO3ArJrFQdroX22j/BU6aQAsLtFP3uVKyJzzMTJFWBgG3TIngKTvvV4xDbSunjfK4YiUUq5HZhzSVw7l8fUK/1C375vtgHV/PlPS6fwIvzDSQPGoeF96s77cppJwDA69IRYFpmQttvHKzfviEv530w+b8VARxU6V3gPLRZaaViRejElmBLfLOvKa/rxT9mXXijCOXSYRJbgklsKbrxpHlnVB2uhSHmBZmxQMen89+DGuSDJxAAMtO2RuhGPA7dLY8CACZc3w4zxvH+88JSC5zCeK2w1Jt3piOl0oBOSBetT9qY5It9DjWgrdKATmnLF9P5XDoUrULMjBXQ3fQwvy1ZRk/d4xYAvOUsWPi6G2fI86UHQRR7iQuCt/B5lwdliPeFZUosbyHJl+DSCIc0BYIshYRaDzqlLXRDZ4BS68C57YpjBAC8PnxJnwhWtZ/7RBDjACscANM6+MQ6QLIyk7DtN7gbNF7dK/BMchuo2vUHo/CWF6oNFEWBSesk888bbnsRxjtfC9leAiEURPBrgLp9FtQdBgDg/fqt2vGicJTrBLuLtxVdwpKqflPj9aNnQzfiCblQKQiReIxRi7nF/dMtUyqtaO1Jl9HTDvGG+7mdcJXwlj+l1oNOalWNm5QsBuN2wOOdO0AbEgCPC67Tu+A84Eu6Ruv5iTOeK6dCVus4uAkcy8ry7bNXr3gtfhcotRbGSQv4MQm1DpzTLl7bH0qtl7s3BLeJvzUt9JGk//SjnoR+zBww6V2h6T9RubEaPbSD7pLt8o/mQRjBpzR66EfOkqzwFIh+5F8RM/3toMfFa2uNoBMCc9gTCFWFCH4dQOvjEDNjBSY/+gg4b5d6OK/f3U8QaH0c1N5cJULkDR2fDuOU15UrV2nACBa+ME0+Lk2xnABFUQCjgfvCQRRnr/SeqwMTRPANE56HuttQ8U0CACjJVEnX2T1wnfhJbCtnq1QcYAYU8u/44dzzBawbX4X7wiFvu7Vgi3Nh3/EBn2JB8uCi1FpwtnI4dn2kXJlGJ1+gRhB6v8FKn4XvE3xV275QterBL5iddTufwdLPHUdpjWKddGJL0Kb2YNK7yGfSBks/UI3QXIpRVSM3DYFQc4jg1xGUSguKoqA18j9c2uttLzRz2HeiUDnHjRB9QlGg40zQjQxcQpFSacCkd4G6+03i7Et1l+sC6/KzaimVhp9ZKqDW+axTP5Fi0jtDN3QG6IQWvqZJp3lJZxMbE+ViptKCTmzlG4CtQngjW3CGX1aPYsS63ad2wH3mV1AqaWiiLmROHkpjkEUuia4cr8tJ02cMtNdPF+8rlKgy6Z3lEVEAf23v/4jSxsB4+zwwKW1hGC/JXx8sKqsquYQIhAaGCH4dkzzxaWj6T4RbzYvLki9ysHx9Dj7+7jSWfn6IX0VLQHgIeEVD3e6awApVGlAqDXTXT4eqVU8YJr8CTb/xAcUCJrb5DyJq9FB3G8rnR7/lMcW2y+K7FYRb03ds4LKNjAp0ShsxF1B14tmpmMTAnbIl9HzuMFX7rMDz/Xz44kPPm/KAik+DpvtNvvKhViCTnu9NR8DZKkB5XVXSlZ2Y1I7QXj/du+V7MErdPVXKFkogNDBE8OsYOi4V2qzbETfszzBrTBg6uAcyUoz44feLOHy2BEfPlfqsfYmFHwz/+HFhYk04AlwNjAaUSgvtgMlQtekD4/RlCudIrsV6YLjzVdDeFY7UXW+AdsAdoAwJ8pOcdt5tJUyQqo7g6+IC6pPFoksHohVS9VIaPT+GIYyTeH34QhRRwIBqmOyPwrWZ5NbQDLgTumEzwSS2hOHOV6HpL3/IinVL3twM458Fk9aZ3yAWPqEJQpaZqSf0HfpC36EvxoP30X71Mx/n/dYXfAKw5DgdstI9GAOAadEteEXVSFHLZHT3RYN4xU8VbwISAx8SytauvAyT0BK0MRFsca4vukjvZ+FzHt8aqqimha81QH/rbHguHoV927/5ndKQQ4lg0/EK4xZCBJQ2BpzT5ssZI8wT8BP8sA9K4eGq0kDbd4xvt9IcB+FaEsGn41Khve4eWL+aB6ZF18BzCIRGhgh+A9CrQzK++vkPxBs1sDs9cLg8KKmwY0sFsJ++Df9UWFtXe909YEvyFNPjBsMw9hnxszBrNX7QRDjbXh9QVkn8Atw1gPjAYUwdlMuotLwws25+0pY0FQKjCpk7n9IaQetiQXcaBM5hhmPnGlksPp3oywMkLNCh7nEzXEd/8O6LFevhKosCXDrVeVhKy9P+ywoqt15xL5PSFsbpy8K7jwiERoAIfgPQNj0Wc6f1R4eWcVAxNC4UVGL++3yStGI2Do8v/QWLHx0Cvdb372AyukPjjaevEd7BUMYQF6agD3X34QDNwPHLB1B14R8SlEoL0CoxpJNS6wCKAqWLg3bAZNCpHeHJ5xcXsXz0FOCyQd39JkClgabPGLiO/whPwVlZamMBpdBUaR59cRCVYkCpNIh9cDVY61VR8GldrKweYdBWSJWslE5B3XOELIRV1h7vQ5AKEUIZSOBgPB0izJZAaEyI4DcQ0qUS26TFQqth4PDO0rI53Nh7ohBD+/hcB1VZMCMUwmQmRh9cfLTX3ycL1aRoFTTdb4I6c7gofuoeN4PJ6C5beck4dQkoXay4jy3i3VVC7noqJkV0iWj7T4Rta+B4AQDZ+gGiRSzxfVMUBeO9/5Ll31fKSRMwm1VIpKaQzkAnzFFQQFhdqyr52YWHkdLYAoHQVCGDto1EiyRe7Bhvds1PfjiNU3lXfQVqKfiCcNIhLHxN9+Fg0jsH7JdlX0xpC3WnQbLjtDFRvvSeWj65jNL4DZZK6lO1uwaqtnyiN7mFz4u2f7IwWh8nn93qrVsrEW6xHm+b1D1u5s/1yygaDlZ8YIUXfNqYiNgHV0MVZqYugdCUIBZ+I/H4pF44mluKG3q3RGmFHa9/cgDvrs/BAi0FChzyim1o2yah5hfwWrmMPhao5whB/4dGQHSMN+xUO2Qa1N2Hw759Fb9fK7HwBSs9TDgjRavEfDziPsGl4xV8Tbcboel2Y3VuAYDkDYUst0eIUIiF30gkxelwQ++W4ufH/9QbFAUI673889McHDilnMq4OtCG+vcn0/o46MdLUiD7Cb6mzxhAa4SqwwDeJeONbJEt9u0V/HBL4ikhuoNq+Vak6cUvyRmYZI1AiAyI4DcRMlKMeOWBgSjN4AdLHSyFZV8dwSv/24er5uqb6GqvhUtXN1KlhqhadPWtw+q3GAljaofY+97xLVTtN+EM4AeH9ROeh37E49W+NtO6F1SdBgfOEagmmu43IfbB1UEHdQmE5g4R/CaEUadG+7EzEPPAf7FgxiBoNQzOXa7Az4f4BGhWuxsrvz6K9zcfx6/HroSsS3vD/Yh54D8N0WwRIZUvpTGGLCeEWPov+q5K7yyfOVtFmMSW0N/0EEkbTCCEgfjwmxgURQEUhVapMVj08GC88r99WL/jHOxOD+IMGvx6jF/3dcfhyxjUPXjmRL6ehhVATZ9bwaR2gKplZshy2gF3gE5qFTY1MYFAqFuIhd+EiTVocEsW79PO/u0C1v54Rnbc6fLgbH45vtmdq5ycrYGhKDqs2AN8ygRN5rAaLWxPIBBqDrHwmzgjslrhxr4t8ePv+cgvMkOtorH9IO/iWb4+B4fPlgAAOraMR7e2VZkhSiAQohWKq4JpuHHjRrz77rtwu9247777MG2aLwb6+PHjmDvXly62tLQU8fHx2LRpE9atW4c33ngDycl8XPOwYcMwe/bsKjeupMQMlq2+5WoyxaKoKHRe9uaMzeHGY2/+DABQMRTcHr6PZozJRN/OKTBoVSi3OJEQo0FqalxE90VVifTvRHUgfcETif1A0xSSk4On9Qhr4RcUFODNN9/EV199BY1GgylTpmDgwIHo1ImfaZiZmYkNGzYAAGw2G+644w7Mnz8fAJCTk4O5c+di3LjAXDGEmqPXqjAgMxV7jhfi9UeGoNzixCv/24f/bpYvL/jUnX2Qmlr11AoEAiGyCevD37VrFwYNGoSEhAQYDAaMGjUK2dnZimVXrFiBa6+9FllZfO7yI0eOYN26dRg/fjyefvpplJeX123ro5gZYzKx6OHBiI/Rok1aLB6bFDgAeu5yRSO0jEAgNFXCCn5hYSFMJt8U9dTUVBQUFASUq6ysxNq1a/H44744apPJhEcffRRff/01WrRogZdffrmOmk3QqBmkJPhSGvTtlIJ3Zg/FsH4ZuG80n5r3QqEZH2WfgNXuClYNgUCIIsK6dFiWlUVTcBynGF3x9ddf45ZbbhH99QDwzjvviJ8feOABjBgxolqNC+WLCofJFJ0ZC/92D/92deiPUuw/WYT9J4uw8/AlxBk1+Otd/dAipfpx7pFCtH4nlCB9wRNt/RBW8NPT07Fv3z5xu6ioCKmpqQHlvv/+ezz00EPidmVlJb788kvcf//9APgHBcNULy6cDNrWnBaJehz0fs4r4Pvi/a9zUFZpR6XNhXZpsbh9aAdsP3gJ13ZLRUq8TpaeOdIg3wkfpC94IrEfaj1oO2TIECxbtgylpaXQ6/XYunUrXnnlFVkZjuNw9OhR9OvXT9xnMBiwatUq9OvXD3369MGaNWuqbeETas64Ie3Qu2MyEhON+OVAHk6cv4rdR32zc/OLLDh9sRyFV23YtCsXfTulYNbk3o3YYgKBUN+EFfy0tDTMnj0b06dPh8vlwuTJk9G7d2/MnDkTs2bNQq9evVBaWgq1Wg2t1peDhGEYLF26FPPnz4fdbke7du2waNGier0Zgg+9VoWubRJhMsUiNVaDMxfL8em20xjcIx3d2iZi8ScHUHjVJpY/ffEqrpod+GzbGdx2fXukJRlC1E4gEJojVYrDbyyIS6f2BOuL7Qfz8UH2SaQlGVBQakVSnBbX9WyBjbtyodeqMOG6dhiR1Ro0TYHjOJy9VIGOLeOa7exY8p3wQfqCJxL7odYuHUJkMqxvBjplxCMhRott+y9i/S/nsHFXLjRqGhkmIz7bdgZOlwftW8Qhr9CMz7efxWO398Q1XQPHbwgEQvOACH4U08rEWwKJcT5X3Lz7r0V6kgGvf3IA63ack5XPL7Lgmq4N2kQCgVCHEMEnILNNItKTDJg5vjtaJPNhm4/e3gu/HSvAkT9KxHw96385h20H8qFR0bjrpk7E2icQmhlE8AlISdDj1Qfl69bG6NW4+ZpWaJceKwo+AFRY+DVnt/2ej99PFePw2WKwHDBtRGcM6dmiQdtNIBCqB0mPTAhJ61T5ANDiR4cgzqjB8fNl2H30Cix2N2wON1ZtOo4Psk9g/8lCMVXzhYJKWO1upWoJBEIjQCx8Qkg0agYPTuiOlDg9EmI0SIrT4ZouJvx4IB9tUmPw9N398EH2Cew7WYTtBy9h+8FLeOquPii+ascHW05iUI80PDi+R2PfBoFAABF8QhXwX1kr3sivk9u+ZRxi9GokxMrXgF3y2SHx897jhZgxJhNllQ4s+/IwhvfLwPD+req/0QQCIQDi0iFUm5QEHQAg07vgStfW/N+50/qLZe4Z2QWPT+oFD8thV84VLP70AC4WWbD2x7M4dKYYl0ssDd9wAiHKIRY+odoM7pEOU4IenTLiAQDXdDVhyePXISFGi8nDOuJU3lUM75cBD8shRq/G6m9PQK2i8dCEHljx9VG89cVhUBTw/L1Z6NAyDi43iy+2n0WF1YmHJhD3D4FQXxDBJ1QbiqLQuVWCbF9CDO/WGTOoLcYMaguAX41r1IDW+PFAPv40tCMGdk+Dw+XBsdxS/H6qGG+uPYiHJ/bE0s8PweOdUT1zfHfQzXQ2L4HQ1CGCT6hXxg5uh7GD24nbQ/u0xNA+LbH/ZCGWr8/BG58dlJUvKrORPD4EQj1BfPiERuGarqmi+0ar8aXNvlBohtvD4uSFMnGfy+3B8dxSHDxT3ODtJBAiCWLhExqNAZlp6NUhGXqtCi63B08u24kPt5zEu+tzAAADu6chVq/G9/sviueseHoY1CpipxAINYEIPqFRERZdUasYPHVnH2z45RxyzpUCAH47FriU5qtr9qNr6wRcm5kKt5tF1zaJDdpeAqE5QwSf0GTomBGPp+7qiwqLE59uO428QjOm3dIFAJBhMmLO8l04f6US569UYuvePADAbTe0h8fD4fahHWC1u5FzrgTpSQa0TDFCxZA3AQJBChF8QpMjzqjBzHHdwXIcGNon2ncM74SPvjslK7vem9Hzpv4ZeP/bE2Len94dkzH1ls5wulgczS3Fb8cL8X9T+0Grrt4ymwRCJEEEn9AkoSgKjF945s3XtMLgHmnY8EsuvtuXJzu2dW+eLMnb4bMlsm0AOJtfDpebBUUBvTum1F/jCYQmChF8QrPCoFPjrps6YWifFmiZYoTbw2Hp54fw7W8XQFMU2BALuJ29VIF1P/8BAPj3326Ehlj7hCiDODkJzQ6appBhigFFUVCraIwb0g6tU2Pw5J29ce/ILujVIVkse1P/DLRvEQsA2LgzV9y/6JMDcHtYALzlL3wmECKZKln4GzduxLvvvgu324377rsP06ZNkx1/++238eWXXyIuLg4AcOedd2LatGm4dOkS5syZg5KSErRv3x6LFy+G0Wis+7sgRDWZbROxYMYAfqM9xORs5RYn4gxqUBSFEosLc5btAAAYdSr8cakC2w/ko32LOCz8cD9u6N0Cfx6T2Vi3QCA0CGEt/IKCArz55pv4+OOPsX79enz22Wc4c+aMrExOTg6WLFmCDRs2YMOGDeIDYcGCBZg6dSqys7PRs2dPLF++vH7ugkBQIN6oERdd79YuSdz/6G09AQAff38aCz/cDwDYcfgydudcAQD8fOgSnl35K34/VQSX24OySgd2H73SwK0nEOqesIK/a9cuDBo0CAkJCTAYDBg1ahSys7NlZXJycrBixQqMHz8eL7/8MhwOB1wuF/bu3YtRo0YBACZNmhRwHoHQkDwwLhN6LYMOGfHo0c4Xvz+sXwZamYx4b9MxvLpmP1Z/ewIFpVa8/dURbNyVi0Uf/473Nh5DpdXZiK0nEGpPWJdOYWEhTCaTuJ2amorDhw+L2xaLBZmZmZgzZw7atm2LuXPnYvny5Zg2bRpiYmKgUvGXMJlMKCgInEhDIDQUQ3q2EJdh/OsdfcBxgNnmQmKsFvtO8Ll9zlwsB0NTYjK3TbvOi+f/9V+/YO60/uiYEScLFyUQmgthBZ9lWfG1GAA4jpNtG41GvPfee+L2jBkz8Nxzz2Hq1KmycgACtsORnBwTvlAQTKbYGp8baZC+4AnVD7ckGnCuwIxeHVPQsVU8Kq1ObNxxDj8duCgr99pHvyPWoMHN17bG9DGZUKuaZ6QP+U7wRFs/hBX89PR07Nu3T9wuKipCamqquH3p0iXs2rULkydPBsA/EFQqFZKSklBZWQmPxwOGYQLOqwolJWawbPAwu2CYTLEoKqqs9nmRCOkLnqr0wx03dvB+4pBkUOPeEZ0xYUhbFJRaseiTA2K5SqsT6386i/yCSowe2Aa/Hi1A93aJyPmjFEP7tgxYB7ipQb4TPJHYDzRNhTSUw76XDhkyBLt370ZpaSlsNhu2bt2KoUOHisd1Oh1ef/115OXlgeM4fPTRRxgxYgTUajWysrKwefNmAMD69etl5xEITR2appAYq0W3tj5///P3XoOxg9vixr4tsfdEIV753z58ty8Pb31xGD/8fhHz/rsHTpcHAJBfZMY3u3NJyCehyUBxXIiZKl42btyIFStWwOVyYfLkyZg5cyZmzpyJWbNmoVevXtiyZQuWLVsGl8uF/v37Y8GCBdBoNMjPz8fcuXNRUlKCFi1aYMmSJYiPj69y44iFX3tIX/DUth8ul1igVtFIidcD4N9kD54pRvFVO7q3T8KLq34Ty7ZvEYsKixMlFQ4A/KDw9FFda3cDdQj5TvBEYj+Es/CrJPiNhZLgezxulJUVwe0OHjFB0zRYNjKsKpVKg8REEximZpOiI/FLXRPqux9y/iiBUa/Gu+tzUFxulx2jAMwYm4mfD13ChQIzRg9sg4nXt6+3toSDfCd4IrEfwgl+s0utUFZWBJ3OAKMxPeggsEpFw+1u/oLPcRwslgqUlRUhJaVFYzeHEIKe3tm9z0zth99PFaNlsgFL1h7CwxN74Kuf/8B/vjkult3wyzlktk3E1zvPwaBT48Hx3WWZPc02F2L06ga/B0Lk0+ws/CtXziMtrU3IiJ9IEXyAF/2CggtIT29bo/Mj0YqpCY3RDw6XB1o1I07c6to6ASqGxt8/2AeNmoHN4RbLPj2lL+KMGnyx/SwOny3BHcM7YuS1reFwstCo6TpN9Uy+EzyR2A8RZ+ED1Q/vbM5E071GGkIq5sRYrbiwOwD06pCMg2eKoVHTcLp4w2Txpwdl537+41kcOFWMM/nluKarCY/d3gtWuxtvfn4Qg7qn4+ZrWjXYfRAiBzJ7pBaYzWY8++zTVS5/4sQxvPbaK/XYIkJzYNLQDsgwGTFmUFu89vBg3DOyC9QqGq1MRjwxqRfe/duNuHN4J5zJLwcA7D9ZhE9/OI2VG4/ibH4F9p0oxMHTxSi6apPVezy3FD/sv4iySkdj3BahGdAsXTrh3BsN5dK5fPkSnnjiIXzxxcZ6vU5V7jkYkfjaWhOaej+43CwYhgIteaNb+OE+nM2vkJVLideJg8JxRg1eui8LibFaAMBf/vmjWG7O3f2Q2TYRZZUOrNl6En8ekymOCzT1vmgoIrEfItKl01RYuvR1FBcX4dlnn8b58+cQH58ArVaLhQsX4R//eAVFRYUoLi5CVtYAzJ37Ig4c2I///ncl3n57JR5//EF0794Dhw4dxNWrZXjyyTkYPPi6xr4lQiOhtDD701P6wWJz4UqpFet+/gOdWyfAFK/Dh1tPQcVQqLA48fTyXUhL1EPld37OuRJktk3ED/sv4sDpYrT7/SLGX9d4kUGEpkGzFvydRy7jl8OXA/ZTFFDb95bre7fAdb1CR8Y8+eQcPPHEQ5g16ynccccEfP75MrRo0RLffZeNzp274O9//ydcLhfuuecOnDx5IuB8l8uNFSvexy+//Iz33nuXCD5BhlbNQKtmkBSnQ3dvts8KixPHz5fh7lu64G/v7AQAFJTxrh29loHNwU/62nHoMg6eLka7dD51wLod56DTqHBLVitwHIf3Nh7FgMw09OlEVv6KJpq14DclEhOT0KJFSwDAiBGjcexYDtau/Ri5uedQXl4Om80acM7AgYMBAB06dERlZUXAcQLBnzijBo/e3gsAv7jLzpwreOfJobhSakVCjBaPL/0ZAB/aaba5cLnE97375IfTSE82oI9Wjd1HC7D7aAH0WhVam4x4bFIv0eVDAgUil2Yt+Nf1UrbCGyMsU6vVip+/+OJTbN++DRMm3I7Jkwfg3LmzUBoq0Wg0APgfWBMeSiE0UaaO6IIpN3cGTVNomcIvLLT40SFgWQ7P/Hu3rOxtN7TH+h3n8ObaQ7L9Nocbpy6W4/PtZ/H7ySJ0aBmHG/tm4EqpBbcObAuaJuIfSZAonVrAMAw8Hk/A/r17f8OECZMwcuStcDqdOH36VMTM/CU0HWiKCojPT4rTISVBj38+PBh33dQJAJCaqMeE69qjS+uEoHX9cvgyrA43cs6V4p11R/DlT3/gm9254hrBbg+LkxfKcCrvKv76rx2otDqJkdIMadYWfmOTlJSMtLR0vPrqAtn+O++cisWL/4E1a96H0RiDnj174/LlS8jIILHThIbBlKDHzde0wsHTxRjal3c1PnJbT1hsLvz32xP4wxvyGYzEWC3W7TiHXTlX0KtjMmwON3Ye8a36dSa/HDsOXQbHcfjrHX3q9V4IdQcJy2wGkLDM2kP6wUdCogGnz5Xgu315uKF3S2jVNDbuzEWHjHh8uOUkAODhiT3w7w1Hg9ZxS1YrfL+PXytgzt39kBynRWqiAUfPlaJteiw2/3oe1/VMh8vD4suf/sCsP/VqcmsHROJ3goRlEggEGWoVA1OCHlNv6SLu+8u47vCwLD7cchIjr22NAZlpUKtoLPvyiFimfxcTfj9VBACi2APA658cQHKcFrcP7YBVm46jdWoM8grNyP7tgljmQqEZHVsGZsotKbcjMU4rm39AqD+ID59AIAAAGJrGiqeH4U6v7793x2R0bBknHr9jWMeg55ZUOLBqE58gLq/QHHB84Qf7cfRcqbh91exAucWJOe/uwtptZ+rqFghhIBY+gUAQkU4AY2gaz0/Pwo5Dl1Ba6UBakgF/m9IXO49cxq9HC5DZNhFpiXoM6pGOb389D4fLA7vTg9wrym6S7D28xf/2V0fgcHkwqHsaAGDr3jxMublz/d8cgQg+gUAIzQ19Woqfe7RLQvv0WJRVODDy2tbixC0hAmjp53zY560D22DnkcuosLrEc4+eK5VZ+b8eKxA//3tDDm7q3wpJsVpQFIXkeB0A4GKRGdsP5GPCde0RZ9TU2z1GC0TwCQRCtTDo1Pi/af0Vj905vBO0agYTrm+PO4Z3wi+HL+O/m4/Lyjxzdz98vv0szl32TTbcc7wQe44XAuAXjJk5oTv6dTLhsx9O42huGc5cLEefTimIj9FgcI906LUqOF3820SHlnEoLLPh91NFGDu4LZk4FgIi+AQCoc5omWLEI7f1FLev790Ca7aehNPNIs6ogd3hRtc2CejcKh7nLleAoSl4vJF41/VMR+fWCdh15DJWfn1MVu+FQjMueMcGHE4PRlzbGq+u2Y8LBWZc2y0VF4vMuFxiRd9OKWjVxBeRb0yI4BMIhHpl8WPXgeU4MRKHoij06ZSCQ2eKMeG69nhvEy/ufx6TCZqm0KtDMt5cewgXi8zo0joBAzNT8eHWUwAAFUPh8+1n8fn2swD4SWV7TxSK1zp0tpgIfgiqJPgbN27Eu+++C7fbjfvuuw/Tpk2THf/++++xbNkycByHVq1a4R//+Afi4+Oxbt06vPHGG0hO5pd/GzZsGGbPnl33d9EMWLhwPvr1uwZjxoxv7KYQCA2K0nKNmW0T8Y+H+FxSguALaRwSY7V4+S8DwHIcKEDMB3Rz/1YotzqxzyvwGSlG3DOyC/758QGx3i9/+gMnzpdh8rBOsDncOJl3FYfPluCZqf1AAdCo624uwMVCM2KNGsQ3o7GFsIJfUFCAN998E1999RU0Gg2mTJmCgQMHolMnPnTLbDZj/vz5+PLLL5GWloa33noLy5YtwwsvvICcnBzMnTsX48aNq/cbIRAIzZPXHh4MJa+78EbQMsWIZ+/pj/Yt4lBW6UB6kh4nzl/FncM7oWWKQSw/IDMVe44X4mhuGY6u3iura9ZbO+ByszBoVWhpMuLWAW0wxKiFy83ip4P5+OngJQzvn4HMtolITzJUaRzgpf/uQUKMBksev17xOMdxOHHhKrq1SWgy4wphBX/Xrl0YNGgQEhISAACjRo1CdnY2Hn/8cQCAy+XCvHnzkJbGh1h17doVGzfyC4IcOXIEubm5WLFiBbp27YoXX3wR8fGBky+aK889NwcjR47GsGE3AwBmzLgHTzwxGytXLofDYUdlpRmzZs3GDTcMa9yGEghNmNQEfdgynVslAOBTRkwaqjwfYMS1rbHneCG0GgbX9UzH2fwKnC/gQ0TjjRr072KC28Pi+PkyLPvqCJZ9dUS2oMwar9soLVGPu2/pDLWKEcV674lC2B1upCcb0CkjHlbvesRXzc6gbd5x+DJWf3sCD0/sgQGZaVXuj/okrOAXFhbCZDKJ26mpqTh8+LC4nZiYiBEjRgAA7HY7Vq5ciXvvvRcAYDKZMGPGDPTv3x9LlizByy+/jDfeeKPOGu86tROukz8H7K+L7JPqrkOh7hI6P/2oUWPw3XffYtiwm5GXdwFOpxNffvkZ5s59EW3btsP+/Xvx1luLieATCPXIXyf3hk7DoGPLeDxzdz90ahUPFUOD4zicyruKTq3iwdC++QUuN4sdhy9hzdZTKC63w6BV4Y7hHfG/bD6tREGZDUs/5zWOooCBmWmyENKb+7eCRuOrr8LihN3lQUq8TjZjOK+AH2QuqbArtpvjOJy9VIF26bF1ukh9KMIKPsuystcRjuMUX08qKyvx2GOPoVu3brj99tsBAO+88454/IEHHhAfDFVFKSdEYSEtru7joamgr0q1fYWiaSpgFSF/hg4diqVLF8HhsGHbtq249dYxmDJlGnbu3IGffvoBOTlHYLPZoFLRoCiqSnUqt4WGyRRb01up1bmRBOkHH5HUF7dI7sX/vlJT4/yLAwDuahGPHp1MeHb5Tvzpps7o3cUEeAVfSotko0zsAeCH3y/Ktp9c9gsAoHv7JLz2GO/euXClEpx3TIJmGJhMsTh/uQL//HAv7r21Owb3aoEdB/KxaM1+9OiQLJ5X34QV/PT0dOzbt0/cLioqQmpqqqxMYWEh/vKXv2DQoEF47rnnAPAPgC+//BL3338/AP5BwTDVGzBRSp7GsqyYGI3pNAT6TkMCb6qOkqeFq4OiGAwZcgN++mk7vv9+K15//S089NBf0L//NejX7xr065eFBQtegNvNguM4sCxXo3axLFvjJE+RmCCqJpB+8EH6gqdnxxQsmDEArUxG2LwuGgB4ecYAvPTfPXjqrj7o1iYR63b8gfbpcVi+PidkfcfOleLO575Bz/ZJ2HeySNz/2fenoKaBw2dLkFdgxqur9+CG3i1EV9LRP0qQl18Gnab2QZO1Tp42ZMgQLFu2DKWlpdDr9di6dSteeeUV8bjH48HDDz+MW2+9FY8++qi432AwYNWqVejXrx/69OmDNWvWVNvCbw6MGjUGS5e+jvj4BBgMBuTlncc777wHjUaDd99dRvLgEwhNmNbeEE6DzhdJ1Co1Bu89M0x0A90xjA9QefKO3jDq1IjRq3HkjxJ8/P1pWV1t0mJwocAsE3sBYXwgzqBGhdWFHd6lWVMT9Ci8asOFAj4ElWU5bNlzAT3aJ6FNWt2/hYUV/LS0NMyePRvTp0+Hy+XC5MmT0bt3b8ycOROzZs3ClStXcOzYMXg8HmzZsgUA0LNnTyxcuBBLly7F/PnzYbfb0a5dOyxatKjOb6Cx6d27L8xmM267bTLi4uIxbtxE3HvvnVCpVOjf/1rY7XbYbLbGbiaBQAjDU3f1QbyRX7lO6vMX6N3Rt/5vWpIBAzLTsHLjURzLLcMNvVvgz2My4XB6kFdoRrsWscgrNOOtzw+J6SW6tUnAQxN64I3PDuJikQUAcO+ornjjs4N47aPfZdfSqJl6EXySD78ZQPLh1x7SDz5IX/DUVT+wLAdQUEzxXFphR9FVGwrKbBjcI11MTrfneAHOXa7AXTd1xjtfHYHTzeLIHyXieQtnDkSLZGO120Ly4RMIBEI9Emrd36Q4HZLidOjaJlG2f0Bmmhiq+dgkflF6s82Fd746grOXKpCeZAioqy4ggk8gEAhNgBi9Gk/d1RduD1tvE7WI4BMIBEITQa2iZWsS1DXNcsWrJjzsUOdE070SCIT6pdkJvkqlgcVSERVCyHEcLJYKqFTNJzkTgUBoujQ7l05iogllZUUwm68GLUPTdMTEv6tUGiQmmsIXJBAIhDA0O8FnGBVSUlqELEPCzggEAiGQZufSIRAIBELNIIJPIBAIUUKTdumEmtBQn+dGGqQveEg/+CB9wRNp/RDufpp0agUCgUAg1B3EpUMgEAhRAhF8AoFAiBKI4BMIBEKUQASfQCAQogQi+AQCgRAlEMEnEAiEKIEIPoFAIEQJRPAJBAIhSiCCTyAQCFFCxAn+xo0bMWbMGIwcORIfffRRYzenQTCbzRg3bhwuXrwIANi1axfGjx+PkSNH4s033xTLHT9+HJMmTcKoUaPw/PPPw+12N1aT65y3334bY8eOxdixY7Fo0SIA0dkPAPDWW29hzJgxGDt2LN5//30A0dsXAPDPf/4Tc+fOBRDd/QAA4CKIK1eucMOHD+fKyso4i8XCjR8/njt9+nRjN6teOXjwIDdu3DiuR48eXF5eHmez2bgbb7yRu3DhAudyubgZM2Zw27dv5ziO48aOHcsdOHCA4ziOe/bZZ7mPPvqoEVted+zcuZO76667OIfDwTmdTm769Oncxo0bo64fOI7jfvvtN27KlCmcy+XibDYbN3z4cO748eNR2Rccx3G7du3iBg4cyP3f//1fVP42/IkoC3/Xrl0YNGgQEhISYDAYMGrUKGRnZzd2s+qVtWvXYt68eUhNTQUAHD58GG3btkXr1q2hUqkwfvx4ZGdnIz8/H3a7HX379gUATJo0KWL6xmQyYe7cudBoNFCr1ejYsSNyc3Ojrh8AYMCAAfjggw+gUqlQUlICj8eDioqKqOyLq1ev4s0338TDDz8MIDp/G/5ElOAXFhbCZPKtDpWamoqCgoJGbFH9s3DhQmRlZYnbwfrAf7/JZIqYvuncubP4Y83NzcW3334LiqKirh8E1Go1/vWvf2Hs2LEYPHhwVH4nAOCll17C7NmzERcXByA6fxv+RJTgsywLivKlB+U4TrYdDQTrg2jom9OnT2PGjBl45pln0Lp166jtBwCYNWsWdu/ejcuXLyM3Nzfq+uLzzz9HixYtMHjwYHFfNP82BJp0Pvzqkp6ejn379onbRUVFoqsjWkhPT0dRUZG4LfSB//7i4uKI6pv9+/dj1qxZeO655zB27Fjs2bMnKvvh7NmzcDqdyMzMhF6vx8iRI5GdnQ2GYcQy0dAXmzdvRlFRESZOnIjy8nJYrVbk5+dHXT/4E1EW/pAhQ7B7926UlpbCZrNh69atGDp0aGM3q0Hp06cPzp07h/Pnz8Pj8WDTpk0YOnQoMjIyoNVqsX//fgDAhg0bIqZvLl++jMceewyLFy/G2LFjAURnPwDAxYsX8cILL8DpdMLpdOKHH37AlClToq4v3n//fWzatAkbNmzArFmzcNNNN2HVqlVR1w/+RJSFn5aWhtmzZ2P69OlwuVyYPHkyevfu3djNalC0Wi1ee+01PPHEE3A4HLjxxhsxevRoAMDixYvxwgsvwGw2o0ePHpg+fXojt7Zu+M9//gOHw4HXXntN3DdlypSo6wcAuPHGG3H48GHcdtttYBgGI0eOxNixY5GUlBR1feFPNP42/CErXhEIBEKUEFEuHQKBQCAEhwg+gUAgRAlE8AkEAiFKIIJPIBAIUQIRfAKBQIgSiOATCARClEAEn0AgEKIEIvgEAoEQJfw/nzDxGoXLAnEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit model\n",
    "\n",
    "res_history_2 = res50model_2.fit(res_train,\n",
    "        epochs=4000,\n",
    "        validation_data=res_val,\n",
    "        verbose = 1, \n",
    "        validation_steps = len(res_val),\n",
    "        callbacks = [es])\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = res50model_2.evaluate(res_train, verbose=1)\n",
    "_, val_acc = res50model_2.evaluate(res_val, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "res50model.save(r\"C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\Models\\Res50_from_scratch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 5s 19ms/step - loss: 0.8713 - accuracy: 0.6381\n",
      "Test loss: 0.8712734580039978\n",
      "Test accuracy: 0.6381322741508484\n"
     ]
    }
   ],
   "source": [
    "#Performance do primeiro teste\n",
    "\n",
    "test_loss, test_acc = res50model_2.evaluate(res_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 6s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = res50model_2.predict(res_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = res_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = res_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "res50_predictions = pd.DataFrame({'Filename': filenames,'ResNet50 From Scratch': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(res50_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del res50_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>AlexNet</th>\n",
       "      <th>ResNet50</th>\n",
       "      <th>ResNet50 From Scratch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample3-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample4-sperm15.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm17.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample1-sperm2.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>class3\\image_036.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>class3\\image_038.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>class3\\image_040.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>class3\\image_048.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>class3\\image_051.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test  Model_1  AlexNet  \\\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     0        3        1   \n",
       "1     class0\\ch00_p1-pl2-sample3-sperm4.tif      0     1        0        0   \n",
       "2    class0\\ch00_p1-pl2-sample4-sperm15.tif      0     3        3        3   \n",
       "3    class0\\ch00_p1-pl3-sample1-sperm17.tif      0     3        3        1   \n",
       "4     class0\\ch00_p1-pl3-sample1-sperm2.tif      0     3        0        3   \n",
       "..                                      ...    ...   ...      ...      ...   \n",
       "252                    class3\\image_036.BMP      3     3        3        3   \n",
       "253                    class3\\image_038.BMP      3     2        3        1   \n",
       "254                    class3\\image_040.BMP      3     2        3        3   \n",
       "255                    class3\\image_048.BMP      3     3        3        3   \n",
       "256                    class3\\image_051.BMP      3     3        1        3   \n",
       "\n",
       "     ResNet50  ResNet50 From Scratch  \n",
       "0           3                      3  \n",
       "1           2                      0  \n",
       "2           1                      0  \n",
       "3           0                      2  \n",
       "4           3                      3  \n",
       "..        ...                    ...  \n",
       "252         1                      0  \n",
       "253         3                      1  \n",
       "254         3                      1  \n",
       "255         3                      3  \n",
       "256         3                      3  \n",
       "\n",
       "[257 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  2  6 12]\n",
      " [11 11  9 26]\n",
      " [ 6  3  4 14]\n",
      " [24 40 22 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.21      0.35      0.27        31\n",
      "      class1       0.20      0.19      0.19        57\n",
      "      class2       0.10      0.15      0.12        27\n",
      "      class3       0.52      0.39      0.45       142\n",
      "\n",
      "    accuracy                           0.32       257\n",
      "   macro avg       0.26      0.27      0.26       257\n",
      "weighted avg       0.37      0.32      0.34       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix and classification report\n",
    "class_labels = list(test_set.class_indices.keys())   \n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOR TOMORROW\n",
    "\n",
    "Check different loss functions\n",
    "CROSS VALIDATION\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
