{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The current project relies on using CNNs in order to process sperm data.\n",
    "\n",
    "The goal is to develop a classifier able to identify different morphologies of head spearm cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context :\n",
    "\n",
    "Due to our background in the fields of biology and health, it was in our interest to use this project,  to develop our knowledge of neural networks, in microscopic images.\n",
    "The chosen theme is a classification problem taking into account the morphology of the sperm cell heads.\n",
    "\n",
    "#### There are two datasets available, which we have chosen to aggregate into one.\n",
    "\n",
    "- SCIAN - MorphoSpermGS  - https://cimt.uchile.cl/gold10/ -  with 1132 image, each image has 35 x 35 pixels and has been classified by 3 experts. We will use majority vote result as target. \n",
    "\n",
    "\n",
    "- HuSHeM - Human Sperm head Morphology - https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:77214/tab/2 -  with 725 images, each image has 576×720 pixels and have the respective classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>  The sperm cells heads will have the following classification:</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![Title](Heads.png)\n",
    "\n",
    "\n",
    "* We don't include the \"small\" class from HuSHem\n",
    "Ref: https://doi.org/10.1016/j.compbiomed.2019.103342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> The process for adapting the data to use on CNN, for reasons of OS compatibility, has been removed. But can be found in [this document.][mylink]\n",
    "\n",
    "[mylink]: DL_Project_LoadImg.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this pipeline, 4 models were developed:\n",
    "\n",
    "- The first model was produced by us, based on heuristics.\n",
    "- The second model was developed based on the Alex Net network architecture\n",
    "- The third model was based on the Resnet50 model.\n",
    "- The last model was based on an Efficient Net which, according to the current literature, has very promising results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#need this to run keras with GPU\\nimport os\\nos.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\\n#\\n#Check Computer's available devices\\n#Will need to check in the future\\nimport tensorflow as tf\\nfrom tensorflow.python.client import device_lib\\nprint(device_lib.list_local_devices())\\n\\n#cfg 1\\ngpus = tf.config.experimental.list_physical_devices('GPU')\\nif gpus:\\n    try:\\n        for gpu in gpus:\\n            tf.config.experimental.set_memory_growth(gpu, True)\\n\\n    except RuntimeError as e:\\n        print(e)\\n\\n#cfg2\\nconfig = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8))\\n# device_count = {'GPU': 1})\\nconfig.gpu_options.allow_growth = True\\nsession = tf.compat.v1.Session(config=config)\\ntf.compat.v1.keras.backend.set_session(session)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#If you are able to run keras with GPU..\n",
    "\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "#\n",
    "#Check Computer's available devices\n",
    "#Will need to check in the future\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "#cfg 1\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "#cfg2\n",
    "config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8))\n",
    "# device_count = {'GPU': 1})\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from timeit import default_timer as timer\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#image manipulation packages\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "#Classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import Augmentor\n",
    "\n",
    "#Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Callbacks\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras import models\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "\n",
    "## RESNET50\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "### Efficient\n",
    "from tensorflow.keras.applications import EfficientNetB7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Import Images and Dataframe\n",
    "\n",
    "In this case, we have a folder with 1132 image - SCIAN-MorphoSpermGS folder - https://cimt.uchile.cl/gold10/. Each image is 35 x 35 pixels and has been classified by 3 experts. We will use majority vote result as target. Each image will need to be loaded and the dataset will need to be created.\n",
    "\n",
    "#### This will yield a dataset with the picture name and the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv(\"Majority_Vote.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('path')\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ricardo Santos\\\\Desktop\\\\Mestrado Ricardo\\\\Ano 1\\\\Spring Semester\\\\Deep\\\\Deep_Learning_Project\\\\CNN_SpermCells\\\\path'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Normal: 154\n",
      "Images Tapered: 281\n",
      "Images Pyriform: 133\n",
      "Images Amorphous: 708\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count the number of images by class\n",
    "\n",
    "def fileCount(folder):\n",
    "    \"count the number of files in a directory\"\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "\n",
    "        if os.path.isfile(path):\n",
    "            count += 1\n",
    "        elif os.path.isdir(path):\n",
    "            count += fileCount(path)\n",
    "\n",
    "    return count\n",
    "\n",
    "count_0 = fileCount(path+'/class0')\n",
    "count_1 = fileCount(path+'/class1')\n",
    "count_2 = fileCount(path+'/class2')\n",
    "count_3 = fileCount(path+'/class3')\n",
    "\n",
    "print(f'Images Normal: {count_0}\\n' +\n",
    "     f'Images Tapered: {count_1}\\n' +\n",
    "     f'Images Pyriform: {count_2}\\n' +\n",
    "     f'Images Amorphous: {count_3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY WORKS IF TRAIN; TEST AND VAL FOLDERS ARE NOT IN PATH FOLDER\n",
    "\n",
    "classes_dir = ['/class0', '/class1', '/class2', '/class3']\n",
    "\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.3\n",
    "test_ratio = 0.1\n",
    "\n",
    "if not os.path.isdir(path + '/train'):\n",
    "\n",
    "    for cls in classes_dir:\n",
    "    \n",
    "        #creates train and test folders, with each class separated inside\n",
    "        os.makedirs(path +'/train' + cls)\n",
    "        os.makedirs(path +'/val' + cls)\n",
    "        os.makedirs(path +'/test' + cls)\n",
    "\n",
    "\n",
    "        # Creating partitions of the data after shuffeling\n",
    "        src = path + cls # Folder to copy images from\n",
    "\n",
    "        allFileNames = os.listdir(src)\n",
    "        random.shuffle(allFileNames)\n",
    "        \n",
    "        train_FileNames, val_FileNames_test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                              [int(len(allFileNames)* (train_ratio))])\n",
    "        \n",
    "        \n",
    "        random.shuffle(val_FileNames_test_FileNames)\n",
    "        val_FileNames, test_FileNames = np.split(np.array(val_FileNames_test_FileNames),\n",
    "                                                              [int(len(val_FileNames_test_FileNames)* 0.75)])\n",
    "        \n",
    "        train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "        val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "        test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "\n",
    "    \n",
    "        # Copy-pasting images\n",
    "        for name in train_FileNames:\n",
    "            shutil.copy(name, path +'/train' + cls)\n",
    "\n",
    "        for name in val_FileNames:\n",
    "            shutil.copy(name, path +'/val' + cls)\n",
    "\n",
    "        for name in test_FileNames:\n",
    "            shutil.copy(name, path +'/test' + cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 DATA AUGMENTATION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Offline Data Augmentation\n",
    "\n",
    "Options are limited since we're working with microscopy data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Normal: 92\n",
      "Images Tapered: 168\n",
      "Images Pyriform: 79\n",
      "Images Amorphous: 424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#counts number of images in training data\n",
    "\n",
    "train_count_0 = fileCount(path+'/train/class0')\n",
    "train_count_1 = fileCount(path+'/train/class1')\n",
    "train_count_2 = fileCount(path+'/train/class2')\n",
    "train_count_3 = fileCount(path+'/train/class3')\n",
    "\n",
    "print(f'Images Normal: {train_count_0}\\n' +\n",
    "     f'Images Tapered: {train_count_1}\\n' +\n",
    "     f'Images Pyriform: {train_count_2}\\n' +\n",
    "     f'Images Amorphous: {train_count_3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 92 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells\\path/train/class0\\output.Initialised with 168 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells\\path/train/class1\\output.Initialised with 79 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells\\path/train/class2\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=34x34 at 0x20A5D34E970>:   0%|    | 2/6308 [00:00<17:39,  5.95 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 424 image(s) found.\n",
      "Output directory set to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells\\path/train/class3\\output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x20A5D97FB50>:  63%|▋| 3993/6308 [00:09<00:01, 1649.23 Samples/IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x20A5DD13D00>: 100%|█| 6308/6308 [00:10<00:00, 580.21 Samples/s\n",
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x20A5DC62DC0>:  64%|▋| 3998/6232 [00:09<00:01, 1578.70 Samples/IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=118x131 at 0x20A5DA4AD90>: 100%|█| 6232/6232 [00:10<00:00, 592.06 Sampl\n",
      "Processing <PIL.Image.Image image mode=RGB size=131x131 at 0x20A5D4DE220>:  63%|▋| 3979/6321 [00:09<00:01, 1696.93 SampIOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Processing <PIL.TiffImagePlugin.TiffImageFile image mode=L size=35x35 at 0x20A5D58D880>: 100%|█| 6321/6321 [00:10<00:00\n",
      "Processing <PIL.TiffImagePlugin.TiffImageFile image mode=L size=35x35 at 0x20A5D994790>:  66%|▋| 3920/5976 [00:08<00:01IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Processing <PIL.Image.Image image mode=L size=35x35 at 0x20A5DD10460>: 100%|█| 5976/5976 [00:09<00:00, 617.16 Samples/s\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation pipelines\n",
    "class_0 = Augmentor.Pipeline(path+'/train/class0')\n",
    "class_1 = Augmentor.Pipeline(path+'/train/class1')\n",
    "class_2 = Augmentor.Pipeline(path+'/train/class2')\n",
    "class_3 = Augmentor.Pipeline(path+'/train/class3')\n",
    "\n",
    "\n",
    "#rotate by a maximum of 90 degrees\n",
    "class_0.rotate(probability=0.7, max_left_rotation=25, max_right_rotation=25)\n",
    "class_1.rotate(probability=0.7, max_left_rotation=25, max_right_rotation=25)\n",
    "class_2.rotate(probability=0.7, max_left_rotation=25, max_right_rotation=25)\n",
    "class_3.rotate(probability=0.7, max_left_rotation=25, max_right_rotation=25)\n",
    "\n",
    "#mirroring, vertical or horizontal, randomly\n",
    "class_0.flip_random(probability=0.7)\n",
    "class_1.flip_random(probability=0.7)\n",
    "class_2.flip_random(probability=0.7)\n",
    "class_3.flip_random(probability=0.7)\n",
    "\n",
    "\n",
    "# Augment images to the same proportion as existing ones in class 4 (majority class - get to 1000 in each class)\n",
    "class_0.sample(6400 - train_count_0)\n",
    "class_1.sample(6400 - train_count_1)\n",
    "class_2.sample(6400 - train_count_2)\n",
    "class_3.sample(6400 - train_count_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Define Callbacks\n",
    "- Checkpoint\n",
    "- Early Stopping\n",
    "- Reduce Learning Rate\n",
    "- Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset path to main folder\n",
    "os.chdir('../')\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'/Models/'\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0, verbose = 1)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, restore_best_weights = True)\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose = 1,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "cb = TimingCallback()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models:\n",
    "- <a href='#1'>First Model</a>\n",
    "- <a href='#2'>Alex Net</a>  ---- > Alex Net [Model Assessment.][mylink]\n",
    "\n",
    "- <a href='#3'>ResNet50</a>\n",
    "- <a href='#4'>EfficientNet B7</a>\n",
    "\n",
    "[mylink]: Alex_Model_Assessment_RGB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. First Model \n",
    "<a id='1'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'/Models/model_HM.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Preprocess input\n",
    "Online Data Augmentation  in GrayScale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25600 images belonging to 4 classes.\n",
      "Found 383 images belonging to 4 classes.\n",
      "Found 130 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "cnn_train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 5,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1, \n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.5], \n",
    "                                   fill_mode='nearest',\n",
    "                                   zoom_range = 0.2,\n",
    "                                   ) \n",
    "\n",
    "cnn_val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "cnn_test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#test different color maps -  class modes and cross validation types\n",
    "cnn_training = cnn_train_datagen.flow_from_directory(path+'/path/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 64,\n",
    "                                                 shuffle = True,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 color_mode = 'grayscale')\n",
    "\n",
    "cnn_val = cnn_val_datagen.flow_from_directory(path+'/path/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 64,\n",
    "                                            shuffle = True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'grayscale')\n",
    "\n",
    "cnn_test = cnn_test_datagen.flow_from_directory(path+'/path/test',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a model that will take inputs 32,32,1\n",
    "cnn_model = Sequential()\n",
    "\n",
    "#convolutional layer with 32 2x2 filters - output 14 x 14 active area\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(4,4), padding = 'same', activation='relu')) \n",
    "cnn_model.add(BatchNormalization())\n",
    "        \n",
    "#2nd convolution with 64 filters  \n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=(2,2), padding = 'same', activation= 'relu'))\n",
    "cnn_model.add(BatchNormalization())  \n",
    "\n",
    "#MaxPooling - takes the max value of each 2x2 pool in the feature map\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model.add(BatchNormalization())\n",
    "      \n",
    "#the result of kthe CNN is then flattened and placed into the \n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "\n",
    "cnn_model.add(Dense(576, activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "\n",
    "#widen layer\n",
    "cnn_model.add(Dense(1024, activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "#shrink layer\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "#Add Dropout\n",
    "cnn_model.add(Dropout(0.4))\n",
    "\n",
    "#final layer, is output, 1 out of 5 possible results\n",
    "#0 Normal, 1 Tapered, 2 Pyriform, 3 Amorphous\n",
    "cnn_model.add(Dense(4))\n",
    "cnn_model.add(BatchNormalization())            \n",
    "cnn_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 126s 310ms/step - loss: 1.3916 - accuracy: 0.2991 - val_loss: 1.6001 - val_accuracy: 0.1462\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.14621, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 1.2605 - accuracy: 0.4101 - val_loss: 1.4010 - val_accuracy: 0.2559\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.14621 to 0.25587, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 19s 47ms/step - loss: 1.1940 - accuracy: 0.4559 - val_loss: 1.2664 - val_accuracy: 0.3890\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.25587 to 0.38903, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 1.1222 - accuracy: 0.4973 - val_loss: 1.3234 - val_accuracy: 0.3211\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.38903\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 1.0696 - accuracy: 0.5350 - val_loss: 1.2106 - val_accuracy: 0.4334\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.38903 to 0.43342, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 1.0148 - accuracy: 0.5537 - val_loss: 0.9908 - val_accuracy: 0.5692\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.43342 to 0.56919, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 19s 48ms/step - loss: 0.9544 - accuracy: 0.5974 - val_loss: 0.9669 - val_accuracy: 0.5770\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.56919 to 0.57702, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 20s 49ms/step - loss: 0.9359 - accuracy: 0.6032 - val_loss: 0.9611 - val_accuracy: 0.5901\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.57702 to 0.59008, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.9081 - accuracy: 0.6140 - val_loss: 1.0213 - val_accuracy: 0.5405\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.59008\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 20s 49ms/step - loss: 0.8731 - accuracy: 0.6308 - val_loss: 0.9659 - val_accuracy: 0.5849\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.59008\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8535 - accuracy: 0.6485 - val_loss: 0.9499 - val_accuracy: 0.5692\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.59008\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8325 - accuracy: 0.6532 - val_loss: 1.0628 - val_accuracy: 0.5457\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.59008\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8148 - accuracy: 0.6576 - val_loss: 0.9647 - val_accuracy: 0.5666\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.59008\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8037 - accuracy: 0.6659 - val_loss: 0.9299 - val_accuracy: 0.5849\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.59008\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 20s 49ms/step - loss: 0.7694 - accuracy: 0.6811 - val_loss: 0.9188 - val_accuracy: 0.5927\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.59008 to 0.59269, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.7546 - accuracy: 0.6914 - val_loss: 0.8951 - val_accuracy: 0.5901\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59269\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.7591 - accuracy: 0.6869 - val_loss: 0.9602 - val_accuracy: 0.5561TA: 0s - loss: 0.7591 - accuracy: 0.68\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59269\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.7357 - accuracy: 0.6993 - val_loss: 0.8859 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.59269 to 0.63969, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.7231 - accuracy: 0.7035 - val_loss: 0.9379 - val_accuracy: 0.5979\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.63969\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.7021 - accuracy: 0.7108 - val_loss: 1.0001 - val_accuracy: 0.6136\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.63969\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6896 - accuracy: 0.7156 - val_loss: 0.8645 - val_accuracy: 0.6136\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.63969\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6711 - accuracy: 0.7240 - val_loss: 0.8413 - val_accuracy: 0.6423\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.63969 to 0.64230, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.6721 - accuracy: 0.7266 - val_loss: 0.8343 - val_accuracy: 0.6292\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64230\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.6630 - accuracy: 0.7302 - val_loss: 0.8749 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.64230 to 0.66580, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.6510 - accuracy: 0.7347 - val_loss: 0.8972 - val_accuracy: 0.6292\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66580\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.6456 - accuracy: 0.7413 - val_loss: 0.9042 - val_accuracy: 0.5901\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66580\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.6336 - accuracy: 0.7450 - val_loss: 0.9055 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66580\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.6257 - accuracy: 0.7546 - val_loss: 0.8071 - val_accuracy: 0.6554\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66580\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.6289 - accuracy: 0.7478 - val_loss: 0.8197 - val_accuracy: 0.6397\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66580\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.6059 - accuracy: 0.7569 - val_loss: 0.8719 - val_accuracy: 0.6266\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66580\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.6009 - accuracy: 0.7551 - val_loss: 0.8575 - val_accuracy: 0.6345\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66580\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5843 - accuracy: 0.7704 - val_loss: 0.9294 - val_accuracy: 0.6214\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66580\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.5920 - accuracy: 0.7609 - val_loss: 0.9286 - val_accuracy: 0.6110\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66580\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5513 - accuracy: 0.7808 - val_loss: 0.8313 - val_accuracy: 0.6554\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66580\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5305 - accuracy: 0.7926 - val_loss: 0.8247 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66580\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5211 - accuracy: 0.7951 - val_loss: 0.8011 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66580\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5233 - accuracy: 0.7933 - val_loss: 0.8018 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.66580 to 0.66841, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.5031 - accuracy: 0.8006 - val_loss: 0.8408 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.66841 to 0.67102, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.4970 - accuracy: 0.8047 - val_loss: 0.9009 - val_accuracy: 0.6449\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.67102\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.5049 - accuracy: 0.7973 - val_loss: 0.8936 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.67102\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4946 - accuracy: 0.8054 - val_loss: 0.8445 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.67102 to 0.67363, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4727 - accuracy: 0.8156 - val_loss: 0.7779 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.67363 to 0.69974, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\assets\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.4747 - accuracy: 0.8160 - val_loss: 0.7743 - val_accuracy: 0.6919\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.69974\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4750 - accuracy: 0.8153 - val_loss: 0.8195 - val_accuracy: 0.6893\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.69974\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.4538 - accuracy: 0.8200 - val_loss: 0.8738 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.69974\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.4521 - accuracy: 0.8248 - val_loss: 0.8527 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.69974\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4505 - accuracy: 0.8262 - val_loss: 0.8234 - val_accuracy: 0.6580\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.69974\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4470 - accuracy: 0.8283 - val_loss: 0.8292 - val_accuracy: 0.6789\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.69974\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4398 - accuracy: 0.8318 - val_loss: 0.8520 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.69974\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4413 - accuracy: 0.8278 - val_loss: 0.8385 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.69974\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4300 - accuracy: 0.8328 - val_loss: 0.8502 - val_accuracy: 0.6815\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.69974\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.4298 - accuracy: 0.8329 - val_loss: 0.9004 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.69974\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4221 - accuracy: 0.8359 - val_loss: 0.8402 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.69974\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4179 - accuracy: 0.8413 - val_loss: 0.8368 - val_accuracy: 0.6919\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.69974\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4104 - accuracy: 0.8413 - val_loss: 0.8327 - val_accuracy: 0.6945\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.69974\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4168 - accuracy: 0.8390 - val_loss: 0.8355 - val_accuracy: 0.6945\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.69974\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4164 - accuracy: 0.8356 - val_loss: 0.8411 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.69974\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4163 - accuracy: 0.8429 - val_loss: 0.8415 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.69974\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4042 - accuracy: 0.8441 - val_loss: 0.8457 - val_accuracy: 0.6815\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.69974\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4001 - accuracy: 0.8461 - val_loss: 0.8403 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.69974\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4206 - accuracy: 0.8387 - val_loss: 0.8335 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.69974\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4079 - accuracy: 0.8417 - val_loss: 0.8446 - val_accuracy: 0.6815\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.69974\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4079 - accuracy: 0.8431 - val_loss: 0.8398 - val_accuracy: 0.6893\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.69974\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(cnn_training,\n",
    "        epochs=200, \n",
    "        validation_data=cnn_val,\n",
    "        verbose = 1, \n",
    "        callbacks = [mc, reduce_lr, es,cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 21s 52ms/step - loss: 0.4058 - accuracy: 0.8441\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.7743 - accuracy: 0.6919\n",
      "Train: 0.844, Val: 0.692\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, train_acc = cnn_model.evaluate(cnn_training, verbose=1)\n",
    "_, val_acc = cnn_model.evaluate(cnn_val, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, None, None, 32)    544       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 576)               9437760   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 576)               2304      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 10,308,916\n",
      "Trainable params: 10,304,876\n",
      "Non-trainable params: 4,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8901 - accuracy: 0.6692\n",
      "Test loss: 0.8901058435440063\n",
      "Test accuracy: 0.6692307591438293\n",
      "\n",
      "Time: 71.24510394333325 min\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(cnn_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print(\"\\nTime:\",sum(cb.logs)/60,\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = cnn_model.predict(cnn_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = cnn_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = cnn_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "df_predictions = pd.DataFrame({'Filename': filenames, 'Label': true_classes, 'CNN Model': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.88061075e-04, 1.28227351e-02, 7.28834071e-04, 9.86060381e-01],\n",
       "       [1.33537198e-03, 4.61354712e-03, 1.60876720e-03, 9.92442369e-01],\n",
       "       [1.66727370e-03, 9.71686661e-01, 2.35487055e-03, 2.42911801e-02],\n",
       "       [6.60337741e-04, 4.21600882e-03, 9.69563425e-02, 8.98167253e-01],\n",
       "       [2.48732488e-03, 5.96975423e-02, 2.07436308e-02, 9.17071402e-01],\n",
       "       [3.28753702e-02, 2.82424130e-02, 2.25824594e-01, 7.13057637e-01],\n",
       "       [1.64282266e-02, 8.74325752e-01, 8.12870488e-02, 2.79589109e-02],\n",
       "       [1.24779651e-02, 6.82062656e-02, 3.49155664e-01, 5.70160091e-01],\n",
       "       [9.30416048e-01, 5.31042852e-02, 4.36542835e-03, 1.21141858e-02],\n",
       "       [1.68784503e-02, 5.11169314e-01, 4.64708619e-02, 4.25481379e-01],\n",
       "       [1.60670411e-02, 3.20445180e-01, 7.58855557e-03, 6.55899167e-01],\n",
       "       [1.42735215e-02, 4.54640925e-01, 6.25734776e-03, 5.24828196e-01],\n",
       "       [9.71598208e-01, 1.94979191e-03, 1.57854229e-03, 2.48734802e-02],\n",
       "       [6.72269464e-01, 3.41492072e-02, 1.22604892e-01, 1.70976460e-01],\n",
       "       [7.29591921e-02, 6.95035994e-01, 1.95095614e-02, 2.12495282e-01],\n",
       "       [9.95833635e-01, 1.54700805e-03, 7.41727592e-04, 1.87754014e-03],\n",
       "       [7.98955932e-03, 7.11537153e-02, 5.33026084e-03, 9.15526450e-01],\n",
       "       [2.90502119e-03, 6.12114137e-03, 9.89996433e-01, 9.77429678e-04],\n",
       "       [2.26836558e-03, 6.75296724e-01, 2.01046765e-01, 1.21388152e-01],\n",
       "       [8.69511247e-01, 1.05437916e-02, 1.79319165e-03, 1.18151784e-01],\n",
       "       [3.78582301e-03, 8.88012871e-02, 6.31198334e-03, 9.01100934e-01],\n",
       "       [6.75289750e-01, 4.06956598e-02, 5.05142435e-02, 2.33500332e-01],\n",
       "       [8.53381336e-01, 5.91724999e-02, 1.32455991e-03, 8.61215815e-02],\n",
       "       [1.46951817e-03, 2.21558288e-01, 9.49620560e-04, 7.76022613e-01],\n",
       "       [1.91127419e-01, 1.06205335e-02, 4.02820036e-02, 7.57970095e-01],\n",
       "       [9.69551802e-01, 4.52791061e-03, 7.61518488e-04, 2.51587182e-02],\n",
       "       [5.88982133e-04, 2.20691130e-04, 9.98759627e-01, 4.30737418e-04],\n",
       "       [2.36995448e-03, 5.20163067e-02, 4.02044179e-03, 9.41593230e-01],\n",
       "       [4.09977958e-02, 7.21144021e-01, 6.26301742e-04, 2.37231955e-01],\n",
       "       [7.63530433e-01, 2.13369176e-01, 2.02849507e-02, 2.81544193e-03],\n",
       "       [4.02203798e-02, 6.18565418e-02, 2.43371557e-02, 8.73585999e-01],\n",
       "       [8.06135237e-01, 1.23709500e-01, 4.57376381e-03, 6.55814558e-02],\n",
       "       [6.33348711e-03, 1.93749368e-02, 1.23085178e-01, 8.51206362e-01],\n",
       "       [9.36782826e-03, 7.96875417e-01, 9.99867450e-04, 1.92756847e-01],\n",
       "       [6.00477331e-04, 5.95571240e-03, 9.91034448e-01, 2.40936899e-03],\n",
       "       [1.15090571e-01, 3.03160120e-02, 6.02899909e-01, 2.51693547e-01],\n",
       "       [9.60130431e-03, 2.50823647e-01, 3.97756726e-01, 3.41818303e-01],\n",
       "       [8.54634881e-01, 9.17494893e-02, 3.83381285e-02, 1.52774462e-02],\n",
       "       [1.64451636e-02, 2.99714416e-01, 6.68370545e-01, 1.54699059e-02],\n",
       "       [1.62383243e-02, 8.12210366e-02, 7.34637916e-01, 1.67902738e-01],\n",
       "       [7.67224491e-01, 1.30054662e-02, 1.49174824e-01, 7.05951825e-02],\n",
       "       [2.65808851e-01, 3.83846872e-02, 9.27797407e-02, 6.03026748e-01],\n",
       "       [1.93085503e-02, 1.69958234e-01, 3.95773398e-03, 8.06775510e-01],\n",
       "       [2.74073891e-02, 2.88836733e-02, 8.53152454e-01, 9.05565023e-02],\n",
       "       [1.64995953e-01, 3.53052974e-01, 4.37166356e-03, 4.77579415e-01],\n",
       "       [1.96978021e-02, 6.51014820e-02, 6.55677319e-02, 8.49633038e-01],\n",
       "       [4.90312756e-04, 1.88091374e-03, 4.32918407e-03, 9.93299603e-01],\n",
       "       [2.11007744e-02, 1.05560701e-02, 3.40692210e-03, 9.64936197e-01],\n",
       "       [6.93309121e-04, 1.05604259e-02, 7.68458412e-04, 9.87977743e-01],\n",
       "       [8.18312824e-01, 8.49491730e-02, 1.30930415e-03, 9.54286829e-02],\n",
       "       [3.42268933e-04, 2.80126575e-02, 1.11752001e-04, 9.71533298e-01],\n",
       "       [1.46293361e-03, 3.05298805e-01, 8.85117985e-03, 6.84387028e-01],\n",
       "       [1.28317952e-01, 4.84792739e-02, 4.18428928e-01, 4.04773861e-01],\n",
       "       [4.36241040e-03, 6.01369375e-03, 2.34096453e-01, 7.55527437e-01],\n",
       "       [9.12234068e-01, 1.09904492e-02, 4.34241304e-03, 7.24329948e-02],\n",
       "       [5.02779498e-04, 1.99077441e-03, 9.60853636e-01, 3.66527028e-02],\n",
       "       [2.18011369e-03, 8.12317431e-01, 2.26713275e-03, 1.83235303e-01],\n",
       "       [1.08148307e-02, 4.05464560e-01, 3.13176098e-03, 5.80588877e-01],\n",
       "       [1.64861194e-04, 6.14634622e-03, 1.60849537e-04, 9.93527949e-01],\n",
       "       [8.02785382e-02, 7.49311224e-03, 9.06637311e-01, 5.59110288e-03],\n",
       "       [9.79426783e-03, 9.58271623e-01, 2.04608347e-02, 1.14732645e-02],\n",
       "       [7.71234045e-03, 3.79183353e-03, 7.26614892e-03, 9.81229663e-01],\n",
       "       [5.83087502e-04, 1.92896219e-03, 1.34244692e-02, 9.84063506e-01],\n",
       "       [4.52641875e-01, 3.07848155e-01, 1.19807767e-02, 2.27529153e-01],\n",
       "       [9.71299052e-01, 4.32950864e-03, 1.35701243e-03, 2.30143592e-02],\n",
       "       [7.66666140e-03, 2.70117144e-03, 1.42906904e-02, 9.75341380e-01],\n",
       "       [2.09599384e-03, 1.08038120e-01, 4.60828329e-03, 8.85257602e-01],\n",
       "       [8.20351008e-04, 4.58049774e-01, 2.28097185e-01, 3.13032717e-01],\n",
       "       [7.90827096e-01, 4.01928350e-02, 4.38872213e-03, 1.64591342e-01],\n",
       "       [1.06072627e-01, 9.31087043e-03, 7.81500459e-01, 1.03116058e-01],\n",
       "       [4.34027135e-01, 4.92549568e-01, 2.92294156e-02, 4.41939645e-02],\n",
       "       [9.88190644e-04, 4.16587340e-03, 2.85794144e-03, 9.91987944e-01],\n",
       "       [1.42290490e-02, 7.04500914e-01, 1.54649615e-01, 1.26620322e-01],\n",
       "       [2.71392728e-05, 3.19193641e-04, 7.31697539e-03, 9.92336690e-01],\n",
       "       [1.87021645e-03, 4.66361567e-02, 1.06665082e-01, 8.44828606e-01],\n",
       "       [4.82987501e-02, 7.00864289e-03, 9.07153182e-04, 9.43785489e-01],\n",
       "       [3.37144621e-02, 2.53995836e-01, 3.28208576e-03, 7.09007621e-01],\n",
       "       [4.16555820e-04, 7.90026505e-04, 8.92654777e-01, 1.06138565e-01],\n",
       "       [4.71117459e-02, 2.15071114e-03, 9.04730141e-01, 4.60073389e-02],\n",
       "       [8.33819866e-01, 3.10015269e-02, 1.14203589e-02, 1.23758242e-01],\n",
       "       [8.79126549e-01, 4.53937091e-02, 1.58667862e-02, 5.96129559e-02],\n",
       "       [7.97718167e-01, 1.19916737e-01, 3.56097240e-03, 7.88041055e-02],\n",
       "       [1.34234806e-03, 3.46325245e-03, 9.93887365e-01, 1.30710879e-03],\n",
       "       [9.24857855e-01, 2.92149540e-02, 1.28764939e-02, 3.30506749e-02],\n",
       "       [6.47670749e-05, 1.38235721e-03, 1.44980280e-04, 9.98407900e-01],\n",
       "       [8.55467692e-02, 1.57006815e-01, 3.89135885e-03, 7.53555059e-01],\n",
       "       [1.41678296e-03, 4.32044625e-01, 2.37461063e-03, 5.64163983e-01],\n",
       "       [5.28007513e-03, 6.44555271e-01, 1.73210446e-02, 3.32843572e-01],\n",
       "       [3.57234641e-03, 1.98128372e-01, 7.07467616e-01, 9.08316150e-02],\n",
       "       [2.40156776e-03, 3.56909573e-01, 1.33248139e-03, 6.39356315e-01],\n",
       "       [2.01735478e-02, 5.11470139e-01, 4.50982200e-03, 4.63846475e-01],\n",
       "       [7.86019087e-01, 6.18362576e-02, 2.07371940e-03, 1.50070950e-01],\n",
       "       [9.17787140e-04, 8.24701190e-01, 7.66335148e-03, 1.66717738e-01],\n",
       "       [2.81877428e-01, 1.85363609e-02, 2.15428174e-01, 4.84158069e-01],\n",
       "       [1.40413793e-03, 1.89145833e-01, 4.85854642e-03, 8.04591477e-01],\n",
       "       [2.95024540e-04, 6.21006973e-02, 2.63620284e-04, 9.37340736e-01],\n",
       "       [1.36509107e-03, 7.83112645e-03, 9.61949766e-01, 2.88539939e-02],\n",
       "       [5.61738154e-03, 1.61997136e-02, 2.34332494e-03, 9.75839615e-01],\n",
       "       [6.54608011e-01, 7.39442706e-02, 1.60150621e-02, 2.55432695e-01],\n",
       "       [8.78527761e-03, 5.88495612e-01, 1.50655568e-01, 2.52063602e-01],\n",
       "       [1.83496382e-02, 8.12420547e-01, 2.38515902e-03, 1.66844636e-01],\n",
       "       [3.56939447e-04, 6.03651404e-01, 1.82594711e-04, 3.95809025e-01],\n",
       "       [2.09593512e-02, 9.74353731e-01, 1.18638552e-03, 3.50051024e-03],\n",
       "       [4.42689192e-03, 2.83067316e-01, 3.92900966e-03, 7.08576798e-01],\n",
       "       [3.55693735e-02, 2.48891190e-01, 6.39199652e-03, 7.09147394e-01],\n",
       "       [1.29525622e-04, 8.23600776e-03, 1.27339954e-04, 9.91507173e-01],\n",
       "       [1.10821556e-02, 8.18134129e-01, 1.76797118e-02, 1.53104022e-01],\n",
       "       [7.34875444e-03, 3.57814878e-02, 5.14803361e-03, 9.51721787e-01],\n",
       "       [8.71034339e-04, 4.23231274e-01, 7.46050791e-04, 5.75151682e-01],\n",
       "       [1.73873894e-04, 1.90085560e-01, 2.79108033e-04, 8.09461474e-01],\n",
       "       [6.20676205e-04, 4.53097746e-03, 9.81329679e-01, 1.35187404e-02],\n",
       "       [5.64999180e-03, 3.32778245e-02, 8.38719029e-03, 9.52685058e-01],\n",
       "       [3.40887083e-04, 8.26358562e-04, 7.83081166e-04, 9.98049617e-01],\n",
       "       [8.09134543e-01, 4.28645872e-03, 1.38756437e-02, 1.72703385e-01],\n",
       "       [3.56023103e-01, 3.65913242e-01, 8.28638375e-02, 1.95199743e-01],\n",
       "       [2.08162912e-03, 1.16461539e-03, 1.01747669e-01, 8.95006061e-01],\n",
       "       [7.01892376e-02, 1.04644068e-01, 7.75847912e-01, 4.93188314e-02],\n",
       "       [1.47764036e-03, 4.12736386e-01, 1.06295431e-03, 5.84723055e-01],\n",
       "       [9.10687566e-01, 1.99532863e-02, 5.77676706e-02, 1.15914606e-02],\n",
       "       [3.66701372e-02, 7.08594263e-01, 9.29806288e-03, 2.45437577e-01],\n",
       "       [4.41777147e-03, 1.57324344e-01, 3.67736518e-02, 8.01484227e-01],\n",
       "       [9.25346017e-02, 2.19446257e-01, 3.02407122e-03, 6.84995115e-01],\n",
       "       [2.09268276e-02, 2.20122278e-01, 5.93205029e-03, 7.53018856e-01],\n",
       "       [2.30269483e-03, 5.84091663e-01, 1.89746101e-03, 4.11708117e-01],\n",
       "       [2.00113794e-03, 8.68349075e-01, 4.08628806e-02, 8.87868702e-02],\n",
       "       [6.01345338e-02, 1.09935105e-01, 2.62587249e-01, 5.67343116e-01],\n",
       "       [9.97361029e-04, 1.59778763e-02, 5.29245054e-03, 9.77732301e-01],\n",
       "       [2.91058474e-04, 1.58049449e-01, 2.41322070e-03, 8.39246273e-01],\n",
       "       [8.27021524e-03, 3.23777385e-02, 1.17623592e-02, 9.47589695e-01],\n",
       "       [6.01288676e-01, 8.89611489e-04, 3.80879454e-02, 3.59733760e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check predictions\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm1.tif</th>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.986060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm4.tif</th>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.992442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample12-sperm9.tif</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.971687</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.024291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample5-sperm3.tif</th>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.096956</td>\n",
       "      <td>0.898167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl3-sample14-sperm3.tif</th>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.059698</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.917071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\ch00_p5-pl1-sample9-sperm5.tif</th>\n",
       "      <td>0.060135</td>\n",
       "      <td>0.109935</td>\n",
       "      <td>0.262587</td>\n",
       "      <td>0.567343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_010.BMP</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.977732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_013.BMP</th>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.158049</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.839246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_014.BMP</th>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.032378</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.947590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_021.BMP</th>\n",
       "      <td>0.601289</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.038088</td>\n",
       "      <td>0.359734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class 0   Class 1   Class 2   Class 3\n",
       "class0\\ch00_p1-pl2-sample10-sperm1.tif  0.000388  0.012823  0.000729  0.986060\n",
       "class0\\ch00_p1-pl2-sample10-sperm4.tif  0.001335  0.004614  0.001609  0.992442\n",
       "class0\\ch00_p1-pl2-sample12-sperm9.tif  0.001667  0.971687  0.002355  0.024291\n",
       "class0\\ch00_p1-pl2-sample5-sperm3.tif   0.000660  0.004216  0.096956  0.898167\n",
       "class0\\ch00_p1-pl3-sample14-sperm3.tif  0.002487  0.059698  0.020744  0.917071\n",
       "...                                          ...       ...       ...       ...\n",
       "class3\\ch00_p5-pl1-sample9-sperm5.tif   0.060135  0.109935  0.262587  0.567343\n",
       "class3\\image_010.BMP                    0.000997  0.015978  0.005292  0.977732\n",
       "class3\\image_013.BMP                    0.000291  0.158049  0.002413  0.839246\n",
       "class3\\image_014.BMP                    0.008270  0.032378  0.011762  0.947590\n",
       "class3\\image_021.BMP                    0.601289  0.000890  0.038088  0.359734\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_pred =  pd.DataFrame(prediction, columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3'], index = filenames)\n",
    "\n",
    "cnn_pred.to_csv(path+'/Models/Cnn_pred_prob.csv')\n",
    "\n",
    "cnn_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7  Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(cnn_model_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del cnn_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.26      0.25      6400\n",
      "           1       0.25      0.27      0.26      6400\n",
      "           2       0.25      0.25      0.25      6400\n",
      "           3       0.24      0.22      0.23      6400\n",
      "\n",
      "    accuracy                           0.25     25600\n",
      "   macro avg       0.25      0.25      0.25     25600\n",
      "weighted avg       0.25      0.25      0.25     25600\n",
      "\n",
      "[[1633 1674 1611 1482]\n",
      " [1648 1751 1571 1430]\n",
      " [1691 1691 1615 1403]\n",
      " [1662 1772 1588 1378]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.17      0.16        46\n",
      "           1       0.16      0.18      0.17        84\n",
      "           2       0.10      0.10      0.10        40\n",
      "           3       0.51      0.46      0.48       213\n",
      "\n",
      "    accuracy                           0.33       383\n",
      "   macro avg       0.23      0.23      0.23       383\n",
      "weighted avg       0.34      0.33      0.33       383\n",
      "\n",
      "[[ 8  7  3 28]\n",
      " [12 15 10 47]\n",
      " [ 3 12  4 21]\n",
      " [33 58 24 98]]\n"
     ]
    }
   ],
   "source": [
    "train_labels, val_labels = cnn_training.classes, cnn_val.classes\n",
    "pred_train, pred_val = np.argmax(cnn_model.predict(cnn_training), axis = 1), np.argmax(cnn_model.predict(cnn_val), axis = 1)\n",
    "\n",
    "metrics(train_labels, pred_train , val_labels, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  4  0  8]\n",
      " [ 8  3  8 10]\n",
      " [ 2  1  2  9]\n",
      " [12 16  9 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.15      0.25      0.19        16\n",
      "      class1       0.12      0.10      0.11        29\n",
      "      class2       0.11      0.14      0.12        14\n",
      "      class3       0.56      0.48      0.52        71\n",
      "\n",
      "    accuracy                           0.33       130\n",
      "   macro avg       0.24      0.24      0.24       130\n",
      "weighted avg       0.36      0.33      0.34       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = list(cnn_test.class_indices.keys())   \n",
    "\n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ALEX NET\n",
    "<a id='2'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'/Models/AlexNet.h5'\n",
    "mc = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose = 1,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Preprocess input\n",
    "Online Data Augmentation  in RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25600 images belonging to 4 classes.\n",
      "Found 383 images belonging to 4 classes.\n",
      "Found 130 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Alex_train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 5,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1, \n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.5], \n",
    "                                   fill_mode='nearest',\n",
    "                                   zoom_range = 0.2,\n",
    "                                   ) \n",
    "\n",
    "Alex_val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "Alex_test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#test different color maps -  class modes and cross validation types\n",
    "Alex_training = Alex_train_datagen.flow_from_directory(path+'/path/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 64,\n",
    "                                                 shuffle = True,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 color_mode = 'rgb')\n",
    "\n",
    "Alex_val = Alex_val_datagen.flow_from_directory(path+'/path/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 64,\n",
    "                                            shuffle = True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb')\n",
    "\n",
    "Alex_test = Alex_test_datagen.flow_from_directory(path+'/path/test',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 1,\n",
    "                                            shuffle = True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Build model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 96)        4704      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 32, 32, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 8, 8, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 8, 8, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 4100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 41,521,396\n",
      "Trainable params: 41,500,204\n",
      "Non-trainable params: 21,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer - Alexnet took 224px imgs, which we do not have here, we will adjust layers accordingly \n",
    "#by reducing first first stride and max pool. All other layers will remain the same\n",
    "\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "##5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1024))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(4))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 29s 68ms/step - loss: 1.3466 - accuracy: 0.3271 - val_loss: 1.4522 - val_accuracy: 0.1645\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.16449, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 1.1855 - accuracy: 0.4500 - val_loss: 1.1793 - val_accuracy: 0.3916l - ETA: 6s - loss: 1\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.16449 to 0.39164, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 1.0238 - accuracy: 0.5541 - val_loss: 1.2453 - val_accuracy: 0.3943\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.39164 to 0.39426, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.9412 - accuracy: 0.5896 - val_loss: 0.9220 - val_accuracy: 0.5849racy:  - ETA: 2s - loss: 0\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.39426 to 0.58486, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.8643 - accuracy: 0.6389 - val_loss: 1.0251 - val_accuracy: 0.4935\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.58486\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.8198 - accuracy: 0.6617 - val_loss: 0.9353 - val_accuracy: 0.5979\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.58486 to 0.59791, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.7805 - accuracy: 0.6759 - val_loss: 0.9610 - val_accuracy: 0.5849\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.59791\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.7433 - accuracy: 0.6944 - val_loss: 1.1369 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.59791\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6991 - accuracy: 0.7133 - val_loss: 1.0193 - val_accuracy: 0.5405\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.6263 - accuracy: 0.7504 - val_loss: 0.8584 - val_accuracy: 0.6449oss: 0.6 - E - ETA: 8s - loss: 0.6304 - accuracy - ETA: 7s - loss: 0.6302 - accu - ETA: 7s - los - ETA: 6s - los - ETA:  - ETA: 1s - loss: 0.6269 - accuracy -\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.59791 to 0.64491, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.5874 - accuracy: 0.7669 - val_loss: 0.8227 - val_accuracy: 0.6554\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.64491 to 0.65535, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.5718 - accuracy: 0.7740 - val_loss: 0.8301 - val_accuracy: 0.6266\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65535\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.5499 - accuracy: 0.7827 - val_loss: 0.8112 - val_accuracy: 0.6554\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65535\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.5248 - accuracy: 0.7941 - val_loss: 0.8129 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.65535 to 0.67363, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.5108 - accuracy: 0.8000 - val_loss: 0.7816 - val_accuracy: 0.6658\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67363\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.4887 - accuracy: 0.8111 - val_loss: 0.9276 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.67363 to 0.68668, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.4659 - accuracy: 0.8169 - val_loss: 0.8576 - val_accuracy: 0.6527- ETA: 19s - loss - ETA: 17s - loss: 0.4630 - ETA: - ETA: 11s - l - ETA: 8s - loss: 0.4642 - ac - ETA: 7s - loss: 0.4643 - accuracy - ETA - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.4654 - accuracy - ETA: \n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.68668\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.4476 - accuracy: 0.8254 - val_loss: 0.9007 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.68668\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.4348 - accuracy: 0.8365 - val_loss: 0.9456 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.68668\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.4192 - accuracy: 0.8405 - val_loss: 0.8646 - val_accuracy: 0.6945oss: 0.4073 - accuracy: 0 - ET - ETA: 17s - l\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.68668 to 0.69452, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.3843 - accuracy: 0.8525 - val_loss: 0.9063 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.69452\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.3435 - accuracy: 0.8722 - val_loss: 0.8703 - val_accuracy: 0.6893\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.69452\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.3419 - accuracy: 0.8746 - val_loss: 0.8739 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.69452 to 0.69713, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.3147 - accuracy: 0.8857 - val_loss: 0.9604 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.69713\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.3195 - accuracy: 0.8832 - val_loss: 0.9545 - val_accuracy: 0.6841\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.69713\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.2771 - accuracy: 0.8999 - val_loss: 0.9535 - val_accuracy: 0.6919\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.69713\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.2759 - accuracy: 0.9015 - val_loss: 0.9429 - val_accuracy: 0.6815TA: 18s - loss: 0.2852 - accuracy: 0 - ETA: 18s - loss: 0.2847 - accuracy: 0. - ETA: 17s - loss: 0.2844 - a - ETA: 7s - loss: 0.2780 - accuracy: 0. - ETA: 7s - loss: 0.2779 -  - ETA: 5s - loss: 0.2775 -  - ETA: 5s -\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.69713\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.2542 - accuracy: 0.9080 - val_loss: 0.9979 - val_accuracy: 0.6815\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.69713\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.2525 - accuracy: 0.9104 - val_loss: 1.0038 - val_accuracy: 0.6789\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.69713\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.2488 - accuracy: 0.9110 - val_loss: 1.0023 - val_accuracy: 0.7076\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.69713 to 0.70757, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\AlexNet.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.2303 - accuracy: 0.9168 - val_loss: 0.9941 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.70757\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 0.2330 - accuracy: 0.9150 - val_loss: 1.0155 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.70757\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.2124 - accuracy: 0.9275 - val_loss: 1.0278 - val_accuracy: 0.6789\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.70757\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.2155 - accuracy: 0.9231 - val_loss: 1.0007 - val_accuracy: 0.6945\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.70757\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.2122 - accuracy: 0.9276 - val_loss: 1.0709 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.70757\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = AlexNet.fit(Alex_training,\n",
    "        epochs=200, \n",
    "        validation_data=Alex_val,\n",
    "        verbose = 1, \n",
    "        callbacks = [mc, reduce_lr, es,cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Evaluate  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 26s 64ms/step - loss: 0.4545 - accuracy: 0.8268\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.7816 - accuracy: 0.6658\n",
      "Train: 0.827, Val: 0.666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, train_acc = AlexNet.evaluate(Alex_training, verbose=1)\n",
    "_, val_acc = AlexNet.evaluate(Alex_val, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 6ms/step - loss: 0.8966 - accuracy: 0.6462\n",
      "Test loss: 0.8965646028518677\n",
      "Test accuracy: 0.6461538672447205\n",
      "\n",
      "Time: 42.683213278333305 min\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = AlexNet.evaluate(Alex_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print(\"\\nTime:\",sum(cb.logs)/60,\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = AlexNet.predict(Alex_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = Alex_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = Alex_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "alex_predictions = pd.DataFrame({'Filename': filenames,'AlexNet': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm1.tif</th>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.015901</td>\n",
       "      <td>0.854810</td>\n",
       "      <td>0.122702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm4.tif</th>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.561558</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.423405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample12-sperm9.tif</th>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.960615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample5-sperm3.tif</th>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.096231</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.839292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl3-sample14-sperm3.tif</th>\n",
       "      <td>0.007259</td>\n",
       "      <td>0.816939</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.138691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\ch00_p5-pl1-sample9-sperm5.tif</th>\n",
       "      <td>0.010131</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>0.143086</td>\n",
       "      <td>0.822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_010.BMP</th>\n",
       "      <td>0.376898</td>\n",
       "      <td>0.172431</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.442325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_013.BMP</th>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.073404</td>\n",
       "      <td>0.529125</td>\n",
       "      <td>0.388925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_014.BMP</th>\n",
       "      <td>0.004888</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.916053</td>\n",
       "      <td>0.062129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_021.BMP</th>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class 0   Class 1   Class 2   Class 3\n",
       "class0\\ch00_p1-pl2-sample10-sperm1.tif  0.006588  0.015901  0.854810  0.122702\n",
       "class0\\ch00_p1-pl2-sample10-sperm4.tif  0.005374  0.561558  0.009662  0.423405\n",
       "class0\\ch00_p1-pl2-sample12-sperm9.tif  0.017577  0.018911  0.002897  0.960615\n",
       "class0\\ch00_p1-pl2-sample5-sperm3.tif   0.008723  0.096231  0.055755  0.839292\n",
       "class0\\ch00_p1-pl3-sample14-sperm3.tif  0.007259  0.816939  0.037111  0.138691\n",
       "...                                          ...       ...       ...       ...\n",
       "class3\\ch00_p5-pl1-sample9-sperm5.tif   0.010131  0.024283  0.143086  0.822500\n",
       "class3\\image_010.BMP                    0.376898  0.172431  0.008346  0.442325\n",
       "class3\\image_013.BMP                    0.008547  0.073404  0.529125  0.388925\n",
       "class3\\image_014.BMP                    0.004888  0.016930  0.916053  0.062129\n",
       "class3\\image_021.BMP                    0.983923  0.007774  0.002852  0.005451\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alex_pred =  pd.DataFrame(prediction, columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3'], index = filenames)\n",
    "\n",
    "Alex_pred.to_csv(path+'/Models/Alex_pred_prob.csv')\n",
    "\n",
    "Alex_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(alex_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del alex_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "      <th>cnn_model</th>\n",
       "      <th>AlexNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm1.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample12-sperm9.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample5-sperm3.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample14-sperm3.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>class3\\ch00_p5-pl1-sample9-sperm5.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>class3\\image_010.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>class3\\image_013.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>class3\\image_014.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>class3\\image_021.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test  cnn_model  AlexNet\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm1.tif      0     3          3        2\n",
       "1    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     3          3        1\n",
       "2    class0\\ch00_p1-pl2-sample12-sperm9.tif      0     1          1        3\n",
       "3     class0\\ch00_p1-pl2-sample5-sperm3.tif      0     3          3        3\n",
       "4    class0\\ch00_p1-pl3-sample14-sperm3.tif      0     3          3        1\n",
       "..                                      ...    ...   ...        ...      ...\n",
       "125   class3\\ch00_p5-pl1-sample9-sperm5.tif      3     3          3        3\n",
       "126                    class3\\image_010.BMP      3     3          3        3\n",
       "127                    class3\\image_013.BMP      3     3          3        2\n",
       "128                    class3\\image_014.BMP      3     3          3        2\n",
       "129                    class3\\image_021.BMP      3     0          0        0\n",
       "\n",
       "[130 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7  Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.28      0.26      6400\n",
      "           1       0.24      0.22      0.23      6400\n",
      "           2       0.24      0.26      0.25      6400\n",
      "           3       0.25      0.22      0.23      6400\n",
      "\n",
      "    accuracy                           0.24     25600\n",
      "   macro avg       0.24      0.24      0.24     25600\n",
      "weighted avg       0.24      0.24      0.24     25600\n",
      "\n",
      "[[1761 1528 1691 1420]\n",
      " [1891 1410 1674 1425]\n",
      " [1853 1540 1653 1354]\n",
      " [1797 1476 1731 1396]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.20      0.17        46\n",
      "           1       0.24      0.19      0.21        84\n",
      "           2       0.10      0.15      0.12        40\n",
      "           3       0.60      0.55      0.57       213\n",
      "\n",
      "    accuracy                           0.39       383\n",
      "   macro avg       0.27      0.27      0.27       383\n",
      "weighted avg       0.41      0.39      0.40       383\n",
      "\n",
      "[[  9  10   5  22]\n",
      " [ 18  16  15  35]\n",
      " [  9   5   6  20]\n",
      " [ 27  37  32 117]]\n"
     ]
    }
   ],
   "source": [
    "train_labels, val_labels = Alex_training.classes, Alex_val.classes\n",
    "pred_train, pred_val = np.argmax(AlexNet.predict(Alex_training), axis = 1), np.argmax(AlexNet.predict(Alex_val), axis = 1)\n",
    "\n",
    "metrics(train_labels, pred_train , val_labels, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  3  3  7]\n",
      " [10  5  4 10]\n",
      " [ 2  2  4  6]\n",
      " [14 11 13 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.10      0.19      0.13        16\n",
      "      class1       0.24      0.17      0.20        29\n",
      "      class2       0.17      0.29      0.21        14\n",
      "      class3       0.59      0.46      0.52        71\n",
      "\n",
      "    accuracy                           0.35       130\n",
      "   macro avg       0.27      0.28      0.27       130\n",
      "weighted avg       0.41      0.35      0.37       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_labels = list(Alex_test.class_indices.keys())   \n",
    "\n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8 AlexNet [Model Assessment][mylink]\n",
    "[mylink]: Alex_Model_Assessment_RGB.ipynb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3m'></a> \n",
    "# 5. RESNET50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'/Models/ResNet50.h5'\n",
    "mc = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose = 1,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Preprocess input\n",
    "resnet50 requires its own preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25600 images belonging to 4 classes.\n",
      "Found 383 images belonging to 4 classes.\n",
      "Found 130 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#to play around with these\n",
    "res_train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   preprocessing_function=preprocess_input,\n",
    "                                   rotation_range = 5,\n",
    "                                   width_shift_range = 0.06, \n",
    "                                   height_shift_range = 0.06, \n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.2], \n",
    "                                   fill_mode='nearest',\n",
    "                                   zoom_range = 0.2,\n",
    "                                   ) \n",
    "\n",
    "res_val_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "res_test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "#test different color maps -  class modes and cross validation types\n",
    "res_train = res_train_datagen.flow_from_directory(path+'/path/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 color_mode = 'rgb',\n",
    "                                                 shuffle = True)\n",
    "\n",
    "res_val = res_val_datagen.flow_from_directory(path+'/path/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb',\n",
    "                                            shuffle = True)\n",
    "\n",
    "res_test = res_test_datagen.flow_from_directory(path+'/path/test',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb',\n",
    "                                            shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Build model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 29,898,628\n",
      "Trainable params: 6,304,772\n",
      "Non-trainable params: 23,593,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res50model = Sequential()\n",
    "\n",
    "#Layer 1: RES50 without top layer\n",
    "res50model.add(ResNet50(weights='imagenet', input_shape= (32,32,1),\n",
    "                 include_top = False, classes=4,))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "res50model.add(Flatten())\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "res50model.add(Dense(2048))\n",
    "res50model.add(BatchNormalization())\n",
    "res50model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "res50model.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "res50model.add(Dense(1024))\n",
    "res50model.add(BatchNormalization())\n",
    "res50model.add(Activation('relu'))\n",
    "\n",
    "#Add Dropout\n",
    "res50model.add(Dropout(0.4))\n",
    "\n",
    "res50model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "#freeze layers in resnet - weights obtained with IMAGENET challenge, we only train final layer\n",
    "res50model.layers[0].trainable = False\n",
    "\n",
    "res50model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50model.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 32s 72ms/step - loss: 1.5973 - accuracy: 0.3237 - val_loss: 2.1744 - val_accuracy: 0.2193\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.21932, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\ResNet50.h5\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.3362 - accuracy: 0.3795 - val_loss: 1.4651 - val_accuracy: 0.2402\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.21932 to 0.24021, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\ResNet50.h5\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 1.2796 - accuracy: 0.4019 - val_loss: 1.4026 - val_accuracy: 0.2193\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.24021\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.2568 - accuracy: 0.4159 - val_loss: 1.2194 - val_accuracy: 0.3551\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.24021 to 0.35509, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\ResNet50.h5\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.2326 - accuracy: 0.4280 - val_loss: 1.9668 - val_accuracy: 0.1567\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.35509\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.2179 - accuracy: 0.4404 - val_loss: 1.0918 - val_accuracy: 0.5561\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.35509 to 0.55614, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\ResNet50.h5\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.1987 - accuracy: 0.4490 - val_loss: 2.1084 - val_accuracy: 0.2193\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.55614\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.2006 - accuracy: 0.4470 - val_loss: 1.5655 - val_accuracy: 0.2376\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.55614\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1789 - accuracy: 0.4620 - val_loss: 1.4860 - val_accuracy: 0.2089\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.55614\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1838 - accuracy: 0.4582 - val_loss: 2.6213 - val_accuracy: 0.1044\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.55614\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1659 - accuracy: 0.4716 - val_loss: 1.3789 - val_accuracy: 0.1749\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.55614\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.1419 - accuracy: 0.4845 - val_loss: 1.3378 - val_accuracy: 0.3107\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.55614\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.1248 - accuracy: 0.4895 - val_loss: 1.5514 - val_accuracy: 0.17490s - loss: 1.1248 - accu\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.55614\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1181 - accuracy: 0.5046 - val_loss: 1.9251 - val_accuracy: 0.1697\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.55614\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1147 - accuracy: 0.5011 - val_loss: 1.0545 - val_accuracy: 0.5979\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.55614 to 0.59791, saving model to C:\\Users\\Ricardo Santos\\Desktop\\Mestrado Ricardo\\Ano 1\\Spring Semester\\Deep\\Deep_Learning_Project\\CNN_SpermCells/Models\\ResNet50.h5\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.1123 - accuracy: 0.5019 - val_loss: 1.3527 - val_accuracy: 0.2089\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.59791\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1025 - accuracy: 0.5076 - val_loss: 1.5650 - val_accuracy: 0.2010\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.59791\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0977 - accuracy: 0.5084 - val_loss: 1.1260 - val_accuracy: 0.5901\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.59791\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.1041 - accuracy: 0.5124 - val_loss: 1.5016 - val_accuracy: 0.1775\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.59791\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.0901 - accuracy: 0.5215 - val_loss: 1.4946 - val_accuracy: 0.1828\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0898 - accuracy: 0.5147 - val_loss: 1.4951 - val_accuracy: 0.2872\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.59791\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.0658 - accuracy: 0.5319 - val_loss: 1.1177 - val_accuracy: 0.4883\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.59791\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0636 - accuracy: 0.5332 - val_loss: 1.2570 - val_accuracy: 0.3368\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.59791\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0539 - accuracy: 0.5398 - val_loss: 1.6127 - val_accuracy: 0.2611\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.59791\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 1.0550 - accuracy: 0.5402 - val_loss: 1.0296 - val_accuracy: 0.5457\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.59791\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 29s 73ms/step - loss: 1.0642 - accuracy: 0.5277 - val_loss: 1.0039 - val_accuracy: 0.5953\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.59791\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 1.0569 - accuracy: 0.5387 - val_loss: 1.4768 - val_accuracy: 0.2768\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.59791\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0496 - accuracy: 0.5380 - val_loss: 1.3233 - val_accuracy: 0.3394\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.59791\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0383 - accuracy: 0.5438 - val_loss: 1.3718 - val_accuracy: 0.3133\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.59791\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0466 - accuracy: 0.5405 - val_loss: 1.2703 - val_accuracy: 0.2768\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.59791\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0418 - accuracy: 0.5465 - val_loss: 1.2182 - val_accuracy: 0.5927\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0463 - accuracy: 0.5455 - val_loss: 1.4538 - val_accuracy: 0.3264\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.59791\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0314 - accuracy: 0.5489 - val_loss: 0.9842 - val_accuracy: 0.5587\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59791\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0242 - accuracy: 0.5556 - val_loss: 1.4534 - val_accuracy: 0.2715\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59791\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0293 - accuracy: 0.5515 - val_loss: 1.1536 - val_accuracy: 0.4204\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59791\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0197 - accuracy: 0.5541 - val_loss: 1.4350 - val_accuracy: 0.2715\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59791\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0182 - accuracy: 0.5558 - val_loss: 1.0130 - val_accuracy: 0.5509\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.59791\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0189 - accuracy: 0.5568 - val_loss: 1.2224 - val_accuracy: 0.3525\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.0032 - accuracy: 0.5652 - val_loss: 0.9943 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.59791\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0109 - accuracy: 0.5678 - val_loss: 0.9819 - val_accuracy: 0.5509\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.59791\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0114 - accuracy: 0.5635 - val_loss: 1.0198 - val_accuracy: 0.4961\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.59791\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0125 - accuracy: 0.5619 - val_loss: 1.1470 - val_accuracy: 0.4569\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.59791\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0107 - accuracy: 0.5582 - val_loss: 1.0493 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.59791\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 1.0110 - accuracy: 0.5556 - val_loss: 0.9356 - val_accuracy: 0.5587\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.59791\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.9967 - accuracy: 0.5677 - val_loss: 1.3278 - val_accuracy: 0.3577\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.59791\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0029 - accuracy: 0.5704 - val_loss: 1.0373 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.59791\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 1.0023 - accuracy: 0.5648 - val_loss: 1.1362 - val_accuracy: 0.4334\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.59791\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0071 - accuracy: 0.5623 - val_loss: 1.4616 - val_accuracy: 0.2689\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.59791\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.9990 - accuracy: 0.5702 - val_loss: 1.1552 - val_accuracy: 0.3812\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 1.0009 - accuracy: 0.5600 - val_loss: 1.0134 - val_accuracy: 0.5091\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.59791\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9955 - accuracy: 0.5686 - val_loss: 0.9560 - val_accuracy: 0.5431\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.59791\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9861 - accuracy: 0.5734 - val_loss: 1.1921 - val_accuracy: 0.4204\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.59791\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9935 - accuracy: 0.5658 - val_loss: 1.0852 - val_accuracy: 0.4465\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.59791\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.9979 - accuracy: 0.5688 - val_loss: 1.0838 - val_accuracy: 0.4804\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9970 - accuracy: 0.5669 - val_loss: 1.1086 - val_accuracy: 0.4308\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.59791\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.9871 - accuracy: 0.5665 - val_loss: 1.1037 - val_accuracy: 0.4334\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.59791\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.9835 - accuracy: 0.5701 - val_loss: 1.1002 - val_accuracy: 0.4439\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.59791\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.9930 - accuracy: 0.5701 - val_loss: 1.0800 - val_accuracy: 0.4674\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.59791\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9966 - accuracy: 0.5683 - val_loss: 1.0281 - val_accuracy: 0.4804\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9912 - accuracy: 0.5721 - val_loss: 1.0717 - val_accuracy: 0.4569\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.59791\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9900 - accuracy: 0.5693 - val_loss: 1.1222 - val_accuracy: 0.4334 loss: 0.9889 - accu - E - ETA: 7s - loss: - ETA: 3s - ETA: 0s - los\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.59791\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.9894 - accuracy: 0.5715 - val_loss: 1.0211 - val_accuracy: 0.4961\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.59791\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 0.9943 - accuracy: 0.5690 - val_loss: 1.0776 - val_accuracy: 0.4465\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.59791\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 26s 65ms/step - loss: 0.9867 - accuracy: 0.5718 - val_loss: 1.0090 - val_accuracy: 0.4909\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.59791\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00064: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = res50model.fit(res_train,\n",
    "        epochs=200, \n",
    "        validation_data=res_val,\n",
    "        verbose = 1, \n",
    "        callbacks = [mc, reduce_lr, es,cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 26s 65ms/step - loss: 1.1215 - accuracy: 0.51521s - loss: 1.1 - ETA: 0s - loss: 1.120\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.9356 - accuracy: 0.5587\n",
      "Train: 0.515, Val: 0.559\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 2s 16ms/step - loss: 0.9312 - accuracy: 0.5923\n",
      "Test loss: 0.93122398853302\n",
      "Test accuracy: 0.5923076868057251\n",
      "\n",
      "Time: 71.24510394333325 min\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = res50model.evaluate(res_train, verbose=1)\n",
    "_, val_acc = res50model.evaluate(res_val, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_acc = res50model.evaluate(res_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "print(\"\\nTime:\",sum(cb.logs)/60,\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 3s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = res50model.predict(res_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = res_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = res_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "res50_prebuilt_predictions = pd.DataFrame({'Filename': filenames,'ResNet50': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm1.tif</th>\n",
       "      <td>0.040881</td>\n",
       "      <td>0.379133</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>0.570614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm4.tif</th>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.278826</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.718260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample12-sperm9.tif</th>\n",
       "      <td>0.732520</td>\n",
       "      <td>0.058375</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>0.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample5-sperm3.tif</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.607359</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.070011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl3-sample14-sperm3.tif</th>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.427877</td>\n",
       "      <td>0.337243</td>\n",
       "      <td>0.223665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\ch00_p5-pl1-sample9-sperm5.tif</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.689045</td>\n",
       "      <td>0.254339</td>\n",
       "      <td>0.056533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_010.BMP</th>\n",
       "      <td>0.049314</td>\n",
       "      <td>0.362852</td>\n",
       "      <td>0.029347</td>\n",
       "      <td>0.558487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_013.BMP</th>\n",
       "      <td>0.028266</td>\n",
       "      <td>0.141220</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.829964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_014.BMP</th>\n",
       "      <td>0.726915</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>0.078768</td>\n",
       "      <td>0.174492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_021.BMP</th>\n",
       "      <td>0.020452</td>\n",
       "      <td>0.167898</td>\n",
       "      <td>0.796677</td>\n",
       "      <td>0.014973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class 0   Class 1   Class 2   Class 3\n",
       "class0\\ch00_p1-pl2-sample10-sperm1.tif  0.040881  0.379133  0.009372  0.570614\n",
       "class0\\ch00_p1-pl2-sample10-sperm4.tif  0.002184  0.278826  0.000730  0.718260\n",
       "class0\\ch00_p1-pl2-sample12-sperm9.tif  0.732520  0.058375  0.016552  0.192553\n",
       "class0\\ch00_p1-pl2-sample5-sperm3.tif   0.001063  0.607359  0.321566  0.070011\n",
       "class0\\ch00_p1-pl3-sample14-sperm3.tif  0.011215  0.427877  0.337243  0.223665\n",
       "...                                          ...       ...       ...       ...\n",
       "class3\\ch00_p5-pl1-sample9-sperm5.tif   0.000083  0.689045  0.254339  0.056533\n",
       "class3\\image_010.BMP                    0.049314  0.362852  0.029347  0.558487\n",
       "class3\\image_013.BMP                    0.028266  0.141220  0.000550  0.829964\n",
       "class3\\image_014.BMP                    0.726915  0.019825  0.078768  0.174492\n",
       "class3\\image_021.BMP                    0.020452  0.167898  0.796677  0.014973\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pred =  pd.DataFrame(prediction, columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3'], index = filenames)\n",
    "\n",
    "res_pred.to_csv(path+'/Models/res_pred_prob.csv')\n",
    "\n",
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm1.tif</th>\n",
       "      <td>0.040881</td>\n",
       "      <td>0.379133</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>0.570614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm4.tif</th>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.278826</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.718260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample12-sperm9.tif</th>\n",
       "      <td>0.732520</td>\n",
       "      <td>0.058375</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>0.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample5-sperm3.tif</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.607359</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>0.070011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl3-sample14-sperm3.tif</th>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.427877</td>\n",
       "      <td>0.337243</td>\n",
       "      <td>0.223665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\ch00_p5-pl1-sample9-sperm5.tif</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.689045</td>\n",
       "      <td>0.254339</td>\n",
       "      <td>0.056533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_010.BMP</th>\n",
       "      <td>0.049314</td>\n",
       "      <td>0.362852</td>\n",
       "      <td>0.029347</td>\n",
       "      <td>0.558487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_013.BMP</th>\n",
       "      <td>0.028266</td>\n",
       "      <td>0.141220</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.829964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_014.BMP</th>\n",
       "      <td>0.726915</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>0.078768</td>\n",
       "      <td>0.174492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_021.BMP</th>\n",
       "      <td>0.020452</td>\n",
       "      <td>0.167898</td>\n",
       "      <td>0.796677</td>\n",
       "      <td>0.014973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class 0   Class 1   Class 2   Class 3\n",
       "class0\\ch00_p1-pl2-sample10-sperm1.tif  0.040881  0.379133  0.009372  0.570614\n",
       "class0\\ch00_p1-pl2-sample10-sperm4.tif  0.002184  0.278826  0.000730  0.718260\n",
       "class0\\ch00_p1-pl2-sample12-sperm9.tif  0.732520  0.058375  0.016552  0.192553\n",
       "class0\\ch00_p1-pl2-sample5-sperm3.tif   0.001063  0.607359  0.321566  0.070011\n",
       "class0\\ch00_p1-pl3-sample14-sperm3.tif  0.011215  0.427877  0.337243  0.223665\n",
       "...                                          ...       ...       ...       ...\n",
       "class3\\ch00_p5-pl1-sample9-sperm5.tif   0.000083  0.689045  0.254339  0.056533\n",
       "class3\\image_010.BMP                    0.049314  0.362852  0.029347  0.558487\n",
       "class3\\image_013.BMP                    0.028266  0.141220  0.000550  0.829964\n",
       "class3\\image_014.BMP                    0.726915  0.019825  0.078768  0.174492\n",
       "class3\\image_021.BMP                    0.020452  0.167898  0.796677  0.014973\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res_pred =  pd.DataFrame(prediction, columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3'], index = filenames)\n",
    "\n",
    "Res_pred.to_csv(path+'/Models/res50_pred_prob.csv')\n",
    "\n",
    "Res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(res50_prebuilt_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del res50_prebuilt_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7  Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24      6400\n",
      "           1       0.25      0.28      0.26      6400\n",
      "           2       0.25      0.09      0.13      6400\n",
      "           3       0.25      0.41      0.31      6400\n",
      "\n",
      "    accuracy                           0.25     25600\n",
      "   macro avg       0.25      0.25      0.24     25600\n",
      "weighted avg       0.25      0.25      0.24     25600\n",
      "\n",
      "[[1457 1807  579 2557]\n",
      " [1443 1799  572 2586]\n",
      " [1399 1859  573 2569]\n",
      " [1415 1788  579 2618]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.28      0.18        46\n",
      "           1       0.15      0.15      0.15        84\n",
      "           2       0.20      0.15      0.17        40\n",
      "           3       0.53      0.42      0.47       213\n",
      "\n",
      "    accuracy                           0.32       383\n",
      "   macro avg       0.25      0.25      0.24       383\n",
      "weighted avg       0.36      0.32      0.33       383\n",
      "\n",
      "[[13  8  5 20]\n",
      " [22 13  6 43]\n",
      " [10  7  6 17]\n",
      " [55 56 13 89]]\n"
     ]
    }
   ],
   "source": [
    "train_labels, val_labels = res_train.classes, res_val.classes\n",
    "pred_train, pred_val = np.argmax(res50model.predict(res_train), axis = 1), np.argmax(res50model.predict(res_val), axis = 1)\n",
    "\n",
    "metrics(train_labels, pred_train , val_labels, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  3  3  5]\n",
      " [10  5  3 11]\n",
      " [ 6  2  1  5]\n",
      " [16 19  5 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.14      0.31      0.19        16\n",
      "      class1       0.17      0.17      0.17        29\n",
      "      class2       0.08      0.07      0.08        14\n",
      "      class3       0.60      0.44      0.50        71\n",
      "\n",
      "    accuracy                           0.32       130\n",
      "   macro avg       0.25      0.25      0.24       130\n",
      "weighted avg       0.39      0.32      0.35       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = list(res_test.class_indices.keys())   \n",
    "\n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EFFICIENT NET B7\n",
    "\n",
    "<a id='4'></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'/Models/EffnetB7.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Preprocess input\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25600 images belonging to 4 classes.\n",
      "Found 383 images belonging to 4 classes.\n",
      "Found 130 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#to play around with these\n",
    "EffNetB7train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 5,\n",
    "                                   width_shift_range = 0.06, \n",
    "                                   height_shift_range = 0.06, \n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True,\n",
    "                                   brightness_range=[0.2,1.2], \n",
    "                                   fill_mode='nearest',\n",
    "                                   zoom_range = 0.2,\n",
    "                                   ) \n",
    "\n",
    "EffNetB7val_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "EffNetB7test_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
    "\n",
    "#test different color maps -  class modes and cross validation types\n",
    "EffNetB7_train = EffNetB7train_datagen.flow_from_directory(path+'/path/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 color_mode = 'rgb',\n",
    "                                                 shuffle = True)\n",
    "\n",
    "EffNetB7_val = EffNetB7val_datagen.flow_from_directory(path+'/path/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb',\n",
    "                                            shuffle = True)\n",
    "\n",
    "EffNetB7_test = EffNetB7test_datagen.flow_from_directory(path+'/path/test',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            color_mode = 'rgb',\n",
    "                                            shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "\n",
    "EffNetB7model = Sequential()\n",
    "\n",
    "#Layer 1\n",
    "\n",
    "EffNetB7model.add(EfficientNetB7(weights='imagenet', input_shape= (32,32,3),\n",
    "                      include_top = False, classes=4))\n",
    "EffNetB7model.add(layers.GlobalMaxPooling2D(name=\"gap\")) ### mais eficiente qie o flatten\n",
    "#EffNetB7.add(Flatten())\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "EffNetB7model.add(Dense(2560))\n",
    "EffNetB7model.add(BatchNormalization())\n",
    "EffNetB7model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "if dropout_rate > 0:\n",
    "    EffNetB7model.add(Dropout(dropout_rate, name=\"dropout_out\"))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "EffNetB7model.add(Dense(1280))\n",
    "EffNetB7model.add(BatchNormalization())\n",
    "EffNetB7model.add(Activation('relu'))\n",
    "if dropout_rate > 0:\n",
    "    EffNetB7model.add(Dropout(dropout_rate, name=\"dropout_out1\"))\n",
    "\n",
    "EffNetB7model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "EffNetB7model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb7 (Functional)  (None, 1, 1, 2560)        64097687  \n",
      "_________________________________________________________________\n",
      "gap (GlobalMaxPooling2D)     (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2560)              6556160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 2560)              10240     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dropout_out (Dropout)        (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1280)              3278080   \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_out1 (Dropout)       (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 5124      \n",
      "=================================================================\n",
      "Total params: 73,952,411\n",
      "Trainable params: 9,847,044\n",
      "Non-trainable params: 64,105,367\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EffNetB7model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "EffNetB7model.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 59s 99ms/step - loss: 1.7011 - accuracy: 0.2532 - val_loss: 1.4497 - val_accuracy: 0.1044\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.4833 - accuracy: 0.2493 - val_loss: 1.4503 - val_accuracy: 0.2193\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.4556 - accuracy: 0.2536 - val_loss: 1.5131 - val_accuracy: 0.1044\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 34s 85ms/step - loss: 1.4433 - accuracy: 0.2529 - val_loss: 1.4055 - val_accuracy: 0.2193\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.4270 - accuracy: 0.2583 - val_loss: 1.5456 - val_accuracy: 0.2193\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 35s 88ms/step - loss: 1.4203 - accuracy: 0.2446 - val_loss: 1.4772 - val_accuracy: 0.1044\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 1.4100 - accuracy: 0.2485 - val_loss: 1.3884 - val_accuracy: 0.2193\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 1.4105 - accuracy: 0.2514 - val_loss: 1.4832 - val_accuracy: 0.2193\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 35s 88ms/step - loss: 1.4041 - accuracy: 0.2517 - val_loss: 1.3306 - val_accuracy: 0.5561\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 36s 89ms/step - loss: 1.4048 - accuracy: 0.2512 - val_loss: 1.3811 - val_accuracy: 0.1201\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3978 - accuracy: 0.2512 - val_loss: 1.4100 - val_accuracy: 0.1201\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3974 - accuracy: 0.2437 - val_loss: 1.4200 - val_accuracy: 0.1201\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3953 - accuracy: 0.2559 - val_loss: 1.4180 - val_accuracy: 0.1044\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3947 - accuracy: 0.2514 - val_loss: 1.3755 - val_accuracy: 0.2193\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3900 - accuracy: 0.2544 - val_loss: 1.3894 - val_accuracy: 0.1201\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 34s 86ms/step - loss: 1.3903 - accuracy: 0.2489 - val_loss: 1.3823 - val_accuracy: 0.1201\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3897 - accuracy: 0.2512 - val_loss: 1.3961 - val_accuracy: 0.1044\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3907 - accuracy: 0.2487 - val_loss: 1.4011 - val_accuracy: 0.1201\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3893 - accuracy: 0.2514 - val_loss: 1.3960 - val_accuracy: 0.1201\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 35s 88ms/step - loss: 1.3894 - accuracy: 0.2442 - val_loss: 1.3849 - val_accuracy: 0.1201\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 1.3877 - accuracy: 0.2489 - val_loss: 1.3846 - val_accuracy: 0.5561\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 35s 88ms/step - loss: 1.3878 - accuracy: 0.2502 - val_loss: 1.3931 - val_accuracy: 0.1201\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 37s 92ms/step - loss: 1.3881 - accuracy: 0.2501 - val_loss: 1.3880 - val_accuracy: 0.1044\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 36s 91ms/step - loss: 1.3881 - accuracy: 0.2449 - val_loss: 1.3917 - val_accuracy: 0.1044\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 34s 86ms/step - loss: 1.3876 - accuracy: 0.2509 - val_loss: 1.3932 - val_accuracy: 0.1044\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3871 - accuracy: 0.2445 - val_loss: 1.3935 - val_accuracy: 0.1201\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 35s 86ms/step - loss: 1.3872 - accuracy: 0.2455 - val_loss: 1.3894 - val_accuracy: 0.1201\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3871 - accuracy: 0.2475 - val_loss: 1.3898 - val_accuracy: 0.1044\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 35s 87ms/step - loss: 1.3870 - accuracy: 0.2501 - val_loss: 1.3899 - val_accuracy: 0.1201\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "EffNet_history = EffNetB7model.fit(EffNetB7_train,\n",
    "        epochs=200,\n",
    "        validation_data=EffNetB7_val,\n",
    "        verbose = 1, \n",
    "        validation_steps = len(EffNetB7_val),\n",
    "        callbacks = [reduce_lr,cb,es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 31s 77ms/step - loss: 1.3973 - accuracy: 0.2500\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 1.3306 - accuracy: 0.5561\n",
      "Train: 0.250, Val: 0.556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = EffNetB7model.evaluate(EffNetB7_train, verbose=1)\n",
    "_, val_acc = EffNetB7model.evaluate(EffNetB7_val, verbose=1)\n",
    "print('Train: %.3f, Val: %.3f' % (train_acc, val_acc))\n",
    "\n",
    "# plot training history\n",
    "plt.plot(EffNet_history.history['loss'], label='train')\n",
    "plt.plot(EffNet_history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 8s 57ms/step - loss: 1.3333 - accuracy: 0.5462\n",
      "Test loss: 1.3332865238189697\n",
      "Test accuracy: 0.5461538434028625\n",
      "\n",
      "Time: 88.67366407499988 min\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = EffNetB7model.evaluate(EffNetB7_test)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "print(\"\\nTime:\",sum(cb.logs)/60,\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 12s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "#get predicted probality\n",
    "prediction = EffNetB7model.predict(EffNetB7_test,verbose=1)\n",
    "\n",
    "#Get class of prediction\n",
    "predicted_class = np.argmax(prediction,axis=1)\n",
    "\n",
    "#get trueclass\n",
    "true_classes = EffNetB7_test.classes\n",
    "\n",
    "# get names of pictures\n",
    "filenames = EffNetB7_test.filenames\n",
    "\n",
    "#store info in dataframe\n",
    "EffNetB7_predictions = pd.DataFrame({'Filename': filenames,'EffNetB7': predicted_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 0</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm1.tif</th>\n",
       "      <td>0.223889</td>\n",
       "      <td>0.206392</td>\n",
       "      <td>0.268597</td>\n",
       "      <td>0.301122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample10-sperm4.tif</th>\n",
       "      <td>0.223904</td>\n",
       "      <td>0.206396</td>\n",
       "      <td>0.268575</td>\n",
       "      <td>0.301125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample12-sperm9.tif</th>\n",
       "      <td>0.223888</td>\n",
       "      <td>0.206399</td>\n",
       "      <td>0.268580</td>\n",
       "      <td>0.301132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl2-sample5-sperm3.tif</th>\n",
       "      <td>0.223903</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>0.268585</td>\n",
       "      <td>0.301119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class0\\ch00_p1-pl3-sample14-sperm3.tif</th>\n",
       "      <td>0.223907</td>\n",
       "      <td>0.206391</td>\n",
       "      <td>0.268589</td>\n",
       "      <td>0.301113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\ch00_p5-pl1-sample9-sperm5.tif</th>\n",
       "      <td>0.223913</td>\n",
       "      <td>0.206392</td>\n",
       "      <td>0.268580</td>\n",
       "      <td>0.301115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_010.BMP</th>\n",
       "      <td>0.223904</td>\n",
       "      <td>0.206393</td>\n",
       "      <td>0.268584</td>\n",
       "      <td>0.301119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_013.BMP</th>\n",
       "      <td>0.223882</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.268581</td>\n",
       "      <td>0.301136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_014.BMP</th>\n",
       "      <td>0.223892</td>\n",
       "      <td>0.206390</td>\n",
       "      <td>0.268601</td>\n",
       "      <td>0.301118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3\\image_021.BMP</th>\n",
       "      <td>0.223904</td>\n",
       "      <td>0.206394</td>\n",
       "      <td>0.268581</td>\n",
       "      <td>0.301121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class 0   Class 1   Class 2   Class 3\n",
       "class0\\ch00_p1-pl2-sample10-sperm1.tif  0.223889  0.206392  0.268597  0.301122\n",
       "class0\\ch00_p1-pl2-sample10-sperm4.tif  0.223904  0.206396  0.268575  0.301125\n",
       "class0\\ch00_p1-pl2-sample12-sperm9.tif  0.223888  0.206399  0.268580  0.301132\n",
       "class0\\ch00_p1-pl2-sample5-sperm3.tif   0.223903  0.206393  0.268585  0.301119\n",
       "class0\\ch00_p1-pl3-sample14-sperm3.tif  0.223907  0.206391  0.268589  0.301113\n",
       "...                                          ...       ...       ...       ...\n",
       "class3\\ch00_p5-pl1-sample9-sperm5.tif   0.223913  0.206392  0.268580  0.301115\n",
       "class3\\image_010.BMP                    0.223904  0.206393  0.268584  0.301119\n",
       "class3\\image_013.BMP                    0.223882  0.206400  0.268581  0.301136\n",
       "class3\\image_014.BMP                    0.223892  0.206390  0.268601  0.301118\n",
       "class3\\image_021.BMP                    0.223904  0.206394  0.268581  0.301121\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Effnet_pred =  pd.DataFrame(prediction, columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3'], index = filenames)\n",
    "\n",
    "Effnet_pred.to_csv(path+'/Models/eff_pred_prob.csv')\n",
    "\n",
    "Effnet_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join prediction to dataframe\n",
    "df_predictions = df_predictions.merge(EffNetB7_predictions, on = 'Filename', how = 'inner')\n",
    "\n",
    "del EffNetB7_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>Test</th>\n",
       "      <th>cnn_model</th>\n",
       "      <th>AlexNet</th>\n",
       "      <th>ResNet50</th>\n",
       "      <th>EffNetB7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm1.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample10-sperm4.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample12-sperm9.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class0\\ch00_p1-pl2-sample5-sperm3.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class0\\ch00_p1-pl3-sample14-sperm3.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>class3\\ch00_p5-pl1-sample9-sperm5.tif</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>class3\\image_010.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>class3\\image_013.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>class3\\image_014.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>class3\\image_021.BMP</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Filename  Label  Test  cnn_model  AlexNet  \\\n",
       "0    class0\\ch00_p1-pl2-sample10-sperm1.tif      0     3          3        2   \n",
       "1    class0\\ch00_p1-pl2-sample10-sperm4.tif      0     3          3        1   \n",
       "2    class0\\ch00_p1-pl2-sample12-sperm9.tif      0     1          1        3   \n",
       "3     class0\\ch00_p1-pl2-sample5-sperm3.tif      0     3          3        3   \n",
       "4    class0\\ch00_p1-pl3-sample14-sperm3.tif      0     3          3        1   \n",
       "..                                      ...    ...   ...        ...      ...   \n",
       "125   class3\\ch00_p5-pl1-sample9-sperm5.tif      3     3          3        3   \n",
       "126                    class3\\image_010.BMP      3     3          3        3   \n",
       "127                    class3\\image_013.BMP      3     3          3        2   \n",
       "128                    class3\\image_014.BMP      3     3          3        2   \n",
       "129                    class3\\image_021.BMP      3     0          0        0   \n",
       "\n",
       "     ResNet50  EffNetB7  \n",
       "0           3         3  \n",
       "1           3         3  \n",
       "2           0         3  \n",
       "3           1         3  \n",
       "4           1         3  \n",
       "..        ...       ...  \n",
       "125         1         3  \n",
       "126         3         3  \n",
       "127         3         3  \n",
       "128         0         3  \n",
       "129         2         3  \n",
       "\n",
       "[130 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7 Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________\n",
      "                                                     TRAIN                                                 \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.28      0.26      6400\n",
      "           1       0.25      0.16      0.19      6400\n",
      "           2       0.24      0.07      0.11      6400\n",
      "           3       0.25      0.49      0.33      6400\n",
      "\n",
      "    accuracy                           0.25     25600\n",
      "   macro avg       0.25      0.25      0.22     25600\n",
      "weighted avg       0.25      0.25      0.22     25600\n",
      "\n",
      "[[1762 1035  459 3144]\n",
      " [1747 1013  462 3178]\n",
      " [1767 1007  448 3178]\n",
      " [1743 1042  469 3146]]\n",
      "___________________________________________________________________________________________________________\n",
      "                                                VALIDATION                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.26      0.16        46\n",
      "           1       0.23      0.23      0.23        84\n",
      "           2       0.07      0.05      0.06        40\n",
      "           3       0.56      0.44      0.49       213\n",
      "\n",
      "    accuracy                           0.33       383\n",
      "   macro avg       0.24      0.24      0.23       383\n",
      "weighted avg       0.38      0.33      0.35       383\n",
      "\n",
      "[[12 15  4 15]\n",
      " [23 19  4 38]\n",
      " [10  6  2 22]\n",
      " [55 44 20 94]]\n"
     ]
    }
   ],
   "source": [
    "train_labels, val_labels = EffNetB7_train.classes, EffNetB7_val.classes\n",
    "pred_train, pred_val = np.argmax(res50model.predict(EffNetB7_train), axis = 1), np.argmax(res50model.predict(EffNetB7_val), axis = 1)\n",
    "\n",
    "metrics(train_labels, pred_train , val_labels, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 16]\n",
      " [ 0  0  0 29]\n",
      " [ 0  0  0 14]\n",
      " [ 0  0  0 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.00      0.00      0.00        16\n",
      "      class1       0.00      0.00      0.00        29\n",
      "      class2       0.00      0.00      0.00        14\n",
      "      class3       0.55      1.00      0.71        71\n",
      "\n",
      "    accuracy                           0.55       130\n",
      "   macro avg       0.14      0.25      0.18       130\n",
      "weighted avg       0.30      0.55      0.39       130\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ricardo Santos\\anaconda3\\envs\\deep_\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_labels = list(EffNetB7_test.class_indices.keys())   \n",
    "\n",
    "print(confusion_matrix(true_classes, predicted_class))\n",
    "\n",
    "\n",
    "report = classification_report(true_classes, predicted_class, target_names=class_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE CSV\n",
    "\n",
    "df_predictions.to_csv(path+'/Models/pred_classes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
